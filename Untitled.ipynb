{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2e994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# AWS設定\n",
    "bucket='sagemaker-han'\n",
    "prefix = \"sagemaker/DEMO-batch-transform\"\n",
    "role = 'FullAccessHan'\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333fe95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b916df31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz to ../../../../../../../tmp/reviews/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/reviews/\n",
    "!aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz /tmp/reviews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79f7516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/q6ch_gg56413s5tt7ymydn7m0000gn/T/ipykernel_10853/3612527241.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(\n",
      "b'Skipping line 92523: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 343254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 524626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 623024: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 977412: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1496867: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1711638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1787213: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2395306: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2527690: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12190288</td>\n",
       "      <td>R3FU16928EP5TC</td>\n",
       "      <td>B00AYB1482</td>\n",
       "      <td>668895143</td>\n",
       "      <td>Enlightened: Season 1</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I loved it and I wish there was a season 3</td>\n",
       "      <td>I loved it and I wish there was a season 3... ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30549954</td>\n",
       "      <td>R1IZHHS1MH3AQ4</td>\n",
       "      <td>B00KQD28OM</td>\n",
       "      <td>246219280</td>\n",
       "      <td>Vicious</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52895410</td>\n",
       "      <td>R52R85WC6TIAH</td>\n",
       "      <td>B01489L5LQ</td>\n",
       "      <td>534732318</td>\n",
       "      <td>After Words</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Charming movie</td>\n",
       "      <td>This movie isn't perfect, but it gets a lot of...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>27072354</td>\n",
       "      <td>R7HOOYTVIB0DS</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>239012694</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>excellant this is what tv should be</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>26939022</td>\n",
       "      <td>R1XQ2N5CDOZGNX</td>\n",
       "      <td>B0094LZMT0</td>\n",
       "      <td>535858974</td>\n",
       "      <td>On The Waterfront</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Brilliant film from beginning to end</td>\n",
       "      <td>Brilliant film from beginning to end. All of t...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12190288  R3FU16928EP5TC  B00AYB1482       668895143   \n",
       "1          US     30549954  R1IZHHS1MH3AQ4  B00KQD28OM       246219280   \n",
       "2          US     52895410   R52R85WC6TIAH  B01489L5LQ       534732318   \n",
       "3          US     27072354   R7HOOYTVIB0DS  B008LOVIIK       239012694   \n",
       "4          US     26939022  R1XQ2N5CDOZGNX  B0094LZMT0       535858974   \n",
       "\n",
       "                           product_title        product_category  star_rating  \\\n",
       "0                  Enlightened: Season 1  Digital_Video_Download            5   \n",
       "1                                Vicious  Digital_Video_Download            5   \n",
       "2                            After Words  Digital_Video_Download            4   \n",
       "3  Masterpiece: Inspector Lewis Season 5  Digital_Video_Download            5   \n",
       "4                      On The Waterfront  Digital_Video_Download            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              0            0    N                 Y   \n",
       "1              0            0    N                 Y   \n",
       "2             17           18    N                 Y   \n",
       "3              0            0    N                 Y   \n",
       "4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0         I loved it and I wish there was a season 3   \n",
       "1  As always it seems that the best shows come fr...   \n",
       "2                                     Charming movie   \n",
       "3                                         Five Stars   \n",
       "4               Brilliant film from beginning to end   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I loved it and I wish there was a season 3... ...  2015-08-31  \n",
       "1  As always it seems that the best shows come fr...  2015-08-31  \n",
       "2  This movie isn't perfect, but it gets a lot of...  2015-08-31  \n",
       "3                excellant this is what tv should be  2015-08-31  \n",
       "4  Brilliant film from beginning to end. All of t...  2015-08-31  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/tmp/reviews/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\",\n",
    "    delimiter=\"\\t\",\n",
    "    error_bad_lines=False,\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bfacab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"customer_id\", \"product_id\", \"star_rating\", \"product_title\"]]\n",
    "customers = df[\"customer_id\"].value_counts()\n",
    "products = df[\"product_id\"].value_counts()\n",
    "\n",
    "quantiles = [\n",
    "    0,\n",
    "    0.1,\n",
    "    0.25,\n",
    "    0.5,\n",
    "    0.75,\n",
    "    0.8,\n",
    "    0.85,\n",
    "    0.9,\n",
    "    0.95,\n",
    "    0.96,\n",
    "    0.97,\n",
    "    0.98,\n",
    "    0.99,\n",
    "    0.995,\n",
    "    0.999,\n",
    "    0.9999,\n",
    "    1,\n",
    "]\n",
    "customers = customers[customers >= 35]\n",
    "products = products[products >= 20]\n",
    "\n",
    "reduced_df = df.merge(pd.DataFrame({\"customer_id\": customers.index})).merge(\n",
    "    pd.DataFrame({\"product_id\": products.index})\n",
    ")\n",
    "customers = reduced_df[\"customer_id\"].value_counts()\n",
    "products = reduced_df[\"product_id\"].value_counts()\n",
    "test_products = products.sample(frac=0.005)\n",
    "train_products = products[~(products.index.isin(test_products.index))]\n",
    "customer_index = pd.DataFrame(\n",
    "    {\"customer_id\": customers.index, \"user\": np.arange(customers.shape[0])}\n",
    ")\n",
    "train_product_index = pd.DataFrame(\n",
    "    {\"product_id\": train_products.index, \"item\": np.arange(train_products.shape[0])}\n",
    ")\n",
    "test_product_index = pd.DataFrame(\n",
    "    {\"product_id\": test_products.index, \"item\": np.arange(test_products.shape[0])}\n",
    ")\n",
    "\n",
    "train_df = reduced_df.merge(customer_index).merge(train_product_index)\n",
    "test_df = reduced_df.merge(customer_index).merge(test_product_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09e7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "train_sparse = scipy.sparse.csr_matrix(\n",
    "    (\n",
    "        np.where(train_df[\"star_rating\"].values >= 4, 1, 0),\n",
    "        (train_df[\"item\"].values, train_df[\"user\"].values),\n",
    "    ),\n",
    "    shape=(train_df[\"item\"].nunique(), customers.count()),\n",
    ")\n",
    "\n",
    "test_sparse = scipy.sparse.csr_matrix(\n",
    "    (\n",
    "        np.where(test_df[\"star_rating\"].values >= 4, 1, 0),\n",
    "        (test_df[\"item\"].values, test_df[\"user\"].values),\n",
    "    ),\n",
    "    shape=(test_df[\"item\"].nunique(), customers.count()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37ac3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/tmp/reviews/train.csv\", train_sparse.todense(), delimiter=\",\", fmt=\"%i\")\n",
    "\n",
    "np.savetxt(\"/tmp/reviews/test.csv\", test_sparse.todense(), delimiter=\",\", fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fc84bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e8ca161",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = sess.upload_data(\n",
    "    \"/tmp/reviews/train.csv\", bucket=bucket, key_prefix=\"{}/pca/train\".format(prefix)\n",
    ")\n",
    "\n",
    "test_s3 = sess.upload_data(\n",
    "    \"/tmp/reviews/test.csv\", bucket=bucket, key_prefix=\"{}/pca/test\".format(prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4916782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, \"pca\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dba141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "pca = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/pca/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "pca.set_hyperparameters(\n",
    "    feature_dim=customers.count(),\n",
    "    num_components=100,\n",
    "    subtract_mean=True,\n",
    "    algorithm_mode=\"randomized\",\n",
    "    mini_batch_size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5752ad55",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-21 09:58:44 Starting - Starting the training job...ProfilerReport-1661075923: InProgress\n",
      "...\n",
      "2022-08-21 09:59:35 Starting - Preparing the instances for training......\n",
      "2022-08-21 10:00:37 Downloading - Downloading input data...\n",
      "2022-08-21 10:01:17 Training - Downloading the training image.........\n",
      "2022-08-21 10:03:01 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'algorithm_mode': 'regular', 'subtract_mean': 'true', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'algorithm_mode': 'randomized', 'feature_dim': '2348', 'mini_batch_size': '500', 'num_components': '100', 'subtract_mean': 'True'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Final configuration: {'algorithm_mode': 'randomized', 'subtract_mean': 'True', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto', 'feature_dim': '2348', 'mini_batch_size': '500', 'num_components': '100'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 WARNING 140064920966976] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-208-200.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-08-21-09-58-43-336', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:608095525235:training-job/pca-2022-08-21-09-58-43-336', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b2b3773ac51b032825e79534db7b5a4bb415a8cdedebc30643c9a2139c6b475b-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-208-200.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-08-21-09-58-43-336', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:608095525235:training-job/pca-2022-08-21-09-58-43-336', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b2b3773ac51b032825e79534db7b5a4bb415a8cdedebc30643c9a2139c6b475b-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.208.200', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-208-200.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-08-21-09-58-43-336', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:608095525235:training-job/pca-2022-08-21-09-58-43-336', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b2b3773ac51b032825e79534db7b5a4bb415a8cdedebc30643c9a2139c6b475b-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-208-200.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-08-21-09-58-43-336', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:608095525235:training-job/pca-2022-08-21-09-58-43-336', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b2b3773ac51b032825e79534db7b5a4bb415a8cdedebc30643c9a2139c6b475b-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.208.200', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-208-200.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'pca-2022-08-21-09-58-43-336', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:608095525235:training-job/pca-2022-08-21-09-58-43-336', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/proxy-b2b3773ac51b032825e79534db7b5a4bb415a8cdedebc30643c9a2139c6b475b-customer', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'all', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '2', 'DMLC_INTERFACE': 'eth0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.208.200', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 35 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 44 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:07 INFO 140064920966976] Using default worker.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:08 INFO 140064920966976] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:08 INFO 140064920966976] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:08 INFO 140064920966976] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:08 INFO 140064920966976] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:08 INFO 140064920966976] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] The default executor is <RandomizedPCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] 2348 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:09 INFO 140064920966976] <RandomizedPCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076188.1139185, \"EndTime\": 1661076189.3203666, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1206.1035633087158, \"count\": 1, \"min\": 1206.1035633087158, \"max\": 1206.1035633087158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076189.3206732, \"EndTime\": 1661076189.320734, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#metrics {\"StartTime\": 1661076189.3205638, \"EndTime\": 1661076201.6374538, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 12316.346883773804, \"count\": 1, \"min\": 12316.346883773804, \"max\": 12316.346883773804}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:21 INFO 140064920966976] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076189.3210604, \"EndTime\": 1661076201.6378756, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 18708.0, \"count\": 1, \"min\": 18708, \"max\": 18708}, \"Total Batches Seen\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Max Records Seen Between Resets\": {\"sum\": 18708.0, \"count\": 1, \"min\": 18708, \"max\": 18708}, \"Max Batches Seen Between Resets\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 18708.0, \"count\": 1, \"min\": 18708, \"max\": 18708}, \"Number of Batches Since Last Reset\": {\"sum\": 38.0, \"count\": 1, \"min\": 38, \"max\": 38}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:21 INFO 140064920966976] #throughput_metric: host=algo-1, train throughput=1518.8807118951063 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076201.6375709, \"EndTime\": 1661076201.835571, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 197.2343921661377, \"count\": 1, \"min\": 197.2343921661377, \"max\": 197.2343921661377}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:03:21 INFO 140064920966976] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076201.8356905, \"EndTime\": 1661076201.843269, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 31.817913055419922, \"count\": 1, \"min\": 31.817913055419922, \"max\": 31.817913055419922}, \"totaltime\": {\"sum\": 13919.909477233887, \"count\": 1, \"min\": 13919.909477233887, \"max\": 13919.909477233887}}}\u001b[0m\n",
      "\n",
      "2022-08-21 10:03:38 Uploading - Uploading generated training model\n",
      "2022-08-21 10:03:58 Completed - Training job completed\n",
      "ProfilerReport-1661075923: NoIssuesFound\n",
      "Training seconds: 187\n",
      "Billable seconds: 187\n"
     ]
    }
   ],
   "source": [
    "train_inputs = sagemaker.inputs.TrainingInput(train_s3, content_type=\"text/csv;label_size=0\")\n",
    "pca.fit({\"train\": train_inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f888a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_transformer = pca.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=\"s3://{}/{}/pca/transform/train\".format(bucket, prefix),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ed2a0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi: took 0.035 seconds to run.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading entry points\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.2515771, \"EndTime\": 1661076791.374515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.3488784, \"EndTime\": 1661076794.6846848, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.4429183, \"EndTime\": 1661076794.7682252, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.485746, \"EndTime\": 1661076794.918351, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076791.3747623, \"EndTime\": 1661076794.9424872, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.3488784, \"EndTime\": 1661076794.6846848, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.4429183, \"EndTime\": 1661076794.7682252, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.485746, \"EndTime\": 1661076794.918351, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076791.3747623, \"EndTime\": 1661076794.9424872, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-08-21T10:13:11.390:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.6849337, \"EndTime\": 1661076796.3284607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.7684944, \"EndTime\": 1661076796.3584216, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.919017, \"EndTime\": 1661076796.4160402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.6849337, \"EndTime\": 1661076796.3284607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.7684944, \"EndTime\": 1661076796.3584216, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.919017, \"EndTime\": 1661076796.4160402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.9426322, \"EndTime\": 1661076796.489689, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.9426322, \"EndTime\": 1661076796.489689, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.4162214, \"EndTime\": 1661076797.8555868, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.329074, \"EndTime\": 1661076797.8844566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.4898283, \"EndTime\": 1661076797.9871442, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.3585644, \"EndTime\": 1661076798.101746, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.4162214, \"EndTime\": 1661076797.8555868, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.329074, \"EndTime\": 1661076797.8844566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.4898283, \"EndTime\": 1661076797.9871442, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.3585644, \"EndTime\": 1661076798.101746, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1300.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076797.8845525, \"EndTime\": 1661076798.6672275, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076797.98726, \"EndTime\": 1661076798.7187693, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1300.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076797.8845525, \"EndTime\": 1661076798.6672275, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076797.98726, \"EndTime\": 1661076798.7187693, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi: took 0.035 seconds to run.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading entry points\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi: took 0.035 seconds to run.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loading entry points\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2022-08-21 10:13:09 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2022-08-21 10:13:09 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] loading model...\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:09 INFO 140021922793280] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.2515771, \"EndTime\": 1661076791.374515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.2515771, \"EndTime\": 1661076791.374515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.3488784, \"EndTime\": 1661076794.6846848, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.4429183, \"EndTime\": 1661076794.7682252, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076789.485746, \"EndTime\": 1661076794.918351, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076791.3747623, \"EndTime\": 1661076794.9424872, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:14 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.3488784, \"EndTime\": 1661076794.6846848, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.4429183, \"EndTime\": 1661076794.7682252, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076789.485746, \"EndTime\": 1661076794.918351, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076791.3747623, \"EndTime\": 1661076794.9424872, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-08-21T10:13:11.390:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.6849337, \"EndTime\": 1661076796.3284607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.7684944, \"EndTime\": 1661076796.3584216, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.919017, \"EndTime\": 1661076796.4160402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:15 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:16 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.6849337, \"EndTime\": 1661076796.3284607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.7684944, \"EndTime\": 1661076796.3584216, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.919017, \"EndTime\": 1661076796.4160402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076794.9426322, \"EndTime\": 1661076796.489689, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076794.9426322, \"EndTime\": 1661076796.489689, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.4162214, \"EndTime\": 1661076797.8555868, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.329074, \"EndTime\": 1661076797.8844566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.4898283, \"EndTime\": 1661076797.9871442, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076796.3585644, \"EndTime\": 1661076798.101746, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:17 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.4162214, \"EndTime\": 1661076797.8555868, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.329074, \"EndTime\": 1661076797.8844566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.4898283, \"EndTime\": 1661076797.9871442, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076796.3585644, \"EndTime\": 1661076798.101746, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1338.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1300.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076797.8845525, \"EndTime\": 1661076798.6672275, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1661076797.98726, \"EndTime\": 1661076798.7187693, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[08/21/2022 10:13:18 WARNING 140021922793280] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[08/21/2022 10:13:18 INFO 140021922793280] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1300.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076797.8845525, \"EndTime\": 1661076798.6672275, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1661076797.98726, \"EndTime\": 1661076798.7187693, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.transform(train_s3, content_type=\"text/csv\", split_type=\"Line\")\n",
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b97adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-han/sagemaker/DEMO-batch-transform/pca/transform/train/train.csv.out to ./train.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pca_transformer.output_path ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6670855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "pca_predictor = pca.deploy(\n",
    "    initial_instance_count=1,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    ")\n",
    "components = []\n",
    "for array in np.array_split(np.array(train_sparse.todense()), 500):\n",
    "    result = pca_predictor.predict(array)\n",
    "    components += [r[\"projection\"] for r in result[\"projections\"]]\n",
    "components = np.array(components)\n",
    "pca_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a174645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sparse.todense())//1338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e26418f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-han/sagemaker/DEMO-batch-transform/pca/train/train.csv'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a4848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
