{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0c300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os, boto3, json, sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from io import BytesIO\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# AWS設定\n",
    "region = boto3.Session().region_name\n",
    "role = 'han_s3_full_access'\n",
    "bucket='sagemaker-han-batch'\n",
    "# role = 'FullAccessHan'\n",
    "# bucket='sagemaker-han'\n",
    "prefix = 'batch-images'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "model_prefix = os.path.join(prefix, 'model')\n",
    "input_prefix = os.path.join(prefix, 'inputs')\n",
    "output_prefix = os.path.join(prefix, 'outputs')\n",
    "inference_prefix = os.path.join(prefix, 'f_inference')\n",
    "\n",
    "# Local設定\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "model_dir = os.path.join(base_dir, 'model')\n",
    "input_dir = os.path.join(base_dir, 'inputs')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "inference_dir = os.path.join(base_dir, 'inference')\n",
    "source_dir = os.path.join(base_dir, 'src')\n",
    "for dir_name in [model_dir, input_dir, output_dir, source_dir, inference_dir]:\n",
    "    make_dir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f28de312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inference用のデータを作る(jsonlines)\n",
    "    - Sampling\n",
    "    - Convert Image into bytes\n",
    "    - Save as jsonlines\n",
    "'''\n",
    "from src.utils import image_to_bytes\n",
    "\n",
    "r_inference_path = os.path.join(base_dir, 'real_inference')\n",
    "n = 1000\n",
    "json_name = r_inference_path+f'/inf_data{n}.jsonl'\n",
    "\n",
    "image_to_bytes(json_name, data_dir, inference_dir, n)\n",
    "\n",
    "f_inference = sagemaker_session.upload_data(path=r_inference_path, bucket=bucket, key_prefix='batch-images/r_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6c0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for the model training\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "training_data_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(input_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(output_dir, 'test.pt'))\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=input_dir, bucket=bucket, key_prefix=input_prefix)\n",
    "outputs = sagemaker_session.upload_data(path=output_dir, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9a0ac",
   "metadata": {},
   "source": [
    "## Traning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Container\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"resnet.py\",\n",
    "                    role=role,\n",
    "                    source_dir = \"src\",\n",
    "                    framework_version='1.12.0',\n",
    "                    py_version='py38',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'batch-size':128,\n",
    "                        'lr': 0.01,\n",
    "                        'epochs': 1,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.rand(1,3,32,32)\n",
    "test_output = cifar10_predictor.predict(test_input)\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)\n",
    "\n",
    "cifar10_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4fb4",
   "metadata": {},
   "source": [
    "# Batch Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb925323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# home\n",
    "# model_path = 's3://sagemaker-us-west-2-608095525235/pytorch-training-2022-08-22-14-02-01-637/model.tar.gz'\n",
    "# fusic\n",
    "model_path = 's3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-11-21-23-382/model.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data = model_path,\n",
    "                             entry_point='resnet_batch_transform.py',\n",
    "                             source_dir = 'src',\n",
    "                             framework_version='1.12.0',\n",
    "                             py_version='py38',\n",
    "                             role = role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea2048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concurrent_transforms = 4\n",
    "max_payload = 25\n",
    "# strategy = 'SingleRecord'\n",
    "# split_type = None\n",
    "strategy = 'MultiRecord'\n",
    "split_type = 'Line'\n",
    "\n",
    "output_s3_path = 's3://{}/{}/bt_test_{}_{}_{}_{}'.format(bucket, output_prefix, max_concurrent_transforms, max_payload, strategy, split_type)\n",
    "\n",
    "transformer = pytorch_model.transformer(instance_count=1,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              max_concurrent_transforms=max_concurrent_transforms,\n",
    "                              max_payload=max_payload,  \n",
    "                              strategy=strategy,\n",
    "                              output_path=output_s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a14655a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,120 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,217 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.6.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 3006 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.8\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mModel config: N/A\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,226 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,255 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,260 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,260 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,262 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,276 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,512 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,513 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:10,533 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,102 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,308 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,310 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.206260681152344|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,312 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.658870697021484|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,313 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,313 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14514.234375|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,314 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:900.13671875|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,315 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:7.8|#Level:Host|#hostname:bcc66948b258,timestamp:1661420231\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,591 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,594 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]46\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,594 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,600 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,605 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,614 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,620 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420231620\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,626 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,627 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]49\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,628 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,630 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,628 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,638 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,640 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420231640\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,708 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,729 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,810 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,813 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]47\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,814 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,815 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,815 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,830 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420231830\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,830 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,900 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,917 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,919 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]48\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,920 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,921 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,920 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,929 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,929 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420231929\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:11,987 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,234 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,235 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,237 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,237 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,238 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,238 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,239 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,239 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,240 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,240 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,240 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,241 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,248 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,249 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,249 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,249 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,250 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,250 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,250 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,251 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,251 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,252 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,252 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,257 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,267 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,275 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,275 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,276 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,277 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,322 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,345 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,345 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,346 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,346 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,346 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,346 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,347 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,347 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,347 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,347 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,348 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,348 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,348 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,350 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,350 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,350 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,350 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,351 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,351 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,354 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,358 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,376 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,377 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,377 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,378 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,378 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,378 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,421 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,427 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,428 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,428 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,428 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,429 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,429 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,429 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,430 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,430 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,430 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,430 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,431 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,431 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,431 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,432 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,432 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,432 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,434 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,439 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,442 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,443 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,443 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,443 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,444 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,515 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,553 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,566 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,567 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,568 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,569 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,569 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,569 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,569 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,570 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,570 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,569 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,571 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,777 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,781 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:12,781 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,419 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,430 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]143\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,430 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,430 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,431 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,454 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420234454\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,492 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,492 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,496 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]150\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,497 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,499 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,497 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,516 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,515 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420234515\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,545 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,582 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,688 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]147\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,692 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,693 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,692 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,712 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,712 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420234712\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,950 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,956 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,956 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,963 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,964 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,964 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,965 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,965 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,966 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,966 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,967 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,967 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,968 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,968 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,969 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,969 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,970 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,971 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,971 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,972 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,972 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,972 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,973 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,978 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,978 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,979 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,979 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,979 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,980 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,980 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,980 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,981 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,981 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,981 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,982 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,982 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,983 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,983 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,984 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,984 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,984 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,985 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,985 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,985 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,986 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:14,986 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,000 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,001 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,001 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,001 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,002 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,009 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,013 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,014 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,014 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,014 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,015 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,019 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,039 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,121 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,122 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]155\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,122 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,123 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,123 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,133 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,134 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420235134\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,183 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,259 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,261 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,261 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,264 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,264 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,266 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,266 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,267 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,267 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,267 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,267 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,273 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,273 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,274 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,275 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,276 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,278 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,282 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,282 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,283 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,283 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,336 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,394 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,472 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,472 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,473 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,474 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,474 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,474 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,474 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,475 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,475 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,475 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,475 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,475 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,476 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,476 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,476 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,476 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,476 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,481 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,483 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,569 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,569 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,784 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:15,784 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,024 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,026 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]201\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,027 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,027 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,028 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,028 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,029 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420237029\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,030 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,059 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,060 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]203\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,060 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,062 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420237062\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,060 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,062 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,071 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,072 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,452 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,452 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,453 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,454 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,454 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,454 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,455 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,455 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,455 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,456 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,457 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,457 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,457 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,457 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,457 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,464 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,464 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,472 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,473 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,475 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,485 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,485 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,485 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,485 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,486 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,589 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,589 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,589 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,589 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,589 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,590 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,590 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,591 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,591 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,591 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,592 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,593 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,600 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]209\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,601 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420237606\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,606 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,606 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,827 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,829 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]213\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,829 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,830 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,833 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,832 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420237832\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,834 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,834 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,927 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,927 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:17,932 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,008 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,009 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,010 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,011 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,011 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,012 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,020 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,020 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,021 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,021 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,021 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,112 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,112 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,112 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,112 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,113 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,114 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,114 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,288 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,289 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:18,461 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[32m2022-08-25T09:37:19.409:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=25, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:19,391 [INFO ] W-9003-model_1.0 ACCESS_LOG - /169.254.255.130:37894 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:19,391 [INFO ] W-9003-model_1.0 ACCESS_LOG - /169.254.255.130:37894 \"GET /ping HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:19,391 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:bcc66948b258,timestamp:1661420239\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:19,403 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:34080 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:19,404 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:bcc66948b258,timestamp:1661420239\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:19,391 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:bcc66948b258,timestamp:1661420239\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:19,403 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:34080 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:19,404 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:bcc66948b258,timestamp:1661420239\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,605 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]261\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,608 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,608 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420240608\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,610 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,723 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,723 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]256\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,724 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,727 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,605 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]261\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,606 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,608 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,608 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420240608\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,610 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,723 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,723 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]256\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,724 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,727 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,728 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,729 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420240729\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,730 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:20,731 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,728 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,729 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420240729\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,730 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:20,731 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,069 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,071 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,080 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,212 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,212 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,213 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,213 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,213 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,213 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,213 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,214 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,354 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]274\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,356 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,356 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,360 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420241360\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,361 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,361 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,070 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,071 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,076 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,080 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,212 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,212 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,213 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,213 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,213 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,213 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,213 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,214 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,214 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,354 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]274\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,356 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,356 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,360 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420241360\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,361 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,361 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,377 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]268\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,380 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,388 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420241388\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,388 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,389 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,492 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,377 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]268\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,378 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,380 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,388 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420241388\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,388 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,389 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,492 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,599 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,599 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,686 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,688 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,689 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,696 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,684 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,685 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,686 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,688 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,689 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,689 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,696 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,726 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,728 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,728 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,729 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,729 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,729 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,729 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,961 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:21,998 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,728 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,728 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,729 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,729 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,729 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,729 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,961 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:21,998 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]312\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,795 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,797 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420244797\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,798 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,798 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,998 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]316\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,005 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,005 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245005\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,007 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]312\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,794 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,795 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,797 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420244797\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,798 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,798 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,998 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]316\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:24,999 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,005 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,005 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245005\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,007 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,271 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,275 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,275 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,276 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,278 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,280 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,282 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,282 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,283 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,283 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,283 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,275 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,275 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,276 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,278 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,280 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,282 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,282 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,283 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,283 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,283 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,518 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,519 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,532 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,533 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,512 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,518 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,519 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,532 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,533 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,533 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,633 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,634 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,745 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]326\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245748\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,751 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,751 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,766 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]329\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,769 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245769\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,769 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,770 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,787 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:25,788 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,030 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,030 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,633 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,634 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,745 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]326\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,746 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245748\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,751 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,751 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,766 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]329\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,767 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,769 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420245769\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,769 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,770 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,787 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:25,788 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,030 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,030 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,031 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,031 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,031 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,036 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,062 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,063 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,063 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,064 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,311 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:26,330 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,031 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,031 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,031 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,029 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,036 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,061 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,062 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,062 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,063 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,063 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,064 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,311 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:26,330 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,001 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]364\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,001 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]364\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,004 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420251003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,005 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,006 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,002 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,004 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420251003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,005 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,006 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,308 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,309 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,309 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,310 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,310 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,311 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,342 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]368\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,344 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,345 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420251345\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,345 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,308 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,309 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,309 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,310 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,310 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,311 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,342 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]368\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,343 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,344 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,345 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420251345\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,345 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,638 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,639 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,786 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,786 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:31,962 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]384\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,037 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,039 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,040 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420252040\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,040 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]381\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,100 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,105 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420252105\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,106 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,319 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,636 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,637 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,638 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,639 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,786 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,786 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:31,962 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]384\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,036 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,037 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,039 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,040 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420252040\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,040 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]381\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,100 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,105 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420252105\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,106 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,319 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,321 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,321 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,323 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,323 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,324 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,324 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,324 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,386 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,388 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,388 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,388 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,389 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,389 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,389 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,390 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,390 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,320 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,321 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,321 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,323 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,323 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,324 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,324 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,324 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,386 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,387 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,388 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,388 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,388 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,389 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,389 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,389 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,390 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,390 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,590 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,590 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:32,651 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,590 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,590 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:32,651 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:39,975 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:39,975 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:39,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420259977\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:39,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:39,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,253 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,254 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,255 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,255 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,255 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,256 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,256 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]420\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,355 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,355 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420260355\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,356 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:39,975 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:39,975 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:39,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420259977\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:39,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:39,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,253 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,254 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,255 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,255 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,255 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,256 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,256 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]420\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,354 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,355 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,355 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420260355\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,356 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,585 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,684 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,685 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,683 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,685 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,686 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,686 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,686 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,687 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,688 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,689 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,686 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,689 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:40,940 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,585 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,684 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,685 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,683 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,685 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,686 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,686 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,686 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,687 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,688 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,689 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,686 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,689 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:40,940 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,239 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]436\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,241 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,241 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420261241\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,242 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,290 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]443\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420261293\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,519 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,520 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,523 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,523 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,524 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,524 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,524 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,239 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]436\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,240 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,241 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,241 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420261241\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,242 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,290 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]443\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,291 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420261293\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,518 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,519 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,520 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,523 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,523 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,524 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,524 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,524 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,561 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,561 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,561 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,561 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,561 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,562 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,562 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,562 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,561 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,561 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,561 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,561 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,561 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,562 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,562 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,562 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,775 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,775 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:41,830 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,775 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,775 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:41,830 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:53,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:53,883 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:53,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:53,883 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:53,884 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420273884\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:53,884 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:53,885 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:53,884 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420273884\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:53,884 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:53,885 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,143 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,145 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,147 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,148 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,148 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,149 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,150 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,374 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]475\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420274376\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,432 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,432 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,145 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,147 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,148 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,148 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,149 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,150 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,374 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]475\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,375 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420274376\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,376 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,432 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,432 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,656 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,654 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,655 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,656 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,658 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,659 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,934 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:54,934 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,228 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]491\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,233 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,233 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420275233\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,234 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,298 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]494\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420275300\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,658 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,659 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,659 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,934 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:54,934 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,228 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]491\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,229 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,233 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,233 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420275233\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,234 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,298 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]494\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,299 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420275300\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,300 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,481 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,481 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,480 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,482 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,477 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,478 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,481 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,481 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,480 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,482 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,482 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,566 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,566 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,564 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,566 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,566 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,566 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,566 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,567 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,567 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,566 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,566 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,567 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,567 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,776 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,776 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,826 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:37:55,826 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,776 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,776 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,826 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:37:55,826 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14051.1640625|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1363.33203125|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.7|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:11,117 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[34mAttributeError: _cache\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/proc/475/stat'\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process no longer exists (pid=475)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process PID not found (pid=475)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[34mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[34mArguments: ('475',)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14051.1640625|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1363.33203125|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:11,108 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:10.7|#Level:Host|#hostname:bcc66948b258,timestamp:1661420291\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:11,117 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[35mAttributeError: _cache\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[35mFileNotFoundError: [Errno 2] No such file or directory: '/proc/475/stat'\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process no longer exists (pid=475)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process PID not found (pid=475)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[35mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[35mArguments: ('475',)\u001b[0m\n",
      "\u001b[35m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[34mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[34mArguments: ('475', 0)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[34mAttributeError: _cache\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/proc/491/stat'\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process no longer exists (pid=491)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process PID not found (pid=491)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[34mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[34mArguments: ('491',)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[35mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[35mArguments: ('475', 0)\u001b[0m\n",
      "\u001b[35m--- Logging error ---\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[35mAttributeError: _cache\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[35mFileNotFoundError: [Errno 2] No such file or directory: '/proc/491/stat'\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process no longer exists (pid=491)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process PID not found (pid=491)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[35mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[35mArguments: ('491',)\u001b[0m\n",
      "\u001b[35m--- Logging error ---\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[34mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[34mArguments: ('491', 0)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[34mAttributeError: _cache\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/proc/494/stat'\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process no longer exists (pid=494)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[34mpsutil.NoSuchProcess: process PID not found (pid=494)\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[34mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[34mArguments: ('494',)\u001b[0m\n",
      "\u001b[34m--- Logging error ---\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[34mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[34mArguments: ('494', 0)\u001b[0m\n",
      "\u001b[34mException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>\u001b[0m\n",
      "\u001b[34mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[35mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[35mArguments: ('491', 0)\u001b[0m\n",
      "\u001b[35m--- Logging error ---\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 442, in wrapper\n",
      "    ret = self._cache[fun]\u001b[0m\n",
      "\u001b[35mAttributeError: _cache\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 445, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1684, in _parse_stat_file\n",
      "    data = bcat(\"%s/%s/stat\" % (self._procfs_path, self.pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 775, in bcat\n",
      "    return cat(fname, fallback=fallback, _open=open_binary)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 763, in cat\n",
      "    with _open(fname) as f:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_common.py\", line 727, in open_binary\n",
      "    return open(fname, \"rb\", buffering=FILE_READ_BUFFER_SIZE)\u001b[0m\n",
      "\u001b[35mFileNotFoundError: [Errno 2] No such file or directory: '/proc/494/stat'\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 361, in _init\n",
      "    self.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 714, in create_time\n",
      "    self._create_time = self._proc.create_time()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1852, in create_time\n",
      "    ctime = float(self._parse_stat_file()['create_time'])\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/_pslinux.py\", line 1649, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process no longer exists (pid=494)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 20, in get_cpu_usage\n",
      "    process = psutil.Process(int(pid))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 332, in __init__\n",
      "    self._init(pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/psutil/__init__.py\", line 373, in _init\n",
      "    raise NoSuchProcess(pid, msg='process PID not found')\u001b[0m\n",
      "\u001b[35mpsutil.NoSuchProcess: process PID not found (pid=494)\u001b[0m\n",
      "\u001b[35mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 22, in get_cpu_usage\n",
      "    logging.error(\"Failed get process for pid: %s\", pid, exc_info=True)\u001b[0m\n",
      "\u001b[35mMessage: 'Failed get process for pid: %s'\u001b[0m\n",
      "\u001b[35mArguments: ('494',)\u001b[0m\n",
      "\u001b[35m--- Logging error ---\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1089, in emit\n",
      "    self.flush()\n",
      "  File \"/opt/conda/lib/python3.8/logging/__init__.py\", line 1069, in flush\n",
      "    self.stream.flush()\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[35mCall stack:\n",
      "  File \"ts/metrics/metric_collector.py\", line 29, in <module>\n",
      "    check_process_mem_usage(sys.stdin)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ts/metrics/process_memory_metric.py\", line 40, in check_process_mem_usage\n",
      "    logging.info(\"%s:%d\", process, get_cpu_usage(process))\u001b[0m\n",
      "\u001b[35mMessage: '%s:%d'\u001b[0m\n",
      "\u001b[35mArguments: ('494', 0)\u001b[0m\n",
      "\u001b[35mException ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>\u001b[0m\n",
      "\u001b[35mBrokenPipeError: [Errno 32] Broken pipe\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]522\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420295777\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,778 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,778 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,961 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,961 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,962 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,962 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:15,964 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,311 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]522\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420295777\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,778 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,778 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,961 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,961 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,962 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,962 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:15,964 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,311 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,395 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,395 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]529\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420296397\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,590 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,395 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,395 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]529\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,396 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420296397\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,590 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,592 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,593 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,594 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,594 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,595 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,592 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,593 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,594 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,594 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,595 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,593 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,596 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,596 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:16,944 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,325 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]545\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,327 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,328 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420297328\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,328 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,329 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,365 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]549\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,367 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,368 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420297368\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,593 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,596 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,596 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:16,944 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,325 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]545\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,326 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,327 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,328 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420297328\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,328 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,329 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,365 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]549\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,367 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,366 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,368 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420297368\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,617 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,624 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,632 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,632 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,633 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,633 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,633 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,650 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,615 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,616 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,617 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,624 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,632 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,632 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,633 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,633 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,633 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,650 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,652 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,653 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,653 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,653 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,653 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,887 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,887 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:17,919 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,652 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,652 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,653 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,653 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,653 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,653 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,887 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,887 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:17,919 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,870 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,872 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,876 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,876 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,879 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,880 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:50,880 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,139 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,139 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]584\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,224 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,224 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,226 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,226 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420331226\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,227 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,504 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,503 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,872 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,876 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,876 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,879 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,880 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:50,880 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,139 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,139 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]584\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,224 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,224 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,226 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,226 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420331226\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,227 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,502 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,504 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,503 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,504 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,510 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,510 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,504 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,504 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,510 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,510 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:51,785 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,345 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]600\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,347 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420332347\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,348 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,348 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,406 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]603\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:51,785 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,345 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]600\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,346 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,347 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420332347\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,348 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,348 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,406 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]603\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,408 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420332409\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,407 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,408 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420332409\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,635 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,635 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,636 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,637 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,638 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,639 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,640 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,641 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,642 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,643 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,643 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,644 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,644 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,697 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,698 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,699 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,909 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,910 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,978 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:38:52,978 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,640 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,641 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,642 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,643 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,643 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,644 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,644 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,697 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,698 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,699 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,699 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,909 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,910 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,978 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:38:52,978 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,334 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,336 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,336 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,336 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,337 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,337 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:47,594 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,334 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,335 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,336 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,336 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,336 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,337 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,337 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:47,594 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,289 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]652\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420388292\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,397 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]656\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,289 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]652\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,290 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420388292\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,292 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,397 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]656\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,399 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,400 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,400 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420388400\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,401 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,570 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,576 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,398 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,399 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,400 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,400 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661420388400\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,401 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,570 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,572 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,573 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,574 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,576 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,576 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,578 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,579 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,579 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,580 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,580 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,580 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,576 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,578 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - #011Unexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.shortcut.0.weight\", \"module.layer1.0.shortcut.1.weight\", \"module.layer1.0.shortcut.1.bias\", \"module.layer1.0.shortcut.1.running_mean\", \"module.layer1.0.shortcut.1.running_var\", \"module.layer1.0.shortcut.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.shortcut.0.weight\", \"module.layer1.1.shortcut.1.weight\", \"module.layer1.1.shortcut.1.bias\", \"module.layer1.1.shortcut.1.running_mean\", \"module.layer1.1.shortcut.1.running_var\", \"module.layer1.1.shortcut.1.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.shortcut.0.weight\", \"module.layer1.2.shortcut.1.weight\", \"module.layer1.2.shortcut.1.bias\", \"module.layer1.2.shortcut.1.running_mean\", \"module.layer1.2.shortcut.1.running_var\", \"module.layer1.2.shortcut.1.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.shortcut.0.weight\", \"module.layer2.0.shortcut.1.weight\", \"module.layer2.0.shortcut.1.bias\", \"module.layer2.0.shortcut.1.running_mean\", \"module.layer2.0.shortcut.1.running_var\", \"module.layer2.0.shortcut.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.shortcut.0.weight\", \"module.layer2.1.shortcut.1.weight\", \"module.layer2.1.shortcut.1.bias\", \"module.layer2.1.shortcut.1.running_mean\", \"module.layer2.1.shortcut.1.running_var\", \"module.layer2.1.shortcut.1.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.shortcut.0.weight\", \"module.layer2.2.shortcut.1.weight\", \"module.layer2.2.shortcut.1.bias\", \"module.layer2.2.shortcut.1.running_mean\", \"module.layer2.2.shortcut.1.running_var\", \"module.layer2.2.shortcut.1.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.shortcut.0.weight\", \"module.layer3.0.shortcut.1.weight\", \"module.layer3.0.shortcut.1.bias\", \"module.layer3.0.shortcut.1.running_mean\", \"module.layer3.0.shortcut.1.running_var\", \"module.layer3.0.shortcut.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.shortcut.0.weight\", \"module.layer3.1.shortcut.1.weight\", \"module.layer3.1.shortcut.1.bias\", \"module.layer3.1.shortcut.1.running_mean\", \"module.layer3.1.shortcut.1.running_var\", \"module.layer3.1.shortcut.1.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.shortcut.0.weight\", \"module.layer3.2.shortcut.1.weight\", \"module.layer3.2.shortcut.1.bias\", \"module.layer3.2.shortcut.1.running_mean\", \"module.layer3.2.shortcut.1.running_var\", \"module.layer3.2.shortcut.1.num_batches_tracked\", \"module.linear.weight\", \"module.linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,579 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,579 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,580 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,580 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,580 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 210, in <module>\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 181, in run_server\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 139, in handle_connection\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_service_worker.py\", line 104, in load_model\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/ts/model_loader.py\", line 151, in load\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\", line 51, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/default_handler_service.py\", line 66, in initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 162, in validate_and_initialize\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._model = self._model_fn(model_dir)\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/ml/model/code/resnet_batch_transform.py\", line 106, in model_fn\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,649 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,649 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,653 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,654 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,842 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,842 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[34m2022-08-25T09:39:48,918 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     model.load_state_dict(torch.load(f))\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1604, in load_state_dict\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - RuntimeError: Error(s) in loading state_dict for ResNet:\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,649 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - #011Missing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.shortcut.0.weight\", \"layer1.0.shortcut.1.weight\", \"layer1.0.shortcut.1.bias\", \"layer1.0.shortcut.1.running_mean\", \"layer1.0.shortcut.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.shortcut.0.weight\", \"layer1.1.shortcut.1.weight\", \"layer1.1.shortcut.1.bias\", \"layer1.1.shortcut.1.running_mean\", \"layer1.1.shortcut.1.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.shortcut.0.weight\", \"layer1.2.shortcut.1.weight\", \"layer1.2.shortcut.1.bias\", \"layer1.2.shortcut.1.running_mean\", \"layer1.2.shortcut.1.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.shortcut.0.weight\", \"layer2.1.shortcut.1.weight\", \"layer2.1.shortcut.1.bias\", \"layer2.1.shortcut.1.running_mean\", \"layer2.1.shortcut.1.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.shortcut.0.weight\", \"layer2.2.shortcut.1.weight\", \"layer2.2.shortcut.1.bias\", \"layer2.2.shortcut.1.running_mean\", \"layer2.2.shortcut.1.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.shortcut.0.weight\", \"layer3.1.shortcut.1.weight\", \"layer3.1.shortcut.1.bias\", \"layer3.1.shortcut.1.running_mean\", \"layer3.1.shortcut.1.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.shortcut.0.weight\", \"layer3.2.shortcut.1.weight\", \"layer3.2.shortcut.1.bias\", \"layer3.2.shortcut.1.running_mean\", \"layer3.2.shortcut.1.running_var\", \"linear.weight\", \"linear.bias\". \u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,649 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,650 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,653 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,654 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,842 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,842 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr\u001b[0m\n",
      "\u001b[35m2022-08-25T09:39:48,918 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=0'>1</a>\u001b[0m inference_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms3://\u001b[39m\u001b[39m{\u001b[39;00mbucket\u001b[39m}\u001b[39;00m\u001b[39m/batch-images/r_inference\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=1'>2</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mtransform(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=2'>3</a>\u001b[0m     data\u001b[39m=\u001b[39;49minference_path,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=3'>4</a>\u001b[0m     data_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mS3Prefix\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=4'>5</a>\u001b[0m     content_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mapplication/jsonlines\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=5'>6</a>\u001b[0m     wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=6'>7</a>\u001b[0m     split_type\u001b[39m=\u001b[39;49msplit_type,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000011?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aws_batch_transform-pg7SNxiG/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:248\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     run_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    246\u001b[0m     \u001b[39mreturn\u001b[39;00m self_instance\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mcontext\n\u001b[0;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aws_batch_transform-pg7SNxiG/lib/python3.9/site-packages/sagemaker/transformer.py:243\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, wait, logs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_transform_job \u001b[39m=\u001b[39m _TransformJob\u001b[39m.\u001b[39mstart_new(\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     model_client_config,\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_transform_job\u001b[39m.\u001b[39;49mwait(logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aws_batch_transform-pg7SNxiG/lib/python3.9/site-packages/sagemaker/transformer.py:440\u001b[0m, in \u001b[0;36m_TransformJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, logs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m logs:\n\u001b[0;32m--> 440\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49mlogs_for_transform_job(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjob_name, wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    441\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mwait_for_transform_job(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/aws_batch_transform-pg7SNxiG/lib/python3.9/site-packages/sagemaker/session.py:4006\u001b[0m, in \u001b[0;36mSession.logs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4003\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m LogState\u001b[39m.\u001b[39mCOMPLETE:\n\u001b[1;32m   4004\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 4006\u001b[0m time\u001b[39m.\u001b[39;49msleep(poll)\n\u001b[1;32m   4008\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m LogState\u001b[39m.\u001b[39mJOB_COMPLETE:\n\u001b[1;32m   4009\u001b[0m     state \u001b[39m=\u001b[39m LogState\u001b[39m.\u001b[39mCOMPLETE\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "inference_path = f's3://{bucket}/batch-images/r_inference'\n",
    "transformer.transform(\n",
    "    data=inference_path,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/jsonlines\",\n",
    "    wait=True,\n",
    "    split_type=split_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ccee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer.stop_transform_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf813c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 21, 12, 13, 37, 860000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'FailureReason': 'AlgorithmError: See job logs for more information',\n",
      " 'ModelName': 'pytorch-inference-2022-08-21-03-13-10-667',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '949',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 21 Aug 2022 05:10:13 GMT',\n",
      "                                      'x-amzn-requestid': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 21, 12, 18, 21, 796000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-han/sagemaker/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:608095525235:transform-job/pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobStatus': 'Failed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-608095525235/pytorch-inference-2022-08-21-03-13-37-242'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 8, 21, 12, 16, 42, 175000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "# import pprint as pp\n",
    "\n",
    "# job_name = 'pytorch-inference-2022-08-21-03-13-37-242'\n",
    "# sm_cli = sagemaker_session.sagemaker_client\n",
    "# job_info = sm_cli.describe_transform_job(TransformJobName=job_name)\n",
    "# pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "054838cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n",
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n",
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"predictions\": [1, 1, 1, 1, 1, 1]}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.resnet_batch_transform import resnet20\n",
    "\n",
    "tmp_model = resnet20()\n",
    "tmp_model.eval()\n",
    "tmp_input = torch.rand(2, 3, 32, 32)\n",
    "\n",
    "preds = []\n",
    "for _ in range(3):\n",
    "    tmp_output = tmp_model(tmp_input)\n",
    "    pred = torch.argmax(tmp_output, dim=1)\n",
    "    print(f'PRED SHAPE: {pred.shape}')\n",
    "    print(pred)\n",
    "    preds += pred\n",
    "\n",
    "preds = np.array(preds).tolist()\n",
    "\n",
    "p_return = {\"predictions\": preds}\n",
    "json.dumps(p_return)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "170915b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.SageMaker at 0x290eb4a60>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "969cb06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['create_transform_job',\n",
       " 'describe_transform_job',\n",
       " 'list_transform_jobs',\n",
       " 'stop_transform_job']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: \"transform\" in x, dir(sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "08288b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x['TransformJobStatus'] == \"InProgress\", sm.list_transform_jobs()['TransformJobSummaries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c4369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('aws_batch_transform-pg7SNxiG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "445eadaa75e92a02935b67c0f43eae30d5f0df35a0b86dd757723720e6c70438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
