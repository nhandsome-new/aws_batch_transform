{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0c300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os, boto3, json, sagemaker, numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from io import BytesIO\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        \n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# AWS設定\n",
    "role = 'han_s3_full_access'\n",
    "region = boto3.Session().region_name\n",
    "bucket='sagemaker-han-batch'\n",
    "prefix = 'batch-images'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "model_prefix = os.path.join(prefix, 'model')\n",
    "input_prefix = os.path.join(prefix, 'inputs')\n",
    "output_prefix = os.path.join(prefix, 'outputs')\n",
    "inference_prefix = os.path.join(prefix, 'inference')\n",
    "\n",
    "# Local設定\n",
    "base_dir = './'\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "model_dir = os.path.join(base_dir, 'model')\n",
    "input_dir = os.path.join(base_dir, 'inputs')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "inference_dir = os.path.join(base_dir, 'inference')\n",
    "source_dir = os.path.join(base_dir, 'src')\n",
    "for dir_name in [model_dir, input_dir, output_dir, source_dir, inference_dir]:\n",
    "    make_dir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28de312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 datas from CIFAR10 dataset\n",
    "\n",
    "from src.utils import create_init_sample_data, convert_np_to_png\n",
    "\n",
    "sampled_imgs = create_init_sample_data(data_dir, 100)\n",
    "convert_np_to_png(inference_dir, sampled_imgs)\n",
    "\n",
    "# Upload png images to S3\n",
    "inference_inputs = sagemaker_session.upload_data(\n",
    "    path=inference_dir, bucket=bucket, key_prefix=inference_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6c0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for the model training\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "training_data_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(input_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(output_dir, 'test.pt'))\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=input_dir, bucket=bucket, key_prefix=input_prefix)\n",
    "outputs = sagemaker_session.upload_data(path=output_dir, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fbaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_inputs= 's3://sagemaker-han-batch/batch-images/inference'\n",
    "inputs= 's3://sagemaker-han-batch/batch-images/inputs'\n",
    "outputs= 's3://sagemaker-han-batch/batch-images/outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5274c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 10:11:10 Starting - Starting the training job...ProfilerReport-1661163068: InProgress\n",
      "...\n",
      "2022-08-22 10:12:13 Starting - Preparing the instances for training....\n",
      "2022-08-22 10:21:55 Downloading - Downloading input data\n",
      "2022-08-22 10:21:55 Training - Training image download completed. Training in progress.\n",
      "2022-08-22 10:21:55 Uploading - Uploading generated training model\n",
      "2022-08-22 10:21:55 Completed - Training job completed\n",
      "ProfilerReport-1661163068: NoIssuesFound\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:29,984 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:29,987 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:29,997 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:30,010 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:30,909 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:30,924 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:30,945 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-08-22 10:15:30,962 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 128,\n",
      "        \"epochs\": 1,\n",
      "        \"lr\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m4.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-training-2022-08-22-10-11-04-812\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-10-11-04-812/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"resnet\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"resnet.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":128,\"epochs\":1,\"lr\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=resnet.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m4.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=resnet\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-10-11-04-812/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m4.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":128,\"epochs\":1,\"lr\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-training-2022-08-22-10-11-04-812\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-10-11-04-812/source/sourcedir.tar.gz\",\"module_name\":\"resnet\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"resnet.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"128\",\"--epochs\",\"1\",\"--lr\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220816-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 resnet.py --batch-size 128 --epochs 1 --lr 0.01\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:35.196 algo-1:28 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220816-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220816-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:36.050 algo-1:28 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:36.052 algo-1:28 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:36.052 algo-1:28 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:36.053 algo-1:28 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-08-22 10:15:36.053 algo-1:28 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/50000 (26%)] Loss: -15.599797\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [25600/50000 (51%)] Loss: -75.351624\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [38400/50000 (77%)] Loss: -376.315094\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:21:07,162 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:21:07,163 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-08-22 10:21:07,163 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 489\n",
      "Billable seconds: 489\n"
     ]
    }
   ],
   "source": [
    "# Create Training Container\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"resnet.py\",\n",
    "                    role=role,\n",
    "                    source_dir = \"src\",\n",
    "                    framework_version='1.12.0',\n",
    "                    py_version='py38',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'batch-size':128,\n",
    "                        'lr': 0.01,\n",
    "                        'epochs': 1,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1344bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "cifar10_predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.rand(1,3,32,32)\n",
    "test_output = cifar10_predictor.predict(test_input)\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0d0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "505a0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 's3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-11-21-23-382/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325866f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ea2048d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,604 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,754 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.6.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[34mMax heap size: 980 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.8\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 2\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mModel config: N/A\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,770 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,806 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,811 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,812 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,815 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:53,830 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,009 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,010 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,022 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,739 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,972 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,980 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.206241607666016|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,980 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.6588897705078125|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,982 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,983 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6763.2109375|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,984 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:702.5078125|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:54,985 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.9|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,639 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,642 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]55\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,650 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,666 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,727 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072815731\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:55,925 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,008 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,014 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]56\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,014 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,016 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,017 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,029 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,029 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072816029\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,115 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,650 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 709\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,651 [INFO ] W-9000-model_1.0 TS_METRICS - W-9000-model_1.0.ms:2829|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072816\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,652 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:212|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072816\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 581\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,695 [INFO ] W-9001-model_1.0 TS_METRICS - W-9001-model_1.0.ms:2870|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072816\u001b[0m\n",
      "\u001b[34m2022-08-21T09:06:56,697 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:87|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072816\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,558 [INFO ] pool-2-thread-3 ACCESS_LOG - /169.254.255.130:51142 \"GET /ping HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,559 [INFO ] pool-2-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,648 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:51156 \"GET /execution-parameters HTTP/1.1\" 404 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,649 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,821 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072822821\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,856 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,857 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 44\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,856 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:31.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4e019e5f-d360-4628-961b-6bb2fdd03dfb,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,858 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,859 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,859 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,974 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072822974\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,980 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,997 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,998 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 25\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,998 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,999 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:02,999 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,000 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.37|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b92d8bd5-c47f-4892-854e-a42f3d14d3e6,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,202 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823202\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,207 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,217 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.77|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3a8088d7-da15-457b-8733-0181030e6d47,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,217 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,218 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,218 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,219 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,219 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,293 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823293\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,294 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,311 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,312 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,313 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,314 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,317 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,318 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.32|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e19b33c3-add5-41da-a033-7323180c0cc7,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,433 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823433\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,449 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,450 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,450 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,451 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,451 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,452 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.13|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f69b2076-2d1d-419b-8550-11a7c311360d,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823553\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,555 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,569 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,569 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,570 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,570 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,571 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,572 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.35|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8e95b3dd-41ec-4d56-a464-8379839317f8,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823678\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,697 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4c2fa462-d4b8-468b-a7d4-fd4b52795bc2,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,697 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,698 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,699 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,699 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,702 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,814 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823814\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,816 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,833 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,836 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,837 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,837 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,838 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,842 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.9|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9cf02857-ae02-4c65-98bc-46c188c36e1b,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,911 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072823911\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,913 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,931 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,932 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,933 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,933 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,933 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:03,938 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ed688451-fa0e-4b55-9a49-bdd5a71e385a,timestamp:1661072823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,010 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824009\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,011 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,023 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,024 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,024 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,025 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,025 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,026 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.0|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:debc166b-f0f4-4cee-93b0-aff1a06f38ae,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,108 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824108\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,112 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,126 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,127 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,127 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,128 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,128 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,129 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.05|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:07ee70f8-115a-455d-8a63-43f249064c78,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,256 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824256\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,260 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,273 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,273 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,273 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.07|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9956acab-bee6-4775-a01c-08c68342f3c4,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,274 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,274 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,275 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,395 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824395\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,397 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,411 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,411 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bb241b10-75e1-4fc8-b359-59d0dc82b140,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,411 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,412 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,412 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,413 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,516 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824516\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,518 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,531 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,531 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.31|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:52ff427e-e2d8-4213-8359-9fccb9184cff,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,532 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,532 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,533 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,533 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,602 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824602\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,604 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,617 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bf41d181-d7cf-42e1-a649-541b457f561f,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,618 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,619 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,620 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,620 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824695\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,702 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,708 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,708 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,709 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,709 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3a086eb6-d8ad-45b9-9616-ee30bfb7dcbe,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,710 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,710 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,811 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824811\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,812 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,829 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.02|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a59407b-e514-4db8-9121-904a032e9ca9,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,829 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,830 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,830 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,830 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,830 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,905 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072824905\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,907 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,921 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,921 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.8|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dc4f077a-558c-4253-a6ba-999e5165d4ef,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,922 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,922 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,923 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:04,924 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072824\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,038 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825038\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,039 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,053 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,053 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2ad67328-9835-4982-809b-59df750bbc44,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,054 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,054 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,055 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,055 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,138 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825138\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,140 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,152 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,153 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,153 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.08|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1342711a-4252-4703-94e4-ea3ff4fb0cee,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,153 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,154 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,154 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,210 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825210\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,227 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,227 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,227 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,228 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,228 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,231 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.06|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:94fcfd4f-88a0-4c75-b9c7-4b9807edcff3,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,316 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825316\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,322 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,332 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,332 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b76a880d-9d85-4fd5-ae29-78bc940c904a,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,333 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,333 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,333 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,334 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,436 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825436\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,438 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,451 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,452 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7e075753-2cf7-4749-a92c-7d81ac76c274,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,452 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,453 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,453 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,454 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,547 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825547\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,548 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,564 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e5a9da9-3e33-4832-bdef-63e2fd99a988,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,566 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,566 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,566 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,566 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,566 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,620 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825620\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,624 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,635 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,636 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9f6a598c-42bf-4d73-8fd6-c2e4b469273e,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,636 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,636 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,637 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,637 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,693 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825692\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,696 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,704 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,704 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:9.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d08df7db-53ff-468e-ab7e-d7c5a291b924,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,705 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,705 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,705 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,705 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,762 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825762\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,763 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,777 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,778 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,778 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.23|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:72762305-f550-4023-ab74-5ef6101203bd,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,778 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,779 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,779 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,885 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072825885\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,889 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,900 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,901 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,901 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,900 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2894714a-0cb4-435b-824c-2074ce691aa2,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,902 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:05,903 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,009 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826009\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,013 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,026 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,026 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,027 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cba030e2-d3a6-4b61-b331-fd7e93772ca8,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,027 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,028 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,174 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826174\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,184 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,200 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,201 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,201 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,201 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.07|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5f705d2-5a98-499b-8fb3-e57d42ddf908,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,202 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,203 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826276\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,279 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,293 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,293 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,294 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,296 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,297 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f7da5370-6cae-4f9b-a9d5-64556286a56a,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,375 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826375\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,377 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,390 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,391 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,391 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,392 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,393 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,396 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.33|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:223fd158-adce-46ba-96a9-f32c01607c45,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,527 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826527\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,531 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,543 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,544 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,545 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,545 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,546 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,546 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b0677b0a-8c67-4d05-9603-459316fe97f0,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,676 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826676\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,682 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,693 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,694 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,694 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,694 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:85427ffc-48ff-47bc-a7fd-1882af6554e3,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,696 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,697 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-08-21T09:07:02.682:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,804 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826804\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,807 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,821 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b9a671c9-ca1c-441a-9577-0b8eb3f12313,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,821 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,822 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,940 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826940\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,943 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,958 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:06,962 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.09|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:676e82b2-dc64-47a6-b6db-b75eed719979,timestamp:1661072826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,050 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827050\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,053 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,067 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,067 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,070 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0a3880c6-89a9-4bcb-8309-76d980843a01,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,174 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827174\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,175 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,188 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,189 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,189 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b291c007-d184-43d4-81f3-4aaf61557b64,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,190 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,190 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,804 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826804\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,807 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,821 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b9a671c9-ca1c-441a-9577-0b8eb3f12313,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,821 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,822 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,824 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,940 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072826940\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,943 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,958 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,959 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:06,962 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.09|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:676e82b2-dc64-47a6-b6db-b75eed719979,timestamp:1661072826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,050 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827050\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,053 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,067 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,067 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,068 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,070 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0a3880c6-89a9-4bcb-8309-76d980843a01,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,174 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827174\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,175 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,188 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,189 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,189 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b291c007-d184-43d4-81f3-4aaf61557b64,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,190 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,190 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,302 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827302\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,308 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,316 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:95fcee67-3160-41a4-bf15-363f24f35f47,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,324 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,416 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827416\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,420 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,432 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,433 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,433 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:369ad40c-f5ce-4302-ae56-cd416bfa8c6b,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827532\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,534 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,546 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8ad5a0f8-468a-41e0-897f-ade99eed9b7f,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,641 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827641\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,644 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,654 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,655 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.21|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e9dbc1b5-3b6c-4538-8d3a-c7b7447c11ca,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,655 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,656 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,656 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,657 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,302 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827302\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,308 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,316 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:95fcee67-3160-41a4-bf15-363f24f35f47,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,324 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,325 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,416 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827416\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,420 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,432 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,433 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,433 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:369ad40c-f5ce-4302-ae56-cd416bfa8c6b,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,434 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827532\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,534 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,546 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8ad5a0f8-468a-41e0-897f-ade99eed9b7f,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,547 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,641 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827641\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,644 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,654 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,655 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.21|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e9dbc1b5-3b6c-4538-8d3a-c7b7447c11ca,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,655 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,656 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,656 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,657 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,755 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827755\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,755 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827755\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,756 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,768 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.26|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a300d456-5512-4c01-8d45-e9bf8ff8b53c,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,768 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,770 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,863 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827863\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,864 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,877 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,877 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bc1cdd0d-7532-4d17-afdc-7b578796ac74,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,879 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,970 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827970\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,971 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,984 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,984 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.12|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cef165fe-5718-49dc-a6d0-000099ba915e,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:07,986 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,086 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828086\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,756 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,768 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.26|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a300d456-5512-4c01-8d45-e9bf8ff8b53c,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,768 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,769 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,770 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,863 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827863\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,864 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,877 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,877 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bc1cdd0d-7532-4d17-afdc-7b578796ac74,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,878 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,879 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,970 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072827970\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,971 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,984 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,984 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.12|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cef165fe-5718-49dc-a6d0-000099ba915e,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,985 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:07,986 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072827\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,086 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828086\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,090 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,099 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.38|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f3073f9b-f7f7-446c-88eb-f84ce90b406c,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,101 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,102 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,163 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828163\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,165 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,178 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.81|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c67e2e6c-96db-4914-86de-598b88abc1f6,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,178 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,180 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,269 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828269\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,284 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:85cd2d4d-98e7-4084-aad9-f1edfe46b8a0,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,286 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,286 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,367 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828367\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,368 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.28|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5222704d-7808-493c-b127-0c9c07f4d4b2,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,480 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828480\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,482 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,090 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,099 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.38|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f3073f9b-f7f7-446c-88eb-f84ce90b406c,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,100 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,101 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,102 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,163 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828163\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,165 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,178 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.81|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c67e2e6c-96db-4914-86de-598b88abc1f6,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,178 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,180 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,269 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828269\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,284 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:85cd2d4d-98e7-4084-aad9-f1edfe46b8a0,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,285 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,286 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,286 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,367 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828367\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,368 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,382 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,383 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.28|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5222704d-7808-493c-b127-0c9c07f4d4b2,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,480 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828480\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,482 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca402550-d375-42a7-b0e4-aa2a89ae44e4,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca402550-d375-42a7-b0e4-aa2a89ae44e4,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,495 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,496 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,496 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,545 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828545\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,548 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,560 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,560 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.02|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad73a1f2-e274-439d-9d1c-4ce1553c1a93,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,561 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,561 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,562 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,562 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,666 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828666\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,668 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,679 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.81|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:055b6c95-3c71-4c6e-b34b-2b60fd2f123d,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,680 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,680 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,681 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,681 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,744 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828744\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,496 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,496 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,545 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828545\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,548 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,560 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,560 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.02|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad73a1f2-e274-439d-9d1c-4ce1553c1a93,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,561 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,561 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,562 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,562 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,666 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828666\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,668 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,679 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.81|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:055b6c95-3c71-4c6e-b34b-2b60fd2f123d,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,680 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,680 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,681 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,681 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,744 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828744\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,750 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,750 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.24|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3113b0a9-7710-418d-9a94-14de78582fd3,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 25\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,769 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,769 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,880 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828880\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,882 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e42ed074-0247-4da7-9ae1-ad9bade301c0,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.24|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3113b0a9-7710-418d-9a94-14de78582fd3,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 25\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,768 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,769 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,769 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,880 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828880\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,882 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e42ed074-0247-4da7-9ae1-ad9bade301c0,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,979 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828979\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,980 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.95|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8f050770-9e49-4b00-92fc-ab6c01f1645a,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:08,996 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,045 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829045\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,048 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,060 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,060 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dbb1ff89-98fb-4e8b-9f66-4fa4b790e22a,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,169 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829169\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,171 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,183 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,183 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e0261f2-8c92-4a11-a96d-0b2c961e7962,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,185 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,250 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829250\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,979 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072828979\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,980 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.95|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8f050770-9e49-4b00-92fc-ab6c01f1645a,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,995 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:08,996 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072828\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,045 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829045\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,048 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,060 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,060 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dbb1ff89-98fb-4e8b-9f66-4fa4b790e22a,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,061 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,169 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829169\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,171 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,183 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,183 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e0261f2-8c92-4a11-a96d-0b2c961e7962,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,184 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,185 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,250 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829250\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,265 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.27|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6175d5f-1d0b-4382-bfdf-0238bb7db61a,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,269 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,269 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,332 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829332\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.95|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:75f0b775-c646-4441-90e4-7614408adfc5,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,428 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829428\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,429 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,442 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4810a13d-8cab-4759-b5ed-334469ecba82,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,443 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,445 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,561 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829561\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,252 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,265 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.27|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6175d5f-1d0b-4382-bfdf-0238bb7db61a,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,268 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,269 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,269 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,332 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829332\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,348 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,347 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.95|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:75f0b775-c646-4441-90e4-7614408adfc5,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,428 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829428\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,429 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,442 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4810a13d-8cab-4759-b5ed-334469ecba82,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,443 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,444 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,445 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,561 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829561\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,562 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.33|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ba3110c-c0d8-4c9a-ad07-6dd5d5cd8184,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,577 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,577 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,639 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829639\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,641 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8cadf953-7bf3-45c5-a15e-da32eeb0aa13,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,655 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,655 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,747 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829747\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,749 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,562 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,576 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.33|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ba3110c-c0d8-4c9a-ad07-6dd5d5cd8184,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,577 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,577 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,639 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829639\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,641 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8cadf953-7bf3-45c5-a15e-da32eeb0aa13,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,654 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,655 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,655 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,747 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829747\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,749 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,761 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,761 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,763 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.17|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:490cba70-6718-432f-87e2-570151e9aaf7,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,831 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,833 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.01|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:efd7840a-a9fe-4987-ac2e-0b8a95a15ddc,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829908\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,909 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,922 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a4a72f0d-8a40-4925-9859-83514db4846f,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,972 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829972\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,973 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:70295bd9-88e8-4234-82a5-caa79ae1574b,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830072\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,073 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,087 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca0b6057-fda9-4b67-bfa2-eb95ca25c54c,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,164 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830164\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,165 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8946b5e1-b8c6-4efd-9f8a-09829b3b4ec9,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,178 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,178 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,283 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830283\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,284 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,297 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.16|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f1675ff-7a82-4e9c-bec5-c06a2ddefac8,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,762 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,763 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.17|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:490cba70-6718-432f-87e2-570151e9aaf7,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,831 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,833 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.01|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:efd7840a-a9fe-4987-ac2e-0b8a95a15ddc,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,845 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829908\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,909 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,922 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a4a72f0d-8a40-4925-9859-83514db4846f,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,923 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,972 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072829972\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,973 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,985 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:70295bd9-88e8-4234-82a5-caa79ae1574b,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:09,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830072\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,073 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,087 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca0b6057-fda9-4b67-bfa2-eb95ca25c54c,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,088 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,164 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830164\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,165 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,177 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8946b5e1-b8c6-4efd-9f8a-09829b3b4ec9,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,178 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,178 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,283 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830283\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,284 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,297 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.16|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f1675ff-7a82-4e9c-bec5-c06a2ddefac8,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,299 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,299 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,339 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830339\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,340 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,353 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d50c062b-61e2-45ba-a2a6-3b0547272a0a,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,355 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830409\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,420 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.12|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f077af0e-603d-4f32-b7dd-2253209ee464,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,422 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830502\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,504 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,518 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.13|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:06e58409-1d4a-4df9-ae76-07fc1c2b7c0a,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,518 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,582 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830582\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,596 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.11|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:671c0e3b-1510-4237-ad73-064ade02f8b0,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,596 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,598 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,656 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830656\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,658 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7c9147e9-6d4d-4b2f-80c7-ea994c9d2545,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,671 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,671 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,722 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830722\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,724 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,736 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.05|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2043c183-f4af-4c89-b64e-c61dbc3509c5,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,738 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,298 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,299 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,299 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,339 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830339\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,340 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,353 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d50c062b-61e2-45ba-a2a6-3b0547272a0a,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,354 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,355 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830409\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,420 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.12|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f077af0e-603d-4f32-b7dd-2253209ee464,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,421 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,422 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830502\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,504 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,518 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.13|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:06e58409-1d4a-4df9-ae76-07fc1c2b7c0a,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,518 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,519 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,582 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830582\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,596 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.11|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:671c0e3b-1510-4237-ad73-064ade02f8b0,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,596 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,597 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,598 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,656 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830656\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,658 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7c9147e9-6d4d-4b2f-80c7-ea994c9d2545,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,670 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,671 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,671 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,722 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830722\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,724 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,736 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.05|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2043c183-f4af-4c89-b64e-c61dbc3509c5,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,737 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,738 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830792\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,793 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.05|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:32fd6212-1ca7-41b1-acf6-9cdab4039d3e,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,897 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830897\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,898 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.33|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7f3b5a8a-c33c-49df-8261-49d79b6d577a,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830792\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,793 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.05|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:32fd6212-1ca7-41b1-acf6-9cdab4039d3e,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,804 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,897 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830897\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,898 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.33|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7f3b5a8a-c33c-49df-8261-49d79b6d577a,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,911 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830959\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,973 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b48c71c0-2fc8-4d58-9388-241c8fe00241,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:10,975 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,049 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831049\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,050 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.8|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3df9580c-131e-44ce-8ec3-c3e86b37c962,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,063 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,063 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,064 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831118\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,119 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,132 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a40c6794-bd5a-49d2-a278-b73b3fda69d9,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831229\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,230 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.01|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e7a39a22-7087-404e-b0d9-6d037137514c,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,912 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072830959\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,973 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b48c71c0-2fc8-4d58-9388-241c8fe00241,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,974 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:10,975 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072830\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,049 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831049\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,050 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,062 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.8|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3df9580c-131e-44ce-8ec3-c3e86b37c962,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,063 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,063 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,064 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831118\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,119 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,132 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a40c6794-bd5a-49d2-a278-b73b3fda69d9,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,133 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831229\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,230 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.01|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e7a39a22-7087-404e-b0d9-6d037137514c,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,242 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,242 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,350 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831350\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,351 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5c962e9e-06e4-4c74-8740-9f2abf1003ea,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,365 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,365 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,451 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831451\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,455 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,468 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84c38702-9c56-4d18-ad7d-f94fea7396f7,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,469 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,560 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831560\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,561 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,573 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6d8587bc-f923-4a67-a2ce-fca333b6adeb,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,574 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,241 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,242 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,242 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,350 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831350\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,351 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5c962e9e-06e4-4c74-8740-9f2abf1003ea,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,364 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,365 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,365 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,451 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831451\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,455 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,468 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84c38702-9c56-4d18-ad7d-f94fea7396f7,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,469 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,470 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,560 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831560\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,561 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,573 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6d8587bc-f923-4a67-a2ce-fca333b6adeb,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,574 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,576 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,656 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831655\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,659 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,671 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,671 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.18|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f675ec03-7aba-4b47-b485-e62a3b852160,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,751 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831750\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,753 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,575 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,576 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,656 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831655\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,659 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,671 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,671 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,672 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.18|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f675ec03-7aba-4b47-b485-e62a3b852160,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,751 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831750\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,753 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:52bbb09e-32d8-4368-b253-1ad152912d28,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,770 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,770 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,829 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831829\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,830 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a0612377-9e7e-4568-b7cd-893c73325e61,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,948 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831948\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,950 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,966 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:415c01a0-4e94-4504-b1b8-d3c4f977c401,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,966 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,967 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,967 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,968 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:11,968 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,034 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832034\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,035 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,048 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.35|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7b64b6af-7c48-4b70-850e-063fc9147735,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,050 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,105 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832105\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,108 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,121 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.16|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80c4198a-cec4-4474-9585-1578eb4bc722,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,121 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,122 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,122 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,123 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,123 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,173 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832173\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,174 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.32|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:50e60149-d1d4-4562-8236-78150aff3487,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,191 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,191 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,769 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:52bbb09e-32d8-4368-b253-1ad152912d28,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,770 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,770 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,829 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831829\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,830 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a0612377-9e7e-4568-b7cd-893c73325e61,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,844 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,845 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,948 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072831948\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,950 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,966 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:415c01a0-4e94-4504-b1b8-d3c4f977c401,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,966 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,967 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,967 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,968 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:11,968 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072831\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,034 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832034\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,035 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,048 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.35|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7b64b6af-7c48-4b70-850e-063fc9147735,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,049 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,050 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,105 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832105\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,108 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,121 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.16|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80c4198a-cec4-4474-9585-1578eb4bc722,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,121 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,122 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,122 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,123 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,123 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,173 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832173\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,174 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.32|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:50e60149-d1d4-4562-8236-78150aff3487,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,189 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,191 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,191 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,192 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832261\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,262 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,275 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c784d1c3-7ea7-40e2-b9d5-1f722f229814,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,277 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,277 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832363\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,389 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,390 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,390 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:25.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a0c9f3d1-fe3e-4827-82f9-523f54931207,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,449 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832449\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,450 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,462 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,462 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37edb32b-648a-406d-afb8-3b1cb0696bc8,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,464 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,513 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832513\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,515 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,528 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,528 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.23|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae038b23-e2bd-4f8c-92f5-98955f14bc99,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,530 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,581 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832581\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,582 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,593 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,593 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.77|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:009e6391-d77b-406a-87d5-3538e031cab4,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832679\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,680 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,192 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832261\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,262 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,275 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c784d1c3-7ea7-40e2-b9d5-1f722f229814,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,276 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,277 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,277 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832363\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,389 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,390 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,390 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:25.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a0c9f3d1-fe3e-4827-82f9-523f54931207,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,391 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,449 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832449\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,450 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,462 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,462 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37edb32b-648a-406d-afb8-3b1cb0696bc8,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,463 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,464 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,513 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832513\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,515 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,528 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,528 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.23|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae038b23-e2bd-4f8c-92f5-98955f14bc99,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,529 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,530 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,581 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832581\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,582 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,593 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,593 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.77|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:009e6391-d77b-406a-87d5-3538e031cab4,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,594 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832679\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,680 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,693 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f680c7f9-3212-4773-81b8-b0ff42ac74a6,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,693 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,742 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832742\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,746 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5187726-23ef-45f3-a289-4f1bec1d27f0,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,757 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,693 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f680c7f9-3212-4773-81b8-b0ff42ac74a6,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,693 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,694 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,742 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832742\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,746 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5187726-23ef-45f3-a289-4f1bec1d27f0,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,756 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,757 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: cannot identify image file <_io.BytesIO object at 0x7f2537d05e00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.090:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/0.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f2537d05e00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.131:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.131:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.133:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.133:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.133:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.133:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.134:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.134:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.134:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.134:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.134:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/1.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.194:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.194:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.194:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.196:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.196:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.196:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.197:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.197:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.197:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.197:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.198:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.198:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/10.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.249:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.249:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.249:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.250:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.250:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.250:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.250:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.250:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.251:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.251:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.251:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.251:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.251:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.252:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.252:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.252:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/11.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.296:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.298:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/12.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.347:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.348:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.348:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.348:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.348:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.349:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.349:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.349:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.349:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.349:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.350:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/13.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.405:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/14.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.457:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.458:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.458:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.458:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.458:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.458:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.459:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.459:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.459:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.459:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.459:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.460:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.460:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.460:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.460:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.460:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/15.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/16.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.598:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.598:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.598:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/17.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/18.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.682:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/19.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.731:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.731:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.731:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.731:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/2.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,810 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832810\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,811 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bc28257e-6f70-406e-a088-cdf7e2875684,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,810 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832810\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,811 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bc28257e-6f70-406e-a088-cdf7e2875684,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,825 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,826 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,886 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832886\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,887 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,898 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2fbaf09a-2618-4d14-97e2-3a88bb000d7f,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,898 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,900 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,977 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832977\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:12,978 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 500 28\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:25.78|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ebc119c-472d-4a65-99c7-51bf1f1e7e7f,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,006 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,006 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,023 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833023\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,024 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,048 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,049 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8fd3926c-21db-4c1c-9ac7-d131ca40cf5c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,049 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34448 \"POST /invocations HTTP/1.1\" 500 27\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,062 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833062\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,826 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,886 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832886\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,887 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,898 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2fbaf09a-2618-4d14-97e2-3a88bb000d7f,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,898 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,900 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,977 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072832977\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:12,978 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072832\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:51170 \"POST /invocations HTTP/1.1\" 500 28\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,005 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:25.78|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ebc119c-472d-4a65-99c7-51bf1f1e7e7f,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,006 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,006 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,023 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833023\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,024 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,048 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,049 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8fd3926c-21db-4c1c-9ac7-d131ca40cf5c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,049 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34448 \"POST /invocations HTTP/1.1\" 500 27\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,051 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,062 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833062\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,063 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b4bf43d0-6a04-4ed0-b8db-7380cd14e6eb,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34452 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,065 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,065 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833078\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,079 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:285aa44d-26b1-4d63-a618-12f46588346b,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34456 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,097 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833097\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,098 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa979911-a5f5-47e4-94e2-99e685f67f7e,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34468 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,100 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,100 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,063 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b4bf43d0-6a04-4ed0-b8db-7380cd14e6eb,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34452 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,064 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,065 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,065 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833078\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,079 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:285aa44d-26b1-4d63-a618-12f46588346b,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34456 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,097 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833097\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,098 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa979911-a5f5-47e4-94e2-99e685f67f7e,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34468 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,099 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,100 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,100 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,106 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833106\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,107 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6a83a53-e3a6-4062-9265-3c1ed0ec9a76,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34472 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,113 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833113\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,114 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,114 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dfcbdd8c-881b-47e9-9a36-bb85dd86b49a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,116 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,116 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,121 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833121\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,121 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34488 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80a3ebad-566b-4ecc-851d-1d046810d494,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833140\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,106 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833106\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,107 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6a83a53-e3a6-4062-9265-3c1ed0ec9a76,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34472 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,108 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,113 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833113\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,114 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,114 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dfcbdd8c-881b-47e9-9a36-bb85dd86b49a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,115 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,116 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,116 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,121 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833121\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,121 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34488 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,122 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,123 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80a3ebad-566b-4ecc-851d-1d046810d494,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833140\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93f65d8c-6b3f-44b3-be42-385389d98f8f,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,143 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,149 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833149\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,150 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8ca03ceb-274e-45ec-baba-18e40aac3a20,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34518 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,152 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833177\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34526 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bb0ff82f-27dc-443f-a122-092938200257,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,188 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833188\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,188 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,189 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,189 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,191 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7d1fcf3f-f171-43ca-a678-81d4c289a7d8,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93f65d8c-6b3f-44b3-be42-385389d98f8f,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,143 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,149 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833149\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,150 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8ca03ceb-274e-45ec-baba-18e40aac3a20,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34518 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,151 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,152 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833177\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34526 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,179 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bb0ff82f-27dc-443f-a122-092938200257,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,188 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833188\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,188 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,189 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,189 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,190 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,191 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7d1fcf3f-f171-43ca-a678-81d4c289a7d8,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,210 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833210\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:09df95c9-87da-4432-be65-3ae876761585,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34542 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,225 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833225\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,226 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0fa37e5a-9263-4003-99a5-3a9a92af97a1,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34550 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,228 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,228 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833234\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:42ff4c55-b55b-4518-a2d6-87b4da3f8c55,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34560 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,244 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833244\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,245 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,245 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34576 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a8d5d43b-27d0-4eb3-9de2-9f59b052fa38,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,257 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833257\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,210 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833210\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,212 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:09df95c9-87da-4432-be65-3ae876761585,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34542 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,213 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,225 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833225\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,226 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0fa37e5a-9263-4003-99a5-3a9a92af97a1,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34550 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,227 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,228 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,228 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833234\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:42ff4c55-b55b-4518-a2d6-87b4da3f8c55,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,236 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34560 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,244 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833244\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,245 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,245 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34576 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,246 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a8d5d43b-27d0-4eb3-9de2-9f59b052fa38,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,257 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833257\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b7581c15-8de6-41ed-8490-5d0b0a38b0dd,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34584 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833264\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,264 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,265 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,265 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34594 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,267 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93da6468-4e5f-4663-8e8c-c108fb000257,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,281 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833281\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,282 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ee92a868-b97a-458c-b286-90174011593f,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34608 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,284 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,284 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,290 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833290\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,293 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ea47f2ff-67ca-4533-b5ab-0bd68f720c0e,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34622 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,303 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833303\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,305 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b7581c15-8de6-41ed-8490-5d0b0a38b0dd,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,258 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34584 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,259 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833264\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,264 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,265 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,265 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34594 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,266 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,267 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93da6468-4e5f-4663-8e8c-c108fb000257,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,281 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833281\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,282 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ee92a868-b97a-458c-b286-90174011593f,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34608 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,283 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,284 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,284 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,290 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833290\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,293 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ea47f2ff-67ca-4533-b5ab-0bd68f720c0e,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34622 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,294 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,303 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833303\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,305 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5c171c4-a8e9-49b7-9eac-9e1f68f6edd0,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34626 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,307 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833314\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,314 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,315 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b12f7f21-9481-4ebf-b3a4-1d84171949c8,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,315 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34632 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833325\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,326 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34638 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c2e03b67-0fba-4f9f-a53c-bbddf2c68d66,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,339 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833339\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,341 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34652 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,343 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6bb505c4-ea83-4f3e-ba36-1fb12d1dda04,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5c171c4-a8e9-49b7-9eac-9e1f68f6edd0,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34626 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,306 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,307 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833314\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,314 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,315 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b12f7f21-9481-4ebf-b3a4-1d84171949c8,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,315 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34632 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,316 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833325\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,326 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34638 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c2e03b67-0fba-4f9f-a53c-bbddf2c68d66,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,329 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,339 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833339\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,341 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34652 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,342 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,343 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6bb505c4-ea83-4f3e-ba36-1fb12d1dda04,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833356\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,357 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e85a96c9-dddf-4838-8dba-e459e7dfe897,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,369 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833369\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,371 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,371 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f36bd6d8-3e33-493e-9c96-94c21fa13e7e,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34674 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833382\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,382 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,383 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3ceefd38-eeab-4a22-bc59-00e3d459e6fa,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,396 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833396\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:119a28d9-c160-4ea7-b5b5-5a03cbbb7fa0,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34694 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,402 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833409\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833356\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,357 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e85a96c9-dddf-4838-8dba-e459e7dfe897,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34664 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,358 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,369 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833369\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,371 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,371 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f36bd6d8-3e33-493e-9c96-94c21fa13e7e,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34674 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,372 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833382\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,382 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,383 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3ceefd38-eeab-4a22-bc59-00e3d459e6fa,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,384 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,396 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833396\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:119a28d9-c160-4ea7-b5b5-5a03cbbb7fa0,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,398 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34694 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,399 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,402 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833409\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34700 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:01e20ba4-dffd-467d-8a36-ed537d807e4c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,417 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833417\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,418 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:acbd5d26-e50f-404a-a12c-e0bbcc6ba7f7,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34712 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,420 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,420 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,425 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833425\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,426 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34716 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:432aa2c8-05b5-49e4-b61a-55423ec8564e,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,432 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,432 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,452 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833452\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34726 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0270cfd5-1197-41ec-8882-386c58377839,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,467 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833467\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34700 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,411 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:01e20ba4-dffd-467d-8a36-ed537d807e4c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,417 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833417\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,418 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:acbd5d26-e50f-404a-a12c-e0bbcc6ba7f7,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34712 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,419 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,420 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,420 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,425 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833425\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,426 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34716 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:432aa2c8-05b5-49e4-b61a-55423ec8564e,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,427 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,432 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,432 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,452 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833452\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34726 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0270cfd5-1197-41ec-8882-386c58377839,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,467 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833467\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,468 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34728 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6c5c9e91-003c-4428-8b68-44e83729cadf,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,470 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,471 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833482\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,486 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dc5b3007-deef-461c-a160-b31472669610,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833493\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,494 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f0a7288-8202-41a3-bd73-c4bfae2f4f61,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,496 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,496 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,501 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833501\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,501 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,468 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34728 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6c5c9e91-003c-4428-8b68-44e83729cadf,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,469 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,470 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,471 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833482\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,485 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,486 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dc5b3007-deef-461c-a160-b31472669610,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833493\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,494 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f0a7288-8202-41a3-bd73-c4bfae2f4f61,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,496 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,496 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,501 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833501\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,501 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6e83522c-0790-42ed-8fb0-3a1fd1d8d313,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,503 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,503 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,522 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833522\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,523 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,523 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34758 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,528 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e0013f8a-eae2-4450-a86b-a461575fafe1,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,543 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833543\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,552 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,552 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1fd1320-0ef0-426a-8917-dedda70e95cd,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34764 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,570 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833570\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,575 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:6.1|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:12a778c3-f00b-4461-a1ba-92916fa95f08,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34774 \"POST /invocations HTTP/1.1\" 500 11\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833588\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:29fc1f32-1c70-4a61-bbb3-569fe438c5f0,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,502 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6e83522c-0790-42ed-8fb0-3a1fd1d8d313,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,503 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,503 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,522 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833522\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,523 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,523 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34758 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,527 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,528 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e0013f8a-eae2-4450-a86b-a461575fafe1,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,543 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833543\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,552 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,552 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1fd1320-0ef0-426a-8917-dedda70e95cd,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34764 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,553 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,570 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833570\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,575 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:6.1|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:12a778c3-f00b-4461-a1ba-92916fa95f08,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34774 \"POST /invocations HTTP/1.1\" 500 11\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,581 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833588\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:29fc1f32-1c70-4a61-bbb3-569fe438c5f0,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,590 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34782 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,592 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833606\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,607 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,608 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,608 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34790 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,612 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:33d94585-0b79-46a8-a002-e8a39fc1e385,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,618 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833618\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,619 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c3f0053a-2614-4445-947f-2824aa578c9e,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34798 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,621 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,639 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833639\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,642 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34806 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,644 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,648 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e3b7e667-3b24-4fbd-822d-69bd0643f7d7,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,649 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833649\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34782 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,591 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,592 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833606\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,607 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,608 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,608 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34790 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,609 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,612 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:33d94585-0b79-46a8-a002-e8a39fc1e385,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,618 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833618\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,619 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c3f0053a-2614-4445-947f-2824aa578c9e,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34798 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,620 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,621 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,639 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833639\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,642 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34806 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,643 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,644 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,648 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e3b7e667-3b24-4fbd-822d-69bd0643f7d7,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,649 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833649\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34808 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:598227a6-e926-47dd-a2b6-f3edcab1e63b,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833658\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,659 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:43491989-335f-4022-8fc8-7cf785c25f10,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34822 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,664 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833664\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,665 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34836 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a2ad2190-f343-4036-8abc-22a289ca7d9d,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833670\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,671 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34852 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7bfe1896-97d4-44bc-8d6a-605a7ac1d46a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833678\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34808 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,650 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:598227a6-e926-47dd-a2b6-f3edcab1e63b,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,651 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833658\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,659 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:43491989-335f-4022-8fc8-7cf785c25f10,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34822 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,660 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,664 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833664\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,665 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34836 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a2ad2190-f343-4036-8abc-22a289ca7d9d,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833670\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,671 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34852 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,672 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7bfe1896-97d4-44bc-8d6a-605a7ac1d46a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833678\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34864 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3359bc14-1c81-4c02-94a3-45bb09a6dc9c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,684 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833684\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,685 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34874 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,687 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ab93065-fcbb-48bd-9874-8be7c0137615,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,691 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833691\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,692 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34890 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,694 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:19a0e55a-bb08-49a4-b150-2e613676aa39,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,698 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833698\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,699 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34898 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8c4af415-453c-44f2-a87d-af3d328a520c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,723 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833723\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,725 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,726 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:41f0b289-b9d2-4b85-abd1-1b818e2a743b,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34864 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,680 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3359bc14-1c81-4c02-94a3-45bb09a6dc9c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,684 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833684\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,685 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34874 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,686 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,687 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ab93065-fcbb-48bd-9874-8be7c0137615,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,691 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833691\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,692 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34890 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,693 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,694 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:19a0e55a-bb08-49a4-b150-2e613676aa39,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,698 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833698\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,699 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34898 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,700 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8c4af415-453c-44f2-a87d-af3d328a520c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,723 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833723\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,725 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,726 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.27|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:41f0b289-b9d2-4b85-abd1-1b818e2a743b,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34914 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833736\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34924 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,740 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62314c24-f384-4671-9a9b-0c4b5aa3bc6c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,760 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833760\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,761 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34932 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ec43ee3e-a4eb-423a-9a2f-6306b565b56a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34914 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,727 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833736\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34924 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,739 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,740 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.24|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62314c24-f384-4671-9a9b-0c4b5aa3bc6c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,760 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833760\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,761 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34932 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ec43ee3e-a4eb-423a-9a2f-6306b565b56a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,762 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.831:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.832:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/20.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/21.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.928:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/22.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.964:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.965:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.965:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.965:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.965:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.966:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.966:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.966:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.966:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.966:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.967:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.967:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.967:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.967:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.968:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:13.968:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/23.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.017:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.017:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.017:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.017:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.018:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.018:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.018:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.018:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.019:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.019:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.019:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.019:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/24.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.063:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.063:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.064:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.064:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.064:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.064:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.065:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.065:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.065:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.065:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.065:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.066:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.066:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.066:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.066:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.067:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/25.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.118:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.119:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.119:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.119:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.119:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.119:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/26.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.172:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.172:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.172:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.173:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.173:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.173:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.173:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.173:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.174:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/27.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.236:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.236:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.236:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.238:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.238:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.238:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/28.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.320:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.321:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/29.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.372:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.372:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.372:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.372:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.372:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.373:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.373:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.373:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.373:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.373:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.374:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.374:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.374:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.374:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.375:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.375:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/3.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.427:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/30.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.486:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/31.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.526:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.526:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.526:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.526:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.526:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/32.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/33.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.591:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/34.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.635:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/35.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.713:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.713:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.713:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.716:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.716:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.716:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.717:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.717:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.717:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.718:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/36.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,785 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833785\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,786 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,786 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7aafebcd-71c7-4a46-a222-7755df53c5b1,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,785 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833785\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,786 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,786 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7aafebcd-71c7-4a46-a222-7755df53c5b1,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34940 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,788 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,788 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,825 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833825\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,826 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34954 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34940 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,787 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,788 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,788 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,825 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833825\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,826 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34954 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cdeff95e-bbe2-47af-9d69-12e6c47e776b,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,828 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,838 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833838\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93e8ee91-a192-47f3-877d-7d30834027ad,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,827 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cdeff95e-bbe2-47af-9d69-12e6c47e776b,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,828 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,838 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833838\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93e8ee91-a192-47f3-877d-7d30834027ad,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34956 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833847\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,848 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,839 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34956 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,840 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833847\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,848 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:83f9f0f7-3f4a-4cd6-8c40-188827338f32,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34958 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,850 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,850 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,860 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833860\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,860 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:83f9f0f7-3f4a-4cd6-8c40-188827338f32,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34958 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,849 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,850 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,850 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,860 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833860\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,860 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34968 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dbbc1b86-16b7-475a-88cd-f204a8da0b4a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,873 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833873\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,874 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:68f41c03-b33f-4a01-a900-bc52f48a981c,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34968 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,861 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dbbc1b86-16b7-475a-88cd-f204a8da0b4a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,873 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833873\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,874 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:68f41c03-b33f-4a01-a900-bc52f48a981c,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34980 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,876 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833888\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34984 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,892 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b10a5fa5-9be5-4639-aaeb-3476394b352d,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,906 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833906\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b40b951b-cdfa-4f8a-88a2-8414481b014b,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34994 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34980 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,876 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833888\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:34984 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,890 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,892 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b10a5fa5-9be5-4639-aaeb-3476394b352d,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,906 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833906\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b40b951b-cdfa-4f8a-88a2-8414481b014b,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:34994 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,916 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833916\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,917 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35008 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,919 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:757c4d68-36f8-4011-b4bd-3b2e90efc27a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,924 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833924\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:00dd34f8-ec1f-4966-a9b7-12f9bfd1413a,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35012 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833932\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35018 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,934 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4769adfa-c479-442d-9e8c-d5ca6a7ca3a1,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,938 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833938\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:86a158fa-7feb-4007-812a-df9cb374eaa8,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35020 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,942 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833947\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,948 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,949 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,909 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,916 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833916\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,917 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35008 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,919 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:757c4d68-36f8-4011-b4bd-3b2e90efc27a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,924 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833924\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:00dd34f8-ec1f-4966-a9b7-12f9bfd1413a,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,925 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35012 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,926 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833932\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35018 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,933 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,934 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4769adfa-c479-442d-9e8c-d5ca6a7ca3a1,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,938 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833938\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:86a158fa-7feb-4007-812a-df9cb374eaa8,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,940 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35020 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,941 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,942 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833947\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,948 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,949 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35024 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,951 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2b328cc4-9307-474d-885a-b6f78c6cc676,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,957 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833957\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,958 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c207ebaa-d72d-4792-bd80-9e94d42fb1f1,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35040 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,960 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,974 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833974\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,975 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35048 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,977 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,977 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8233b34a-e0e1-4082-9d49-54f7ce4c5f92,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,983 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833983\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,984 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35052 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:40f1b9a4-63eb-4808-a46a-524d7dd21854,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833993\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,995 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,995 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35066 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,996 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,996 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,998 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:13,998 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:71bf6e2a-36c1-4e49-ac80-fd6eb51bdddb,timestamp:1661072833\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,010 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834010\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,010 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,011 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35074 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35024 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,950 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,951 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2b328cc4-9307-474d-885a-b6f78c6cc676,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,957 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833957\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,958 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c207ebaa-d72d-4792-bd80-9e94d42fb1f1,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35040 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,959 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,960 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,974 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833974\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,975 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35048 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,976 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,977 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,977 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8233b34a-e0e1-4082-9d49-54f7ce4c5f92,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,983 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833983\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,984 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35052 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,985 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:40f1b9a4-63eb-4808-a46a-524d7dd21854,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072833993\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,995 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,995 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35066 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,996 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,996 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,998 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:13,998 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:71bf6e2a-36c1-4e49-ac80-fd6eb51bdddb,timestamp:1661072833\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,010 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834010\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,010 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,011 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35074 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,013 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,013 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a660ec0c-d678-42ee-ba16-a9d32a23e2f9,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834025\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,026 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35080 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,028 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,028 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,029 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3c4e17eb-1ddf-4a14-814d-a839d793d5ad,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834035\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,036 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35090 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,038 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,038 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:164a1d35-79ce-4051-a5cd-30011c126565,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,045 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834045\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,046 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35102 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,048 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,048 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f59fcddd-e83d-4132-b9c1-210edf4f8e9c,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,056 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834056\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,057 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35108 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,012 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,013 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,013 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a660ec0c-d678-42ee-ba16-a9d32a23e2f9,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834025\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,026 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35080 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,027 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,028 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,028 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,029 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3c4e17eb-1ddf-4a14-814d-a839d793d5ad,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834035\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,036 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35090 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,037 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,038 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,038 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:164a1d35-79ce-4051-a5cd-30011c126565,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,045 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834045\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,046 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35102 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,047 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,048 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,048 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f59fcddd-e83d-4132-b9c1-210edf4f8e9c,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,056 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834056\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,057 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35108 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,059 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,059 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:869007f7-7b2c-4ccd-b90c-f10265b36c11,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,073 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834073\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,074 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,075 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35120 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,077 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,077 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:113df851-23fe-496d-b077-020229ff766e,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,084 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834084\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,085 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,085 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35126 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,087 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,088 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f5ccc0c2-1d0c-463a-92da-c08c78e63e9d,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,101 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834101\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,103 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35142 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,105 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,105 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f9fe448-1813-42de-b908-338d92504a13,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,112 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834112\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,113 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,058 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,059 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,059 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:869007f7-7b2c-4ccd-b90c-f10265b36c11,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,073 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834073\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,074 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,075 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35120 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,076 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,077 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,077 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:113df851-23fe-496d-b077-020229ff766e,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,084 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834084\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,085 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,085 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35126 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,086 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,087 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,088 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f5ccc0c2-1d0c-463a-92da-c08c78e63e9d,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,101 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834101\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,103 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35142 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,104 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,105 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,105 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f9fe448-1813-42de-b908-338d92504a13,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,112 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834112\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,113 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,113 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35148 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,115 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,115 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1b0909e9-fb94-46c9-8237-a9a437dd9403,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,129 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834129\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,130 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,131 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,131 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35164 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,133 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:de312d8a-e36f-44a6-8138-0a5030b85d79,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834140\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,141 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35174 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,113 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35148 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,114 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,115 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,115 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1b0909e9-fb94-46c9-8237-a9a437dd9403,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,129 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834129\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,130 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,131 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,131 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35164 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,132 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,133 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:de312d8a-e36f-44a6-8138-0a5030b85d79,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834140\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,141 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35174 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,142 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,144 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,144 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4d80274b-cc4c-4be3-849f-586084c8cdb0,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,152 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834152\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,153 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,154 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,154 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35190 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,156 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5be6336a-0473-4905-8aa6-8b989b31bf77,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834163\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,164 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35194 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,144 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,144 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4d80274b-cc4c-4be3-849f-586084c8cdb0,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,152 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834152\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,153 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,154 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,154 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35190 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,155 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,156 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5be6336a-0473-4905-8aa6-8b989b31bf77,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834163\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,164 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35194 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,165 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,166 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,166 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d1383774-5a30-434a-8c1e-b078e39387a8,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,179 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834179\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,181 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,181 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35208 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,166 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,166 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d1383774-5a30-434a-8c1e-b078e39387a8,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,179 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834179\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,181 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,181 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35208 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,182 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,185 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6e8a0ac4-932a-428a-be88-045ccdd4af17,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834192\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,194 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,194 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35224 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:77c51df2-cc93-4432-ab45-bb2ee65ba51b,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834211\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35238 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,185 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6e8a0ac4-932a-428a-be88-045ccdd4af17,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834192\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,194 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,194 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35224 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,197 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:77c51df2-cc93-4432-ab45-bb2ee65ba51b,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834211\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35238 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,215 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,215 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.79|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:612e0448-adf6-4bd3-99c5-fa4f1ebac274,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834226\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35240 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,215 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,215 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.79|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:612e0448-adf6-4bd3-99c5-fa4f1ebac274,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834226\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35240 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,229 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,229 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,231 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,231 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:89a0f430-3722-4db3-aa76-99f8d82dd737,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,244 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834244\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,246 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ecf6d7cd-c7da-4c8e-9fcc-3159865981b5,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35252 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,248 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,228 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,229 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,229 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,231 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,231 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:89a0f430-3722-4db3-aa76-99f8d82dd737,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,244 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834244\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,246 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ecf6d7cd-c7da-4c8e-9fcc-3159865981b5,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35252 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,247 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,248 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834261\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,263 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35266 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,265 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,269 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:52599c7e-cd53-477d-80dd-142ae6f3173c,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,291 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834291\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:849d834b-149d-4d63-84ae-6c370a5f9dad,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35278 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,295 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,310 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834310\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,311 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35280 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834261\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,263 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35266 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,264 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,265 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,269 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:52599c7e-cd53-477d-80dd-142ae6f3173c,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,291 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834291\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:849d834b-149d-4d63-84ae-6c370a5f9dad,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35278 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,294 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,295 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,310 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834310\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,311 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35280 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,312 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,313 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,325 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,325 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4530a598-da36-4125-bfb2-027588082d98,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,329 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834329\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:96787f45-4842-4880-999e-84408e326907,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35282 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,332 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,332 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,341 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834341\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,342 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,342 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5866f91f-d7c2-4a57-8471-de0d23541e32,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35290 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,313 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,325 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,325 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4530a598-da36-4125-bfb2-027588082d98,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,329 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834329\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:96787f45-4842-4880-999e-84408e326907,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35282 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,331 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,332 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,332 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,341 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834341\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,342 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,342 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5866f91f-d7c2-4a57-8471-de0d23541e32,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35290 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,344 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,349 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834349\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,353 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,353 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35294 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:22e7f52e-ff89-4ce2-a32f-55e73002230c,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,355 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,355 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,364 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834364\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,365 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bdcfed32-d584-4f56-a163-bb1f42a7ee81,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35300 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,343 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,344 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,349 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834349\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,353 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,353 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35294 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:22e7f52e-ff89-4ce2-a32f-55e73002230c,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,354 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,355 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,355 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,364 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834364\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,365 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bdcfed32-d584-4f56-a163-bb1f42a7ee81,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35300 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,379 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834379\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,380 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0fcf28a5-80cf-494a-a8a6-52ca1c73837b,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35304 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,382 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,382 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,388 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834388\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,389 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,390 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8857098a-4056-4229-bda4-756a2a08f966,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,390 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35318 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,366 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,379 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834379\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,380 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0fcf28a5-80cf-494a-a8a6-52ca1c73837b,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35304 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,381 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,382 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,382 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,388 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834388\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,389 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,390 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8857098a-4056-4229-bda4-756a2a08f966,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,390 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35318 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,404 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834404\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,405 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:90c28274-de4c-4247-a541-2e5be00c21f3,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35334 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,416 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834416\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,417 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:913c3021-5536-4082-9742-690f31035a46,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,419 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,419 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834432\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,433 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b4f9410b-d6ed-4a18-aaa7-fb0ebf58911a,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35358 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,435 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834454\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,454 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2cb9f0cb-e6e1-4779-917d-1c064ee6f3b6,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,391 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,404 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834404\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,405 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:90c28274-de4c-4247-a541-2e5be00c21f3,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35334 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,406 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,416 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834416\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,417 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:913c3021-5536-4082-9742-690f31035a46,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,418 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,419 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,419 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834432\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,433 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b4f9410b-d6ed-4a18-aaa7-fb0ebf58911a,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35358 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,434 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,435 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834454\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,454 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.74|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2cb9f0cb-e6e1-4779-917d-1c064ee6f3b6,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35364 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834471\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35370 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,474 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,474 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,475 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f0d2f5aa-81b2-4cec-9470-a272ab343db2,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,482 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834482\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35364 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,456 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834471\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35370 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,473 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,474 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,474 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,475 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f0d2f5aa-81b2-4cec-9470-a272ab343db2,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,482 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834482\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35374 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6f63dbc7-03c4-49d8-953e-db71aebd6ebb,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834493\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,493 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35382 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,496 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8854104d-1a03-4cb4-98ed-78ab1f536fb8,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834502\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,503 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf64bc90-b528-47b0-b2ec-6438e34501b4,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35388 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,511 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834511\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35402 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:25580ffc-f3ca-43de-9f21-c40fb737451a,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35374 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,483 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,484 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6f63dbc7-03c4-49d8-953e-db71aebd6ebb,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834493\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,493 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35382 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,495 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,496 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8854104d-1a03-4cb4-98ed-78ab1f536fb8,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,502 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834502\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,503 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf64bc90-b528-47b0-b2ec-6438e34501b4,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,504 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35388 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,505 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,511 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834511\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35402 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,512 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:25580ffc-f3ca-43de-9f21-c40fb737451a,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,513 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,519 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834519\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0231b118-d5a9-424a-ad57-60375c5894dd,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35410 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,522 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,522 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834530\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,531 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,519 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834519\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0231b118-d5a9-424a-ad57-60375c5894dd,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35410 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,521 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,522 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,522 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834530\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,531 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35426 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,533 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5b42d526-f70f-40fc-98cf-6605972008ce,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834539\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,540 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35436 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,542 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,542 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,543 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad61943b-976e-4be1-95c6-e891c6fbbad5,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,548 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834548\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,549 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35426 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,532 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,533 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5b42d526-f70f-40fc-98cf-6605972008ce,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834539\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,540 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35436 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,541 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,542 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,542 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,543 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad61943b-976e-4be1-95c6-e891c6fbbad5,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,548 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834548\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,549 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,551 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2b562a4a-c88b-478e-a218-0e2e111dde5b,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,558 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834558\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,558 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,559 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,559 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,561 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa3f91ea-fad2-4ab5-af3b-4eb534003fde,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,566 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834566\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,568 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,568 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35470 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,570 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1669cf7e-dc6a-4ac7-9221-f1d3082bb2cf,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,574 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834574\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,574 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35478 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,550 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,551 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2b562a4a-c88b-478e-a218-0e2e111dde5b,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,558 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834558\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,558 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,559 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,559 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,560 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,561 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa3f91ea-fad2-4ab5-af3b-4eb534003fde,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,566 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834566\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,568 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,568 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35470 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,569 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,570 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1669cf7e-dc6a-4ac7-9221-f1d3082bb2cf,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,574 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834574\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,574 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35478 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,575 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:50138aad-0ab7-49d7-8a16-cbe3fd1cdf4d,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,580 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834580\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35488 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0cc131ca-fe16-419d-ae05-d35aece46f45,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834587\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,587 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35498 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,589 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,589 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,591 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:796cf055-ba6e-4d8c-9175-fd496446acdd,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,594 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834594\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35512 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,597 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,598 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:04d89d0d-df99-49e4-8cce-093ca1553d24,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834602\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,576 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:50138aad-0ab7-49d7-8a16-cbe3fd1cdf4d,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,580 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834580\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,581 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35488 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,582 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0cc131ca-fe16-419d-ae05-d35aece46f45,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834587\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,587 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35498 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,588 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,589 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,589 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,591 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:796cf055-ba6e-4d8c-9175-fd496446acdd,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,594 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834594\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35512 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,596 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,597 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,598 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:04d89d0d-df99-49e4-8cce-093ca1553d24,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834602\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35524 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,605 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a610448-ddd7-4d6d-9229-eba00de0a6f6,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,608 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834608\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,609 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,611 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1b9f084b-7f10-4df9-abbc-0b345e52dcfe,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834615\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,616 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35546 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,618 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e191da6-7d18-41d7-a0ab-f0732ffed525,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,640 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834640\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9f675440-639b-4284-ad14-7bcdd60cb814,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35558 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,603 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35524 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,604 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,605 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a610448-ddd7-4d6d-9229-eba00de0a6f6,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,608 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834608\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,609 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,610 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,611 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1b9f084b-7f10-4df9-abbc-0b345e52dcfe,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834615\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,616 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35546 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,617 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,618 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e191da6-7d18-41d7-a0ab-f0732ffed525,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,640 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834640\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,641 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9f675440-639b-4284-ad14-7bcdd60cb814,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35558 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,643 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834650\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,650 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,651 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c8f1d5c9-6d9d-4594-81f6-6b5f6641f800,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,651 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35564 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,658 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834658\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,659 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bed8259d-86ac-489d-981c-c358bd66a536,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,661 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,674 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834674\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ac27144-e0b0-443a-8eb7-b63e886cb5c9,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35582 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,734 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834734\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,735 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,642 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,643 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834650\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,650 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,651 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c8f1d5c9-6d9d-4594-81f6-6b5f6641f800,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,651 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35564 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,652 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,658 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834658\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,659 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bed8259d-86ac-489d-981c-c358bd66a536,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,660 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,661 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,674 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834674\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ac27144-e0b0-443a-8eb7-b63e886cb5c9,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,675 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35582 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,676 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,734 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834734\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,735 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35586 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,737 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,737 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,738 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5df9394-a636-4045-8b31-6455a971cc6e,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,750 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834750\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,751 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35596 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c6d9018a-2b4d-4038-b042-f4fdd4b5cdb2,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,764 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834764\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35610 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,768 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37806882-d7f9-4774-b1d9-b3b29b4212f2,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834776\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,777 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e018b792-a343-4007-bcd8-3f9966418099,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35616 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35586 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,736 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,737 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,737 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,738 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5df9394-a636-4045-8b31-6455a971cc6e,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,750 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834750\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,751 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35596 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,753 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,752 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c6d9018a-2b4d-4038-b042-f4fdd4b5cdb2,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,764 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834764\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35610 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,766 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,768 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,769 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37806882-d7f9-4774-b1d9-b3b29b4212f2,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834776\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,777 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e018b792-a343-4007-bcd8-3f9966418099,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35616 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,779 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834796\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,797 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,797 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8722071c-b6c6-4029-b01b-7c8b9d2508a3,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834805\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84e7291b-2d88-40c1-b1d0-49b1ea4a80f2,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35628 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,808 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,808 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,779 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834796\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,797 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,797 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8722071c-b6c6-4029-b01b-7c8b9d2508a3,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,798 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834805\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84e7291b-2d88-40c1-b1d0-49b1ea4a80f2,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35628 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,807 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,808 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,808 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.784:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.784:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.784:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.784:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.785:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.785:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.785:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.785:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.785:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.786:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.786:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.786:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.786:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.787:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.787:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.787:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/37.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.847:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.847:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/38.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.886:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.886:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.887:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.887:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.887:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.887:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.888:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.888:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.888:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:     data = self._input_fn(input_data, content_type)\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T09:07:14.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.891:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.891:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.891:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.891:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/39.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.941:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.941:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.942:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.942:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.942:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.942:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.943:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.943:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.943:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.943:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.944:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.944:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.944:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.945:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.945:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:14.945:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/4.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.025:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/40.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/41.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.169:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/42.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.245:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.246:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.246:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.246:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.246:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/43.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.299:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/44.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.446:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/45.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.503:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.503:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.503:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.504:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.504:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.504:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.505:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.505:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.505:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.505:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.506:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.506:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.506:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.507:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.507:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.507:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/46.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.551:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.551:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.552:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.552:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.552:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.552:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.554:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.554:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.554:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.554:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.555:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.555:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.555:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.555:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.556:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.556:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/47.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.592:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.593:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.593:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.593:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.593:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.594:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.594:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.594:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.594:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/48.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.651:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.651:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.652:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.652:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.652:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.652:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.652:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.653:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.654:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.654:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.654:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/49.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/5.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.744:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.744:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.744:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.745:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/50.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,826 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834826\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35634 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5b26835a-871c-47f2-8d5a-ced23c2f8333,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,830 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,836 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d8f0c688-e26a-4927-9024-d233fe3b1ccf,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35636 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,840 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834853\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:13441195-9083-4148-81e7-75bcbe78cc98,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,856 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35652 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,856 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,857 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,857 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,862 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834862\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6056288f-d14b-48df-8042-9244f6339cbb,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35656 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,870 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834870\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,826 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834826\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35634 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,828 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5b26835a-871c-47f2-8d5a-ced23c2f8333,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,829 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,830 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,836 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d8f0c688-e26a-4927-9024-d233fe3b1ccf,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,838 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35636 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,839 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,840 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834853\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:13441195-9083-4148-81e7-75bcbe78cc98,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,856 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35652 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,856 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,857 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,857 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,862 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834862\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6056288f-d14b-48df-8042-9244f6339cbb,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,864 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35656 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,865 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,870 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834870\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:764cd206-b178-4560-8a59-0be3dba19950,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35658 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,874 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,880 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834880\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,881 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:33bfe34b-9afd-434c-8566-580797ad6ea3,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35668 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,883 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,883 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,897 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834897\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,897 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:94646fb7-5e2f-410c-9b4e-eb5f601dcf82,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,900 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834906\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,907 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1fc7f672-90d1-4961-a0ff-24aa6fed3b5c,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35680 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,910 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,910 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,920 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834920\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,921 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e78c5fc9-3ab7-4109-a7dc-07670f415a7d,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35684 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,925 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,925 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834932\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,933 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b1ff4d00-cce4-4c00-a331-af8e7fb8c610,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:764cd206-b178-4560-8a59-0be3dba19950,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,872 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35658 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,873 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,874 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,880 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834880\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,881 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:33bfe34b-9afd-434c-8566-580797ad6ea3,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35668 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,882 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,883 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,883 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,897 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834897\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,897 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:94646fb7-5e2f-410c-9b4e-eb5f601dcf82,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,900 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834906\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,907 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1fc7f672-90d1-4961-a0ff-24aa6fed3b5c,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35680 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,908 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,910 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,910 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,920 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834920\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,921 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e78c5fc9-3ab7-4109-a7dc-07670f415a7d,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35684 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,923 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,925 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,925 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834932\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,933 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b1ff4d00-cce4-4c00-a331-af8e7fb8c610,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35692 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,935 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,935 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,951 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834951\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,955 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:88299297-4d59-4247-885c-ffaefd736ccb,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,976 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834976\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35692 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,935 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,935 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,951 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834951\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,953 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,954 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,955 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.15|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:88299297-4d59-4247-885c-ffaefd736ccb,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,976 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072834976\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,977 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,978 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35710 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:38b70d0f-9dcb-4a72-812e-3a33da614ffa,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,980 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:14,980 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,000 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835000\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,001 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35714 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,003 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9d8f3999-7e5d-4d4c-8f28-71c7c792a27c,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835015\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,977 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,978 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35710 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,979 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:38b70d0f-9dcb-4a72-812e-3a33da614ffa,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,980 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:14,980 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072834\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,000 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835000\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,001 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35714 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,002 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,003 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9d8f3999-7e5d-4d4c-8f28-71c7c792a27c,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835015\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,015 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,016 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,017 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35724 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,017 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c0724673-0f75-4d22-aa41-b7985029f336,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,031 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835031\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,032 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:61e74d1c-45e5-47be-9ec6-4cb924b60b52,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,046 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835046\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,047 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,048 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,049 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35752 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1e2b1a29-fb31-43b2-8a7e-4432fe565ae1,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,066 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835066\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,067 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35760 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,015 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,016 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,017 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35724 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,017 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,018 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c0724673-0f75-4d22-aa41-b7985029f336,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,031 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835031\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,032 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,033 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,034 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:61e74d1c-45e5-47be-9ec6-4cb924b60b52,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,046 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835046\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,047 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,048 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,049 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35752 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,052 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1e2b1a29-fb31-43b2-8a7e-4432fe565ae1,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,066 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835066\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,067 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35760 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,068 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:004ff258-3741-49f5-808f-b90c97c2516e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,082 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835082\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,084 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,084 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:99f64b8d-1074-42a8-9b1e-c7b42b44b553,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35764 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,086 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,086 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,107 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835107\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,108 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,109 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:86b45d85-0d28-4e12-b9de-d7d967cda1b0,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,109 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35776 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835122\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,123 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,123 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4d5a794e-1d53-4518-9a6f-4f69c526c415,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35788 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,125 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835141\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,143 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,143 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35790 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:662f17c9-5886-4806-a991-3ff13859a6dc,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,069 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:004ff258-3741-49f5-808f-b90c97c2516e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,082 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835082\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,084 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,084 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:99f64b8d-1074-42a8-9b1e-c7b42b44b553,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35764 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,085 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,086 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,086 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,107 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835107\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,108 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,109 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:86b45d85-0d28-4e12-b9de-d7d967cda1b0,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,109 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35776 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,110 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835122\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,123 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,123 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4d5a794e-1d53-4518-9a6f-4f69c526c415,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35788 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,124 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,125 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835141\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,143 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,143 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35790 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:662f17c9-5886-4806-a991-3ff13859a6dc,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,144 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,145 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,145 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,162 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835162\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35802 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:71d75d5a-6b20-4699-a419-fc77f5bc4683,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,178 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835178\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,179 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:af198189-7c56-4b30-ac8c-80fc5e7d2c76,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35812 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,190 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835190\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8d7ef763-2962-47b6-b0cf-25f1ffff5524,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35824 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835211\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b79a27a8-85ac-4650-8ae0-36c13bd45f53,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35832 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,145 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,145 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,162 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835162\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35802 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,164 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,163 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:71d75d5a-6b20-4699-a419-fc77f5bc4683,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,178 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835178\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,179 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:af198189-7c56-4b30-ac8c-80fc5e7d2c76,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35812 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,190 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835190\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8d7ef763-2962-47b6-b0cf-25f1ffff5524,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,191 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35824 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835211\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,212 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b79a27a8-85ac-4650-8ae0-36c13bd45f53,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,213 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35832 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,237 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835237\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,238 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:502a7def-2002-4922-ba50-34704fdedc8e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35848 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835249\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad82ef86-4728-4297-a09c-442e01befd38,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35854 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,263 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835263\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,265 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d74dee36-5aa1-4da7-986e-3b51a864a474,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35864 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,267 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,277 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835277\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:54c0e6f8-f65a-4115-806a-10616a20b4e6,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,214 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,237 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835237\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,238 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:502a7def-2002-4922-ba50-34704fdedc8e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,239 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35848 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,240 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835249\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ad82ef86-4728-4297-a09c-442e01befd38,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,251 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35854 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,252 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,263 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835263\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,265 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d74dee36-5aa1-4da7-986e-3b51a864a474,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35864 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,266 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,267 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,277 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835277\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:54c0e6f8-f65a-4115-806a-10616a20b4e6,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35874 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,281 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,290 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835290\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,291 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,291 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5bdf4b9d-277e-41f3-9f21-2a0b44cd8bca,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35888 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,293 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835305\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35904 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c761e60b-cfa4-4ca6-acfb-debd6bd88154,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,319 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835319\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,320 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35914 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,322 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,322 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,323 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98a197aa-31f3-4281-8c92-58f5ce9dae8f,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,333 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835333\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,279 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35874 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,280 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,281 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,290 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835290\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,291 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,291 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5bdf4b9d-277e-41f3-9f21-2a0b44cd8bca,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35888 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,292 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,293 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835305\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35904 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c761e60b-cfa4-4ca6-acfb-debd6bd88154,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,319 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835319\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,320 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35914 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,321 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,322 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,322 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,323 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98a197aa-31f3-4281-8c92-58f5ce9dae8f,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,333 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835333\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35928 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6db2c4ae-1f4d-4c1a-96ff-15b7fe90e488,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835438\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,439 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ea05d34-565f-4bb6-95ff-170f4615258e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35940 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,441 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,450 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835450\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,451 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,451 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:59ed3296-3acd-4e01-b0b1-2703bbb50a00,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35956 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,465 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835465\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,466 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.98|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:048073bd-70c9-460e-9ab0-bbbbc89b05fc,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35964 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,476 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835476\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ed906cf-3c90-453f-be71-1e90e1424442,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35980 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35928 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,334 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,335 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6db2c4ae-1f4d-4c1a-96ff-15b7fe90e488,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835438\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,439 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6ea05d34-565f-4bb6-95ff-170f4615258e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35940 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,440 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,441 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,450 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835450\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,451 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,451 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:59ed3296-3acd-4e01-b0b1-2703bbb50a00,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35956 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,452 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,465 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835465\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,466 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.98|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:048073bd-70c9-460e-9ab0-bbbbc89b05fc,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,467 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35964 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,468 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,476 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835476\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ed906cf-3c90-453f-be71-1e90e1424442,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,478 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:35980 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835493\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,494 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,494 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35996 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,496 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,497 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7c520547-4bb5-4945-9143-e862437a657c,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,514 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835514\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36010 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,517 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,517 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,518 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,518 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:251f7855-a7e2-488a-be02-95da92151d19,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,525 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835525\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,525 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,526 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36014 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,529 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,530 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0692bbae-c2be-438e-9dda-6a4a6127d99f,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835536\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,537 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,538 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36024 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,540 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,540 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b91643da-55b1-4aa9-9e50-c5fd7dd347e3,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835546\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,546 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,547 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,547 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36036 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,549 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eda23187-ddb3-4654-83b8-c33555f62d89,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,561 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835561\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,562 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36042 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,479 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835493\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,494 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,494 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:35996 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,495 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,496 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,497 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7c520547-4bb5-4945-9143-e862437a657c,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,514 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835514\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,516 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36010 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,517 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,517 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,518 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,518 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:251f7855-a7e2-488a-be02-95da92151d19,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,525 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835525\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,525 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,526 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36014 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,527 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,529 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,530 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0692bbae-c2be-438e-9dda-6a4a6127d99f,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835536\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,537 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,538 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36024 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,539 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,540 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,540 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b91643da-55b1-4aa9-9e50-c5fd7dd347e3,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835546\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,546 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,547 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,547 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36036 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,548 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,549 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eda23187-ddb3-4654-83b8-c33555f62d89,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,561 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835561\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,562 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36042 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:194b9e24-0b60-4fbe-bbe5-d4156a3b9681,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,570 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835570\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,571 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36048 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,573 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,573 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9f1e4fae-5542-4837-986b-86e9c87989a5,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,578 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835578\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,579 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36058 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,581 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,581 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da411fbf-6409-4739-bbca-bb3cf3c6f212,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,586 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835586\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,587 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36068 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:967ccf4e-bd79-4a13-b7b4-e1c68b41733a,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,601 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835601\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,601 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36070 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,604 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3675816f-3408-454d-9d0f-ebe6f9405eb5,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835617\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,619 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36084 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7758b330-2218-4000-9ab9-03831e82a3cd,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,636 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835636\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,637 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:44759719-86dc-4f15-9101-bcc7ba1caf2b,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,563 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,564 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:194b9e24-0b60-4fbe-bbe5-d4156a3b9681,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,570 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835570\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,571 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36048 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,572 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,573 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,573 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9f1e4fae-5542-4837-986b-86e9c87989a5,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,578 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835578\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,579 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36058 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,580 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,581 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,581 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da411fbf-6409-4739-bbca-bb3cf3c6f212,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,586 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835586\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,587 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36068 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,588 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,589 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:967ccf4e-bd79-4a13-b7b4-e1c68b41733a,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,601 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835601\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,601 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36070 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,603 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,604 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3675816f-3408-454d-9d0f-ebe6f9405eb5,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835617\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,619 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36084 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,620 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7758b330-2218-4000-9ab9-03831e82a3cd,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,636 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835636\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,637 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:44759719-86dc-4f15-9101-bcc7ba1caf2b,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36100 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,639 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,639 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,646 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835646\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36110 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c7efa813-8cc7-44b9-b7b3-b04bcbc9d60e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835660\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,661 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8fb0cdcf-a943-4537-8ffa-32444586f5a3,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36114 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,677 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835677\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,678 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,678 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5a9c1ed3-0cb3-4715-83b6-c8f18676dd1e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36130 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,685 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835685\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,686 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,687 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f94084fb-9aa5-49a9-a356-518a436d5f3a,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36140 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,694 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835694\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f9fad2a6-7053-44ab-b09b-56bfe317e2fe,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36146 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,708 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835708\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36158 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36100 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,638 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,639 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,639 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,646 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835646\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36110 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c7efa813-8cc7-44b9-b7b3-b04bcbc9d60e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,648 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835660\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,661 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8fb0cdcf-a943-4537-8ffa-32444586f5a3,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36114 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,662 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,677 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835677\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,678 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,678 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5a9c1ed3-0cb3-4715-83b6-c8f18676dd1e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36130 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,679 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,685 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835685\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,686 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,687 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f94084fb-9aa5-49a9-a356-518a436d5f3a,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36140 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,688 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,694 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835694\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f9fad2a6-7053-44ab-b09b-56bfe317e2fe,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36146 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,696 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,708 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835708\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,709 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36158 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ce598e15-4705-4959-9f1c-86c194d54ced,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835719\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fd599c2d-8b03-4f09-b7bb-625b37324af4,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36172 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,728 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835728\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,729 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98d8e341-2bfd-43dc-9864-b1fa19ef56ec,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,737 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835737\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,739 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:74a2ea5a-5a01-4af2-86b3-9fd199dc74cf,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36184 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,741 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,749 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835749\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,750 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,751 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36192 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,752 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,752 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e5365e2-8e57-41f5-9229-ce52546ecd19,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,756 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,756 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,781 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835781\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,782 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36204 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,784 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,784 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1a4c723-06ee-482e-bb7b-0a2959460d6a,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,789 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835789\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,789 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36216 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8d2b0d26-3a4e-45cd-8d69-d8d3fb846fff,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,710 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ce598e15-4705-4959-9f1c-86c194d54ced,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835719\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fd599c2d-8b03-4f09-b7bb-625b37324af4,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36172 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,721 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,728 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835728\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,729 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,730 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98d8e341-2bfd-43dc-9864-b1fa19ef56ec,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,731 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,737 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835737\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,739 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:74a2ea5a-5a01-4af2-86b3-9fd199dc74cf,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36184 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,740 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,741 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,749 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835749\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,750 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,751 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36192 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,752 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,752 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e5365e2-8e57-41f5-9229-ce52546ecd19,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,756 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,756 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,781 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835781\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,782 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36204 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,783 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,784 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,784 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1a4c723-06ee-482e-bb7b-0a2959460d6a,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,789 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835789\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,789 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36216 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,790 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,791 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8d2b0d26-3a4e-45cd-8d69-d8d3fb846fff,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,799 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835799\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0bd97292-477c-4f25-83d0-6690d4448b87,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36220 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,811 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835811\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:55da6d10-256a-4fa4-8f42-626264a3e5a9,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36234 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,799 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835799\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,800 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0bd97292-477c-4f25-83d0-6690d4448b87,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36220 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,801 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,811 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835811\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:55da6d10-256a-4fa4-8f42-626264a3e5a9,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,813 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36234 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,814 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.805:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.805:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.805:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.806:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/51.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f253c1ede00>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.857:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/52.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.889:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.889:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.890:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/53.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.918:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/54.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.945:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.946:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/55.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:15.973:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/56.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.006:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/57.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/58.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.091:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/59.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.124:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.124:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.127:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.127:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.127:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.127:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.128:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/6.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.166:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/60.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.202:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/61.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.229:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.229:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.229:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.229:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.233:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.236:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.237:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.240:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.240:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.243:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.243:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.244:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.244:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.244:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/62.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.281:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.281:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.282:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.282:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.282:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.282:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.283:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.283:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.283:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.283:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.283:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/63.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/64.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.363:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.363:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.364:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.364:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.364:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.365:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.365:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.365:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.365:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.366:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.366:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.366:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.367:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.367:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.367:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.368:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/65.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.436:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.436:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.436:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.437:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.437:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.437:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.438:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.438:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.438:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.439:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.439:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.439:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.440:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.440:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.440:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.440:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/66.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.496:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.496:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.496:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.496:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.499:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.499:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.499:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/67.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.534:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.534:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.534:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.536:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.536:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.536:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.536:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/68.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.564:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.565:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.565:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.565:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.565:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/69.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.595:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/7.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.621:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/70.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.654:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.655:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.655:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.655:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.655:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.658:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.658:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/71.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.714:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.715:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/72.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.746:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.747:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/74.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,835 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36244 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ea78eee-ddc5-47d4-bd1d-a5576ad2c839,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835847\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,835 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,836 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36244 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,837 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ea78eee-ddc5-47d4-bd1d-a5576ad2c839,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835847\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4b138fe2-5103-4ce5-b208-329ae14c3d6a,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36250 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,850 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,850 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835853\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,854 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,854 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:32b07775-bb71-4705-89a3-ec195f44e32d,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36258 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,859 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835859\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c337595d-4dba-4ba2-9852-4456c1f1c052,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4b138fe2-5103-4ce5-b208-329ae14c3d6a,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36250 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,849 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,850 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,850 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835853\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,854 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,854 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:32b07775-bb71-4705-89a3-ec195f44e32d,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36258 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,855 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,859 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835859\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c337595d-4dba-4ba2-9852-4456c1f1c052,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,860 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36268 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,864 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835864\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,865 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,865 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:055d39e0-c24c-46f9-8dd5-ed6c503c988c,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36284 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,872 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835872\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36290 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,876 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2ec003aa-f6ab-43b1-862f-025f2f314356,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,883 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835883\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,884 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36268 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,861 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,864 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835864\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,865 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,865 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:055d39e0-c24c-46f9-8dd5-ed6c503c988c,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36284 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,866 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,872 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835872\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36290 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,875 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,876 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2ec003aa-f6ab-43b1-862f-025f2f314356,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,883 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835883\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,884 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36304 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,886 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,886 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c6daae0f-1848-4a46-99a6-f17e2c0fa676,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835894\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,895 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36312 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,897 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,897 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b989ac49-b658-4217-8301-9811a0d7f18f,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,901 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835901\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,902 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36324 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5021d8e1-5e99-42ee-a6c4-2e10e9c1dece,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,907 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835907\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,907 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36328 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,910 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:65dcb247-9b16-482b-9e51-1047d62846fe,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,914 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835914\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36304 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,885 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,886 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,886 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c6daae0f-1848-4a46-99a6-f17e2c0fa676,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835894\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,895 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36312 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,897 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,897 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b989ac49-b658-4217-8301-9811a0d7f18f,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,901 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835901\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,902 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36324 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,903 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5021d8e1-5e99-42ee-a6c4-2e10e9c1dece,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,907 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835907\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,907 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36328 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,909 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,910 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:65dcb247-9b16-482b-9e51-1047d62846fe,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,914 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835914\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,915 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,915 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,915 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,915 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,916 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,917 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:af38b68c-8aad-4b69-b265-7a9a5ded7ca6,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,922 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835922\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,922 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,923 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,923 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36334 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a9391a59-9672-45b9-a348-cf7197688633,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,928 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835928\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,929 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36338 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,917 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:af38b68c-8aad-4b69-b265-7a9a5ded7ca6,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,922 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835922\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,922 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,923 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,923 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36334 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,924 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a9391a59-9672-45b9-a348-cf7197688633,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,928 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835928\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,929 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36338 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,931 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7d532574-1796-44b4-a9b3-26a11dad8371,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,934 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835934\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,935 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,937 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,937 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7be113e4-b083-4e29-ba53-f06322fe1334,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,941 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835940\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,941 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36368 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,943 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,943 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:951a6b81-aedd-4309-a2d0-36d772d38779,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,949 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835949\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,949 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36382 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,951 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,951 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,952 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:82ab8281-5e9f-4b43-a1c3-2f3a993bd63e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,955 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835955\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,930 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,931 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7d532574-1796-44b4-a9b3-26a11dad8371,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,934 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835934\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,935 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,936 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,937 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,937 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7be113e4-b083-4e29-ba53-f06322fe1334,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,941 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835940\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,941 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36368 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,942 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,943 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,943 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:951a6b81-aedd-4309-a2d0-36d772d38779,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,949 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835949\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,949 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36382 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,950 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,951 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,951 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,952 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:82ab8281-5e9f-4b43-a1c3-2f3a993bd63e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,955 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835955\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,956 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36390 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1eb927ea-97b0-47e5-834a-04d08825d80e,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835962\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,963 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,963 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36398 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e516bf2-8b78-4c50-ad37-9f468de0630f,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,968 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835968\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,969 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36406 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5a84d292-b1f6-4479-a205-191bda666e90,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,975 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835975\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,976 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36410 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,956 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36390 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,957 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,958 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1eb927ea-97b0-47e5-834a-04d08825d80e,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835962\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,963 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,963 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36398 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e516bf2-8b78-4c50-ad37-9f468de0630f,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,968 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835968\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,969 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36406 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,970 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,971 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5a84d292-b1f6-4479-a205-191bda666e90,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,975 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835975\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,976 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36410 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,981 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8429362c-6a41-4ca6-bfd4-5b85859ff911,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,986 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835986\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,986 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,987 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36416 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,989 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae752e85-7281-4e29-9723-3a75349b8207,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,995 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835995\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,995 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,996 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36424 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:15,998 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da76af9a-bd28-4ac7-b65f-5adcb091fa37,timestamp:1661072835\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,001 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836001\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,002 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36438 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,004 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4a2ee000-dd1a-4067-9612-99d7b96b9b4b,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,008 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836008\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,978 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,981 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8429362c-6a41-4ca6-bfd4-5b85859ff911,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,986 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835986\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,986 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,987 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36416 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,988 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,989 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae752e85-7281-4e29-9723-3a75349b8207,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,995 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072835995\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,995 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,996 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36424 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,997 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:15,998 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da76af9a-bd28-4ac7-b65f-5adcb091fa37,timestamp:1661072835\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,001 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836001\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,002 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36438 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,003 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,004 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4a2ee000-dd1a-4067-9612-99d7b96b9b4b,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,008 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836008\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,009 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,011 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d726b26c-7a47-4146-a241-8f57e1f8e3ec,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,014 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836014\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,015 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36456 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,017 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,017 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bf800703-63ce-4d7c-af0b-04c48b9c4e12,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,031 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836031\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,033 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36462 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.93|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a72fc719-9891-4282-ad39-c7ddc2a38ca1,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836042\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,043 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36474 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,009 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,010 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,011 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d726b26c-7a47-4146-a241-8f57e1f8e3ec,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,014 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836014\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,015 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36456 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,016 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,017 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,017 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bf800703-63ce-4d7c-af0b-04c48b9c4e12,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,031 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836031\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,033 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36462 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,034 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.93|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a72fc719-9891-4282-ad39-c7ddc2a38ca1,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836042\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,043 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36474 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,044 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,045 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c755db65-6682-4836-97a5-63f02a999f72,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,052 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836052\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,053 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,053 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b6ddfec0-cb90-4f07-af8e-41340044b174,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36476 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836070\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,071 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92eb3642-d4b4-4dd7-80e8-306b884242f4,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36486 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,079 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836079\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a00b803c-51e5-4a6b-b2f1-2ad7b8e6a3ed,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,082 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,082 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836087\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,088 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,088 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a75fd2d-f90c-4ddc-81dc-e2c9f7accd0f,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36512 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,045 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c755db65-6682-4836-97a5-63f02a999f72,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,052 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836052\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,053 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,053 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b6ddfec0-cb90-4f07-af8e-41340044b174,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36476 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,054 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836070\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,071 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92eb3642-d4b4-4dd7-80e8-306b884242f4,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36486 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,079 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836079\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a00b803c-51e5-4a6b-b2f1-2ad7b8e6a3ed,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,081 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,082 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,082 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836087\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,088 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,088 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a75fd2d-f90c-4ddc-81dc-e2c9f7accd0f,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36512 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,095 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836095\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,097 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36520 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,099 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0804ec1c-2156-4e17-b571-b95f8c1ebdac,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,106 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836106\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36530 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37b0cab8-9cb2-44c6-9027-321f6c0e1cbe,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,112 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836112\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,112 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,113 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ca5df85-847f-4fa7-8806-7040ad20b4e0,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,119 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836119\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,120 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,089 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,095 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836095\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,097 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36520 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,098 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,099 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0804ec1c-2156-4e17-b571-b95f8c1ebdac,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,106 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836106\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36530 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,108 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:37b0cab8-9cb2-44c6-9027-321f6c0e1cbe,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,112 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836112\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,112 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,113 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ca5df85-847f-4fa7-8806-7040ad20b4e0,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36538 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,114 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,119 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836119\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,120 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,120 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c802f3b1-1f35-411f-a5ef-8fb2948a878f,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36542 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,133 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836133\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,134 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3aceca5-f179-4e48-b6a2-6ef57a80f507,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36558 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836140\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,140 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,141 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,141 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8b685c70-01fd-4375-9389-dfa891bdb86e,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836148\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,149 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36570 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4cb5a5c7-ce9e-4964-8850-341298f9cb48,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,120 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c802f3b1-1f35-411f-a5ef-8fb2948a878f,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36542 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,121 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,133 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836133\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,134 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3aceca5-f179-4e48-b6a2-6ef57a80f507,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36558 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,135 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836140\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,140 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,141 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,141 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8b685c70-01fd-4375-9389-dfa891bdb86e,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,142 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836148\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,149 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36570 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,150 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4cb5a5c7-ce9e-4964-8850-341298f9cb48,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,156 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836156\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,156 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36574 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,158 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,158 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a00f55bb-ae00-4696-8cac-3500976d0c22,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836171\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,171 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,172 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:44bf9250-57c4-4ebc-9213-fc1adf0b0344,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36582 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,184 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836184\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,151 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,156 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836156\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,156 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36574 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,157 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,158 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,158 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a00f55bb-ae00-4696-8cac-3500976d0c22,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836171\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,171 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,172 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:44bf9250-57c4-4ebc-9213-fc1adf0b0344,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36582 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,173 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,184 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836184\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,184 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36594 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,187 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98434475-d4de-4a27-922d-72534351e764,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836192\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,192 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36598 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cd5e09ed-1640-405c-b863-032adebe15c6,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,194 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,194 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,195 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,198 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836198\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,199 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36612 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,201 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5fa7d033-d812-4e8d-8511-a3584318a6b8,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,207 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836207\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,207 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36614 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,184 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36594 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,185 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,187 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:98434475-d4de-4a27-922d-72534351e764,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836192\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,192 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36598 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,193 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cd5e09ed-1640-405c-b863-032adebe15c6,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,194 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,194 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,195 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,198 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836198\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,199 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36612 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,200 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,201 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5fa7d033-d812-4e8d-8511-a3584318a6b8,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,207 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836207\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,207 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36614 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,209 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4e02acb8-4dad-4d99-8b1a-6aaac2826b8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,212 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836212\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,213 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:064fce17-c63d-47f4-9ac0-537e26c83230,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36620 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,219 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836219\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,219 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9eef37f3-7f25-4ab0-9c6a-f2f7dbb14170,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,208 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,209 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4e02acb8-4dad-4d99-8b1a-6aaac2826b8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,212 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836212\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,213 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:064fce17-c63d-47f4-9ac0-537e26c83230,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36620 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,214 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,219 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836219\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,219 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9eef37f3-7f25-4ab0-9c6a-f2f7dbb14170,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36626 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,221 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,224 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836224\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,225 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,225 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f094c88-7651-4555-8406-7c36261784b5,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36642 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,250 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836250\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,251 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36626 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,220 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,221 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,224 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836224\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,225 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,225 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f094c88-7651-4555-8406-7c36261784b5,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36642 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,226 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,250 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836250\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,251 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36644 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,253 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f442a619-64b9-4bbe-b999-ab530468e2a5,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,260 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836260\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,261 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36652 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,263 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f4f2601-bf58-48ff-90a4-44f07646a752,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,270 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836270\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,271 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36644 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,252 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,253 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f442a619-64b9-4bbe-b999-ab530468e2a5,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,260 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836260\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,261 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36652 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,262 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,263 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f4f2601-bf58-48ff-90a4-44f07646a752,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,270 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836270\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,271 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,272 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,273 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,273 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5bdaa2f-c802-447c-b8a9-2d3c6de35125,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,277 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836277\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36672 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d0738e53-2ba8-4c4b-af78-d7b2514f7301,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,289 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836289\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,290 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36688 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,292 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,292 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9eb58771-78b1-4dda-89a0-0777cacede9b,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,296 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836296\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,297 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36700 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b03c865-8175-468e-a1ef-dcee55ce9810,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,299 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,299 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,305 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836305\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,306 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36706 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,273 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,273 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5bdaa2f-c802-447c-b8a9-2d3c6de35125,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,277 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836277\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36672 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,278 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d0738e53-2ba8-4c4b-af78-d7b2514f7301,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,289 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836289\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,290 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36688 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,291 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,292 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,292 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9eb58771-78b1-4dda-89a0-0777cacede9b,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,296 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836296\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,297 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36700 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b03c865-8175-468e-a1ef-dcee55ce9810,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,298 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,299 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,299 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,305 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836305\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,306 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,306 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36706 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,307 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,308 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dfcee04f-7591-4b38-8097-ef087557f3ec,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,323 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836323\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,324 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36714 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.08|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92756974-d589-4795-9006-f02b0e3f2811,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,333 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836333\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,333 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36720 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3ef3b206-4064-4f2a-bc5d-9a1cdc053a8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,339 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836339\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,340 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,340 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b810d9b2-9930-41a2-90db-8018a4ca0402,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36736 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,347 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836347\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,348 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:57702397-44c0-45e3-b607-d9ff1ac9f968,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,308 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:dfcee04f-7591-4b38-8097-ef087557f3ec,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,323 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836323\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,324 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36714 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,325 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,326 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.08|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92756974-d589-4795-9006-f02b0e3f2811,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,333 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836333\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,333 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36720 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,334 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3ef3b206-4064-4f2a-bc5d-9a1cdc053a8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,335 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,339 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836339\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,340 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,340 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b810d9b2-9930-41a2-90db-8018a4ca0402,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36736 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,341 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,347 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836347\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,348 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,349 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,350 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:57702397-44c0-45e3-b607-d9ff1ac9f968,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,357 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836357\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,357 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36754 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:06c4744f-bff6-4467-b94b-8595b99bc835,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,373 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836373\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,374 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,375 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,375 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36760 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,378 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3aa1db19-7c9e-47f2-89b2-f5069c26172b,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,389 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836389\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,391 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36766 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,393 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d38d9aaf-8462-4890-a362-5fa225048873,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,399 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836399\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,405 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,405 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36770 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,357 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836357\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,357 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36754 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,358 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,359 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:06c4744f-bff6-4467-b94b-8595b99bc835,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,373 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836373\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,374 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,375 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,375 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36760 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,376 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,378 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3aa1db19-7c9e-47f2-89b2-f5069c26172b,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,389 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836389\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,391 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36766 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,393 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,392 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d38d9aaf-8462-4890-a362-5fa225048873,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,399 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836399\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,405 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,405 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36770 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,410 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d76319f2-0af7-44f2-b697-70f333a3272b,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836427\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,428 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2d6ee3f0-a6e1-4879-8ca5-0f6270bf2161,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36776 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,452 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836452\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36780 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c892cb88-6191-46ad-a097-962a0f3230b0,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,464 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836464\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,465 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,466 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,466 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36796 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,467 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1e424549-b008-4e97-9ae7-b0c90525bcd5,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,481 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836481\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,482 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:74928998-0b49-41df-83b4-b8e3b9c76d9f,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36812 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,406 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,410 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d76319f2-0af7-44f2-b697-70f333a3272b,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836427\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,428 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2d6ee3f0-a6e1-4879-8ca5-0f6270bf2161,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36776 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,432 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,452 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836452\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36780 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,454 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c892cb88-6191-46ad-a097-962a0f3230b0,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,464 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836464\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,465 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,466 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,466 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36796 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,467 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,468 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1e424549-b008-4e97-9ae7-b0c90525bcd5,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,481 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836481\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,482 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:74928998-0b49-41df-83b4-b8e3b9c76d9f,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36812 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,491 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836491\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,492 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36814 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,494 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3389d36-d504-4069-9cca-b5ba9e59c4cc,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,505 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836505\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,506 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:03925fc7-153e-495a-9dce-71c2a07d8a0a,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36816 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,514 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836514\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,514 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36830 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bccb466a-8d2a-4b5d-b2e6-857aa989b4f3,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,521 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836521\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,522 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d98fbed7-d707-45b2-ac67-833a318d82cb,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,483 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,491 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836491\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,492 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36814 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,493 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,494 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3389d36-d504-4069-9cca-b5ba9e59c4cc,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,505 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836505\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,506 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:03925fc7-153e-495a-9dce-71c2a07d8a0a,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36816 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,507 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,514 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836514\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,514 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36830 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,515 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bccb466a-8d2a-4b5d-b2e6-857aa989b4f3,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,521 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836521\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,522 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d98fbed7-d707-45b2-ac67-833a318d82cb,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36844 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,529 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836529\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36856 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:81c832cb-05f8-4eef-8389-7e28f3719836,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,544 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836544\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36866 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:423e9b2f-c564-4b09-a68d-d18864c38326,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,550 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836550\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,550 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36872 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:586c3f7e-3a02-4142-8f2c-93b1c280b13b,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,555 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836555\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36884 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36844 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,529 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836529\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36856 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,530 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,531 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:81c832cb-05f8-4eef-8389-7e28f3719836,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,544 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836544\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36866 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:423e9b2f-c564-4b09-a68d-d18864c38326,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,546 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,550 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836550\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,550 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36872 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,551 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,552 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:586c3f7e-3a02-4142-8f2c-93b1c280b13b,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,555 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836555\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36884 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1703d402-9502-4737-b870-86c81d1518d0,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,561 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836561\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36892 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:056baea4-333a-4490-b880-8947039805ba,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,569 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836569\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,570 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,570 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36906 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:75d0a52f-7004-47ed-97d3-fc695dd0ca8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,577 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836577\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,577 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36908 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,579 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:57dac4a0-1a9a-4f3f-ace2-3f5abdfbe3e3,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,583 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836583\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,583 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e989b5d3-3b8f-4353-b6fd-21113bf97432,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36914 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1703d402-9502-4737-b870-86c81d1518d0,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,557 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,561 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836561\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36892 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,562 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,563 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:056baea4-333a-4490-b880-8947039805ba,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,569 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836569\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,570 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,570 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36906 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,571 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:75d0a52f-7004-47ed-97d3-fc695dd0ca8d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,577 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836577\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,577 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36908 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,578 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,579 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:57dac4a0-1a9a-4f3f-ace2-3f5abdfbe3e3,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,583 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836583\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,583 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e989b5d3-3b8f-4353-b6fd-21113bf97432,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36914 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,588 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836588\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,589 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36924 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,591 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:30db1765-3a37-4538-a6b3-96688a461e14,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,598 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836598\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b00dec6d-2a9b-4da8-bf00-41e7767143c4,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36934 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,604 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836604\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,605 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.29|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1a13e93-d0bb-41ef-90c7-c1b5fca7b477,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36944 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,611 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836611\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,611 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36954 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,584 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,588 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836588\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,589 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36924 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,590 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,591 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:30db1765-3a37-4538-a6b3-96688a461e14,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,598 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836598\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,599 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b00dec6d-2a9b-4da8-bf00-41e7767143c4,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36934 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,600 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,604 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836604\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,605 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.29|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f1a13e93-d0bb-41ef-90c7-c1b5fca7b477,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36944 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,606 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,611 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836611\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,611 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36954 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:096d50eb-ae6e-4e2b-b23f-19fede1152cd,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836617\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,618 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36968 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6b0c371-cb23-4c43-a078-275fec61446a,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836626\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:673d70ef-5960-4f09-917d-75040cf2992f,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36972 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,628 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,633 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836633\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,634 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36986 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,612 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:096d50eb-ae6e-4e2b-b23f-19fede1152cd,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836617\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,618 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36968 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,619 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e6b0c371-cb23-4c43-a078-275fec61446a,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836626\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:673d70ef-5960-4f09-917d-75040cf2992f,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36972 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,627 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,628 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,633 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836633\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,634 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:36986 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,635 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:90c7a0e4-ad04-4983-acdb-cb4a9387e97a,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,642 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836642\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,643 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,643 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4f9bf449-0440-4b3d-81b5-cc340bfef3e9,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36990 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,645 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,649 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836649\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,649 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,650 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37000 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,652 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62163d13-de19-47c5-acca-42252c108979,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,665 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836665\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,666 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37010 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d9ecd2c3-0009-4331-a0da-d340dbbb5093,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,636 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:90c7a0e4-ad04-4983-acdb-cb4a9387e97a,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,642 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836642\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,643 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,643 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4f9bf449-0440-4b3d-81b5-cc340bfef3e9,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:36990 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,644 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,645 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,649 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836649\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,649 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,650 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37000 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,651 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,652 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62163d13-de19-47c5-acca-42252c108979,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,665 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836665\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,666 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37010 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d9ecd2c3-0009-4331-a0da-d340dbbb5093,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836679\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,679 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37022 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,682 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2dadb9e7-0532-49ce-bc10-9e29a7042b46,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,694 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836694\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e3e9c75-edc5-4cc2-83dc-ff006af9c257,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37032 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,697 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,697 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,703 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836703\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,703 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,704 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37036 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,706 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:38a8eb14-a398-4bbf-aaac-e0209ee7e4f1,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836718\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e69d0ec6-641d-4e4a-ae58-bae65872913a,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37052 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,667 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836679\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,679 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37022 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,681 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,682 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2dadb9e7-0532-49ce-bc10-9e29a7042b46,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,694 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836694\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9e3e9c75-edc5-4cc2-83dc-ff006af9c257,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37032 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,696 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,697 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,697 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,703 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836703\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,703 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,704 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37036 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,705 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,706 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:38a8eb14-a398-4bbf-aaac-e0209ee7e4f1,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836718\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,720 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e69d0ec6-641d-4e4a-ae58-bae65872913a,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37052 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,729 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836729\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,730 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37058 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,732 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3313260-4b5f-41cd-ba0a-c7f5df0be79c,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836736\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37060 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3b79ef25-38bb-4927-8483-833d66c60589,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,743 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836743\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,743 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e477994-d829-4f2c-b298-931def42f136,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37076 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,745 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,745 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,757 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836757\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9254fe0e-9837-4a1a-bf8f-81a0ad46ebb8,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,721 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,729 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836729\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,730 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37058 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,731 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,732 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d3313260-4b5f-41cd-ba0a-c7f5df0be79c,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836736\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37060 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,738 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3b79ef25-38bb-4927-8483-833d66c60589,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,743 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836743\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,743 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5e477994-d829-4f2c-b298-931def42f136,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37076 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,744 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,745 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,745 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,757 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836757\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9254fe0e-9837-4a1a-bf8f-81a0ad46ebb8,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37092 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,760 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,760 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,761 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,765 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836765\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37096 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bbe0a3ab-23ce-4649-8db2-0c512021347c,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,773 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836773\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,775 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b827ccfa-81ba-44cf-9206-44083337d7b1,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37106 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,777 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,781 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836781\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,785 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,786 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,786 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37114 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,759 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37092 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,760 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,760 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,761 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,765 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836765\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37096 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bbe0a3ab-23ce-4649-8db2-0c512021347c,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,768 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,773 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836773\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,775 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,775 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b827ccfa-81ba-44cf-9206-44083337d7b1,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37106 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,776 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,777 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,781 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836781\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,785 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,786 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,786 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37114 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:55482775-e208-4285-9928-cfc30f973200,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,801 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836801\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,802 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,802 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4155f7d9-1259-4db9-a745-9d9479062251,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37118 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,804 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,804 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,810 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836810\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,811 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,811 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,787 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:55482775-e208-4285-9928-cfc30f973200,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,801 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836801\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,802 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,802 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4155f7d9-1259-4db9-a745-9d9479062251,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37118 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,803 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,804 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,804 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,810 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836810\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,811 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,811 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,813 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eac9a8fc-b2c7-414c-b006-4b56af5024c2,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,816 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836816\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37144 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,818 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,818 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:906e383c-5c2a-4d37-9179-422f43ca903d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,812 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,813 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eac9a8fc-b2c7-414c-b006-4b56af5024c2,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,816 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836816\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37144 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,818 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,818 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,817 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:906e383c-5c2a-4d37-9179-422f43ca903d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,823 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836823\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,824 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37156 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80c10fc3-f433-4af0-a76e-ddb6b3b4a4b2,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,844 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836844\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca9d1bda-8736-4218-b9ec-6c1757195f58,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37172 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,847 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,847 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2022-08-21T09:07:16,823 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836823\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,824 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37156 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,825 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:80c10fc3-f433-4af0-a76e-ddb6b3b4a4b2,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,844 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836844\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca9d1bda-8736-4218-b9ec-6c1757195f58,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37172 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,847 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,847 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/73.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.834:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/75.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.883:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.884:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/76.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.912:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.913:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/77.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.959:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.959:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.960:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/78.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:16.999:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/79.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.048:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.049:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.049:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.049:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.050:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.050:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.050:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.050:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.053:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/8.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.092:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.093:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.094:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.095:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.095:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.095:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.095:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.096:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.096:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.096:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.097:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/80.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.125:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.126:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/81.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.148:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/82.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.187:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.187:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.188:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.188:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.188:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.188:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.190:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.190:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.190:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.190:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.191:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.191:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/83.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.219:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.219:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.223:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/84.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.262:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.262:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.262:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.262:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.262:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.263:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.263:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.263:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.263:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.263:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.264:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.264:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.264:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.264:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.265:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.265:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/85.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/86.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.350:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.350:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.350:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.351:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.352:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/87.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.416:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.417:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.417:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/88.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.535:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/89.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.596:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.597:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.605:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.605:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.605:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.605:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.605:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/9.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/90.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.668:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/91.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.699:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.700:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.701:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.701:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.701:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.701:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.702:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.702:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.702:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.702:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.703:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.703:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/92.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.732:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.733:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.733:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.733:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.733:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.733:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.734:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.735:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.735:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/93.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.768:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.769:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.769:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.769:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.769:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.772:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.772:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/94.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,865 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836865\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,865 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836865\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37176 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84b8c464-19c3-450a-bcd6-968ae6d69e29,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,873 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836873\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,874 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5a8d8c9-66d2-4ffa-8b30-1bd50c859f14,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37186 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,879 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836879\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,880 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,880 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37188 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37176 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:84b8c464-19c3-450a-bcd6-968ae6d69e29,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,867 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,873 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836873\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,874 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,874 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b5a8d8c9-66d2-4ffa-8b30-1bd50c859f14,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37186 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,875 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,879 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836879\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,880 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,880 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37188 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,882 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6bb06ffa-96c6-45f5-af54-b10e5c531a3d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,889 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836889\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,890 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,881 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,882 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6bb06ffa-96c6-45f5-af54-b10e5c531a3d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,889 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836889\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,890 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c27dd581-3e79-4d2d-99d4-d74dfa5c2f08,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37198 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,895 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836895\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,896 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37204 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,898 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:08240726-7bda-4fe0-8a17-0acd2f08226f,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,902 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836902\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,902 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6511ac14-fe5c-4e1a-91d6-b539131a8c2a,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37216 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:c27dd581-3e79-4d2d-99d4-d74dfa5c2f08,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37198 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,891 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,895 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836895\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,896 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37204 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,897 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,898 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:08240726-7bda-4fe0-8a17-0acd2f08226f,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,902 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836902\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,902 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6511ac14-fe5c-4e1a-91d6-b539131a8c2a,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,903 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37216 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836908\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,908 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,909 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,909 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37222 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d76cae2c-8c07-4c30-9803-449e2682c80d,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,917 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836917\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,904 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,908 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836908\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,908 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,909 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,909 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37222 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,910 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d76cae2c-8c07-4c30-9803-449e2682c80d,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,917 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836917\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:948a5465-c1c3-450c-8ce2-daf3f7ebf5d8,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37230 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836923\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,924 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37234 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,926 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:21c22228-a832-4fda-b765-70247084628e,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,933 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836933\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,934 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:948a5465-c1c3-450c-8ce2-daf3f7ebf5d8,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37230 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,919 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836923\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,924 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37234 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,925 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,926 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:21c22228-a832-4fda-b765-70247084628e,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,933 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836933\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,934 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,934 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6eee2b79-ab88-4bba-a627-5498eef6782e,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37240 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,936 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,951 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836951\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,952 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37254 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,954 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,954 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ce971241-b42c-41e2-9378-883639a0e416,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,966 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836966\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,934 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6eee2b79-ab88-4bba-a627-5498eef6782e,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37240 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,935 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,936 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,951 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836951\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,952 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37254 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,953 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,954 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,954 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ce971241-b42c-41e2-9378-883639a0e416,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,966 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836966\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,967 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6c6dbc8b-0089-458d-82bf-92e04645603e,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37256 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,969 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,969 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836976\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,977 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37272 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,979 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,979 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,984 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b02eb8a-79ce-48e2-862b-8b6de4758528,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836986\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,986 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,987 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,987 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ea75af5-2d1e-48f6-9452-8936110cc294,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37274 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,967 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6c6dbc8b-0089-458d-82bf-92e04645603e,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37256 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,968 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,969 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,969 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836976\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,977 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37272 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,978 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,979 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,979 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,984 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b02eb8a-79ce-48e2-862b-8b6de4758528,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836986\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,986 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,987 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,987 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:4ea75af5-2d1e-48f6-9452-8936110cc294,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37274 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,988 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836994\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,995 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37276 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:16,997 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:30f07b04-37f0-4959-932b-0a4a53b8a1f9,timestamp:1661072836\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,013 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837013\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,014 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7b750edf-81bd-4fd1-8265-78fd29f1bbb0,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37278 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072836994\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,995 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37276 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,996 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:16,997 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:30f07b04-37f0-4959-932b-0a4a53b8a1f9,timestamp:1661072836\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,013 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837013\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,014 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:7b750edf-81bd-4fd1-8265-78fd29f1bbb0,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,015 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37278 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,024 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837024\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,025 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37284 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,027 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,027 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ce5a90d-cb8e-46a6-a3b8-555582be077b,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,016 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,024 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837024\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,025 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37284 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,026 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,027 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,027 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9ce5a90d-cb8e-46a6-a3b8-555582be077b,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837033\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9783ae42-9c18-45db-ba3b-328e863f67d6,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37298 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,041 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837041\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,042 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,043 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37314 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,043 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2c0e2993-a17d-4951-8d5a-53467e2c35e8,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,058 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837058\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,059 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,060 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93f3436d-9904-44fe-9191-769eeca5e240,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,060 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37330 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837033\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9783ae42-9c18-45db-ba3b-328e863f67d6,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37298 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,041 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837041\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,042 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,043 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37314 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,043 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,044 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2c0e2993-a17d-4951-8d5a-53467e2c35e8,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,058 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837058\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,059 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,060 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:93f3436d-9904-44fe-9191-769eeca5e240,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,060 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37330 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,067 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837067\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,061 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,067 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837067\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,069 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:19a759db-33c0-4fae-baa0-5e389cababee,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837078\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,079 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3e1d730f-2f29-40d8-b17c-c45daf6de52a,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37342 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,070 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:19a759db-33c0-4fae-baa0-5e389cababee,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837078\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,079 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3e1d730f-2f29-40d8-b17c-c45daf6de52a,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37342 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,086 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837086\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,086 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,080 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,086 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837086\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,086 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,089 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e9a6fa62-3e20-413b-8822-3146b3130db2,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837102\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,087 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,088 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,089 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e9a6fa62-3e20-413b-8822-3146b3130db2,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837102\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,103 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,104 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,104 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1dfb9dd4-7963-4120-a820-926fa244812f,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37354 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,109 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837109\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,110 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,110 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f785f571-bfb3-4857-a5e0-30b05b719dbc,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,103 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,104 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,104 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1dfb9dd4-7963-4120-a820-926fa244812f,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37354 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,105 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,109 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837109\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,110 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,110 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f785f571-bfb3-4857-a5e0-30b05b719dbc,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37362 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,115 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837115\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,115 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d2bd36ac-410a-4c12-a2aa-0c9f4fe6a9d1,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37374 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,121 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837121\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,122 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37362 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,111 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,115 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837115\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,115 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d2bd36ac-410a-4c12-a2aa-0c9f4fe6a9d1,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,116 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37374 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,117 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,121 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837121\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,122 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37380 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:deb1184d-06a9-4d2a-94b6-9ea6b0a09ec2,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,129 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837129\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,129 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:df7b412d-556b-466a-a81d-d7ee70658738,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37382 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,132 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,132 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,135 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837135\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,135 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37398 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92645aa8-2460-4e11-98e8-9890394a89e4,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837140\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2a9992b6-5433-4204-90c1-53dc7a07b2b0,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37414 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,142 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,142 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37380 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,123 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:deb1184d-06a9-4d2a-94b6-9ea6b0a09ec2,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,129 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837129\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,129 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:df7b412d-556b-466a-a81d-d7ee70658738,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37382 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,131 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,132 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,132 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,135 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837135\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,135 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37398 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,136 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,137 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:92645aa8-2460-4e11-98e8-9890394a89e4,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837140\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2a9992b6-5433-4204-90c1-53dc7a07b2b0,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37414 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,141 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,142 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,142 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,145 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837145\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,145 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:69c1d08d-d30f-4e6b-a563-f8290ace2e49,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37426 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,147 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,147 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,153 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837153\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:25a7dfd6-2330-4060-a8b2-aab90cdcb6f6,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,145 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837145\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,145 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:69c1d08d-d30f-4e6b-a563-f8290ace2e49,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37426 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,146 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,147 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,147 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,153 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837153\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:25a7dfd6-2330-4060-a8b2-aab90cdcb6f6,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37436 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,161 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837161\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f01d496-efb7-41e0-8920-8bb33eea097e,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37440 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,154 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37436 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,155 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,161 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837161\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f01d496-efb7-41e0-8920-8bb33eea097e,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37440 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,163 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,175 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837175\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,176 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b1194d66-f3db-48f8-8984-42ad5d666513,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,178 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,182 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837182\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,183 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37458 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,162 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,163 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,175 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837175\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,176 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:b1194d66-f3db-48f8-8984-42ad5d666513,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,177 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,178 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,182 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837182\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,183 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37458 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:740be3fa-6f40-4f99-aec5-ac373143d805,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,194 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837194\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,195 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:03a5c064-1db8-4a76-be72-27687d4f593e,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37474 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,197 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,201 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837201\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,201 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37490 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:740be3fa-6f40-4f99-aec5-ac373143d805,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,184 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,194 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837194\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,195 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:03a5c064-1db8-4a76-be72-27687d4f593e,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37474 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,196 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,197 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,201 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837201\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,201 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37490 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,202 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b2fc041-5c43-41ad-980d-20cca36987fe,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,207 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837207\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,207 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,208 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eae51a78-f8a5-4267-bedd-69b811da671a,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,208 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837213\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,214 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37502 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,203 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9b2fc041-5c43-41ad-980d-20cca36987fe,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,207 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837207\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,207 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,208 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:eae51a78-f8a5-4267-bedd-69b811da671a,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,208 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,209 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,213 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837213\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,214 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37502 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,216 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:99b88368-a7dd-44ed-b128-fe6540da1680,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837226\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,227 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2631e632-9aef-4949-b1f4-7e34e589f406,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,215 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,216 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:99b88368-a7dd-44ed-b128-fe6540da1680,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837226\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,227 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2631e632-9aef-4949-b1f4-7e34e589f406,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,233 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837233\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37512 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,228 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,233 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837233\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,234 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37512 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,235 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6d553265-bf8d-42d2-aea3-bb78f403b2b9,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,240 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837240\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,240 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,241 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:07500639-0960-45d8-8b98-80e3c829e9de,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37524 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,248 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,256 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837256\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37540 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,259 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf840d44-a88b-4678-b144-36a93be44858,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,269 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837269\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,270 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8413c0e6-59c7-4f5f-9c04-a3e3109b4cab,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6d553265-bf8d-42d2-aea3-bb78f403b2b9,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,240 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837240\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,240 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,241 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:07500639-0960-45d8-8b98-80e3c829e9de,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37524 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,242 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,248 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,256 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837256\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37540 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,258 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,259 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf840d44-a88b-4678-b144-36a93be44858,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,269 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837269\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,270 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,270 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8413c0e6-59c7-4f5f-9c04-a3e3109b4cab,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37552 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837276\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,277 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a08e85f2-ec74-4e93-a3dc-9be976a54321,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,284 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837284\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,284 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,285 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5ca78223-4810-4fac-ba39-877ceffdd4b1,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,285 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37574 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37552 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,271 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837276\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,277 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,278 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,279 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a08e85f2-ec74-4e93-a3dc-9be976a54321,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,284 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837284\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,284 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,285 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:5ca78223-4810-4fac-ba39-877ceffdd4b1,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,285 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37574 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837305\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,306 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,306 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37588 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,286 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,305 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837305\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,306 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,306 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37588 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36c3c907-c044-4d63-b855-bf85f36984db,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,312 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837312\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,313 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37592 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:17037018-0af6-4fd7-9fc4-05e27233f225,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,323 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837323\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,324 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,307 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36c3c907-c044-4d63-b855-bf85f36984db,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,312 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837312\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,313 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:37592 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:17037018-0af6-4fd7-9fc4-05e27233f225,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,314 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,323 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837323\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,324 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,325 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37596 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,332 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2987f6d3-0c15-40ec-8e79-22dad811d640,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,336 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837336\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,337 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6b3fc6bf-224a-497d-bc8f-e069b0fc8ab8,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,343 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837343\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,344 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54344 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3463dc19-c6ac-4fb4-b400-e9c63ca0e408,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,355 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837355\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,355 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,356 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54348 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,325 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:37596 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,326 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,332 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2987f6d3-0c15-40ec-8e79-22dad811d640,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,336 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837336\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,337 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54332 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,338 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,339 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6b3fc6bf-224a-497d-bc8f-e069b0fc8ab8,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,343 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837343\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,344 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54344 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,345 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,346 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3463dc19-c6ac-4fb4-b400-e9c63ca0e408,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,355 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837355\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,355 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,356 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54348 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:aab851b2-f289-47a7-adbd-8b9079c20444,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,362 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837362\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,363 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9fa213c6-3a55-4de5-9e67-fb1fc5cef191,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54364 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,384 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837384\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,388 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5ea67a4-74b9-467d-8249-16a99ee838e2,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54376 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,403 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837403\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,404 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54378 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,357 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:aab851b2-f289-47a7-adbd-8b9079c20444,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,362 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837362\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,363 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9fa213c6-3a55-4de5-9e67-fb1fc5cef191,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54364 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,366 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,384 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837384\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,388 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e5ea67a4-74b9-467d-8249-16a99ee838e2,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54376 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,389 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,403 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837403\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,404 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54378 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,406 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36ff8423-de3f-47ff-b68e-acee9bd9af47,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,423 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837423\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54388 \"POST /invocations HTTP/1.1\" 500 16\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:15|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,444 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf27f648-a2b8-4c5c-9ad7-04432fa82f30,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,457 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837457\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,458 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54404 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,460 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa3b6b63-f71b-47e2-82c8-4e8ce27288c2,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,469 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837469\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,470 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54416 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,472 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,472 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,473 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:de8fd0ec-a3d7-477b-a3b5-df9cd6af7bcc,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837490\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,497 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,405 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,406 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36ff8423-de3f-47ff-b68e-acee9bd9af47,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,423 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837423\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54388 \"POST /invocations HTTP/1.1\" 500 16\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:15|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,440 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,444 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:cf27f648-a2b8-4c5c-9ad7-04432fa82f30,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,457 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837457\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,458 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54404 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,459 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,460 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fa3b6b63-f71b-47e2-82c8-4e8ce27288c2,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,469 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837469\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,470 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54416 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,471 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,472 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,472 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,473 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:de8fd0ec-a3d7-477b-a3b5-df9cd6af7bcc,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837490\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,497 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,497 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f842583-c227-42f9-86de-167fea640ee5,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54418 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,545 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837545\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,549 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,549 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54422 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:062dc218-46d9-4dca-8432-32bf20bc9709,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,575 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837575\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,575 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,576 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54436 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0240d504-6002-44f0-9080-449f08aad7fe,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837587\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bd3cde54-3a68-49d8-9eb2-ff26248d71ae,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54438 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,497 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:3f842583-c227-42f9-86de-167fea640ee5,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54418 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,498 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,545 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837545\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,549 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,549 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54422 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,550 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:062dc218-46d9-4dca-8432-32bf20bc9709,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,575 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837575\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,575 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,576 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54436 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,577 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0240d504-6002-44f0-9080-449f08aad7fe,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837587\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,588 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bd3cde54-3a68-49d8-9eb2-ff26248d71ae,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54438 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,592 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837592\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,593 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,593 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36691e16-0b15-4f0d-a9f0-334dd7d76920,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54442 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,609 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837609\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,610 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,610 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9bcaffd4-8c8e-4035-a8a9-aa621964cfd2,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837617\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,617 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54464 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,619 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fb53bf2a-992b-44bd-a51c-13d59f135a45,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837624\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,589 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,592 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837592\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,593 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,593 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:36691e16-0b15-4f0d-a9f0-334dd7d76920,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54442 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,594 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,609 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837609\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,610 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,610 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9bcaffd4-8c8e-4035-a8a9-aa621964cfd2,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,611 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837617\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,617 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54464 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,619 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,618 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fb53bf2a-992b-44bd-a51c-13d59f135a45,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837624\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,625 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54468 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da5b65fa-f25b-4da5-adb5-34e6ec5d49e5,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,635 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837635\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,635 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54472 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8efc5c07-5daa-4ae5-b5bd-232acd926c77,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,645 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837645\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,645 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e73e1e49-6d73-4eab-a4fd-a2d811b367ad,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54478 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,647 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,647 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,651 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837650\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54486 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,625 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54468 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,626 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da5b65fa-f25b-4da5-adb5-34e6ec5d49e5,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,635 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837635\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,635 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54472 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,636 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,637 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8efc5c07-5daa-4ae5-b5bd-232acd926c77,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,645 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837645\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,645 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e73e1e49-6d73-4eab-a4fd-a2d811b367ad,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54478 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,646 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,647 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,647 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,651 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837650\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,651 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54486 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,652 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae23c6bd-90b2-405f-ad7b-c886da1cfb3f,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,657 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837657\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a810eea-27d4-4e30-84a7-31148fbabc29,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54500 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837663\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54514 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:592987b2-9224-4d2e-8503-80d107e028d5,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,671 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837671\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,672 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,672 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54518 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6feee1a0-06c8-4f41-9356-87cefe582808,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,653 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae23c6bd-90b2-405f-ad7b-c886da1cfb3f,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,657 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837657\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6a810eea-27d4-4e30-84a7-31148fbabc29,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,658 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54500 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,659 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837663\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54514 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,665 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:592987b2-9224-4d2e-8503-80d107e028d5,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,671 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837671\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,672 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,672 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54518 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:6feee1a0-06c8-4f41-9356-87cefe582808,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837679\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,679 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54530 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9fd3b6c1-3a50-4f3e-9de8-5c8c3069d615,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837686\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,673 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,679 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837679\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,679 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54530 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:9fd3b6c1-3a50-4f3e-9de8-5c8c3069d615,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,680 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837686\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,686 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54536 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e430ee06-df3b-4312-88d5-5ad8d9630137,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,692 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837692\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,695 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:18eac336-beab-4420-9223-b1003b7d37d1,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54540 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,697 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,697 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,707 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837707\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,707 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54550 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,709 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,709 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:176bbade-d417-4945-9cce-6617f90ee6c4,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,712 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837712\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,686 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54536 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,687 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,688 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e430ee06-df3b-4312-88d5-5ad8d9630137,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,692 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837692\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,695 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:18eac336-beab-4420-9223-b1003b7d37d1,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54540 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,696 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,697 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,697 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,707 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837707\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,707 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54550 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,708 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,709 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,709 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:176bbade-d417-4945-9cce-6617f90ee6c4,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,712 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837712\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,714 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca993087-8499-43ae-8500-44c7e5e6690c,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54558 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,716 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,716 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837719\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fd699f9d-d809-4072-9bc3-93a762973b8f,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,725 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837725\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,726 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:471d2db8-2a67-482a-b516-2e0b6ee8ab94,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54570 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,739 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837739\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,741 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,741 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54572 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,714 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ca993087-8499-43ae-8500-44c7e5e6690c,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54558 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,715 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,716 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,716 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837719\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,720 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54566 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,721 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fd699f9d-d809-4072-9bc3-93a762973b8f,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,722 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,725 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837725\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,726 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:471d2db8-2a67-482a-b516-2e0b6ee8ab94,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54570 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,727 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,739 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837739\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,741 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,741 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54572 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2ca616e4-b564-4ed9-9059-60e7ab88596e,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,747 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837747\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,747 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54584 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,750 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e3f1c35e-1101-406d-bc96-689d6a1f257e,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,754 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837754\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,754 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54600 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f76ee68f-0d43-4df8-b807-83cef8991d14,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,761 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837761\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,762 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54604 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,764 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:91df21d5-87b4-45ba-8a37-317e98959cee,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837776\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,777 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2ca616e4-b564-4ed9-9059-60e7ab88596e,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,742 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,747 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837747\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,747 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54584 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,749 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,750 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:e3f1c35e-1101-406d-bc96-689d6a1f257e,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,754 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837754\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,754 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54600 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,755 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,756 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f76ee68f-0d43-4df8-b807-83cef8991d14,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,761 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837761\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,762 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54604 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,763 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,764 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:91df21d5-87b4-45ba-8a37-317e98959cee,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837776\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,777 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54610 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,779 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bef135db-3a90-48e3-9f21-e7d016c8012b,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,792 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837792\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,793 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,794 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,794 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1dbe8ea7-e545-4886-aab5-c2c18c498085,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,796 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54616 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837805\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,806 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54630 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,808 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d2facbe8-8e8c-4fc4-bdb0-342b24cb3d9e,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,815 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837815\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,815 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,816 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,833 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f09ba6ed-7183-499d-aef4-0a6c4e87fde3,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54642 \"POST /invocations HTTP/1.1\" 500 19\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54610 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,778 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,779 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bef135db-3a90-48e3-9f21-e7d016c8012b,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,792 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837792\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,793 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,794 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,794 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:1dbe8ea7-e545-4886-aab5-c2c18c498085,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,796 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54616 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,797 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837805\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,806 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54630 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,807 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,808 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:d2facbe8-8e8c-4fc4-bdb0-342b24cb3d9e,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,815 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837815\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,815 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,816 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,833 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:f09ba6ed-7183-499d-aef4-0a6c4e87fde3,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54642 \"POST /invocations HTTP/1.1\" 500 19\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:18|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,851 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837851\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae1bc84b-5119-40d9-b475-f23deed0b7b4,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54650 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,858 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837858\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f57349c-f114-4518-959e-4b84d1283797,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54660 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837864\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da32ea71-07cc-4eff-8895-391994f2ff25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54664 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,870 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837870\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,871 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fb23a55a-32c5-46d0-8643-1c712debbfb6,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,834 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:18|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,851 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837851\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,852 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:ae1bc84b-5119-40d9-b475-f23deed0b7b4,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54650 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,853 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,858 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837858\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2f57349c-f114-4518-959e-4b84d1283797,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54660 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,860 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837864\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:da32ea71-07cc-4eff-8895-391994f2ff25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,865 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54664 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,866 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,870 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837870\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,871 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:fb23a55a-32c5-46d0-8643-1c712debbfb6,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54670 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,873 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,881 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837881\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54676 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,884 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62068cdc-57e9-4f3e-9e7a-115f80d2fa41,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837888\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,889 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54680 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bbe0ad51-9afa-4d8f-951e-3b64850d59f5,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,896 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837896\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,901 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,901 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54688 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a62702c1-a479-4477-b0cb-4f05df208e0a,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54670 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,872 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,873 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,881 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837881\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54676 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,883 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,884 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:62068cdc-57e9-4f3e-9e7a-115f80d2fa41,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837888\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,889 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54680 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,890 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:bbe0ad51-9afa-4d8f-951e-3b64850d59f5,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,896 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837896\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,901 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,901 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54688 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,902 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:a62702c1-a479-4477-b0cb-4f05df208e0a,timestamp:1661072837\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.842:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.842:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.842:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.843:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.844:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.845:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.846:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/95.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.875:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.875:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.876:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.876:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.876:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.876:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.876:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.877:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.877:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.877:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.877:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.877:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.878:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.878:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.878:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.878:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/96.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.934:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.934:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.934:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.935:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.936:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.936:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.936:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.936:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.936:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.937:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.937:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/97.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.961:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/98.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.990:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.990:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.990:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.990:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.991:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.991:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.991:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.991:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.992:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.992:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.992:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.992:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T09:07:17.993:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_output_100_1/99.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7f9a63836040>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2022-08-21T09:07:17,928 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837928\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,929 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,928 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837928\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,929 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,929 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:53092055-2cff-4f53-a0c5-b3e7df8ef5bc,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54694 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,941 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837941\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,941 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:51b1294e-1c5c-4642-af73-364aabf011ad,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54708 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,943 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,943 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,946 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837946\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8468b7c0-b9ef-4d2d-88f5-02a8ebcd0921,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54724 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,951 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837951\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,929 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:53092055-2cff-4f53-a0c5-b3e7df8ef5bc,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54694 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,930 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,941 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837941\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,941 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:51b1294e-1c5c-4642-af73-364aabf011ad,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54708 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,942 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,943 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,943 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,946 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837946\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,947 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:8468b7c0-b9ef-4d2d-88f5-02a8ebcd0921,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54724 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,948 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,951 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837951\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54732 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0396e201-15dc-44c2-b50e-65a323dc4da9,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,958 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837958\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,958 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f2d244e-3233-44f0-959d-6e18a15da4f6,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54734 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,960 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,964 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837964\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,964 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f302ac8-abe6-4bdf-9df7-f1206eaa9761,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,971 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837971\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,972 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,972 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54750 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2d4cfe14-869d-416e-86c4-ee2b13e0ee7c,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837977\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:56406ab2-ad25-49e4-bde8-ed90f3abb40a,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54732 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,953 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,952 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0396e201-15dc-44c2-b50e-65a323dc4da9,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,958 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837958\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,958 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f2d244e-3233-44f0-959d-6e18a15da4f6,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54734 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,959 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,960 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,964 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837964\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,964 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:0f302ac8-abe6-4bdf-9df7-f1206eaa9761,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,965 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,971 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837971\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,972 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,972 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54750 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,973 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:2d4cfe14-869d-416e-86c4-ee2b13e0ee7c,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837977\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,978 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:56406ab2-ad25-49e4-bde8-ed90f3abb40a,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54754 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,984 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837984\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,985 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54762 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[34m2022-08-21T09:07:17,987 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:56cfea18-35d8-4e75-a0c0-9a541e6cc1e3,timestamp:1661072837\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2022-08-21T09:07:17,979 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:54754 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,980 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,984 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661072837984\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,985 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:54762 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072822\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,986 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:59c63a18ea25,timestamp:1661072837\u001b[0m\n",
      "\u001b[35m2022-08-21T09:07:17,987 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:59c63a18ea25,requestID:56cfea18-35d8-4e75-a0c0-9a541e6cc1e3,timestamp:1661072837\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job pytorch-inference-2022-08-21-09-02-13-653: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m output_s3_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://sagemaker-han.s3.us-west-2.amazonaws.com/sagemaker/batch_transform_output_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_concurrent_transforms,max_payload)\n\u001b[1;32m      7\u001b[0m transformer \u001b[38;5;241m=\u001b[39m pytorch_model\u001b[38;5;241m.\u001b[39mtransformer(instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                         instance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml.m5.large\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                         output_path\u001b[38;5;241m=\u001b[39moutput_s3_path,\n\u001b[1;32m     10\u001b[0m                                         max_concurrent_transforms \u001b[38;5;241m=\u001b[39m max_concurrent_transforms,\n\u001b[1;32m     11\u001b[0m                                         max_payload \u001b[38;5;241m=\u001b[39m max_payload\n\u001b[1;32m     12\u001b[0m                                        )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS3Prefix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/x-image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/workflow/pipeline_context.py:248\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     run_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m self_instance\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mcontext\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/transformer.py:243\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, data, data_type, content_type, compression_type, split_type, job_name, input_filter, output_filter, join_source, experiment_config, model_client_config, wait, logs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_transform_job \u001b[38;5;241m=\u001b[39m _TransformJob\u001b[38;5;241m.\u001b[39mstart_new(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     model_client_config,\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_transform_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/transformer.py:440\u001b[0m, in \u001b[0;36m_TransformJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m--> 440\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_transform_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_transform_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/session.py:4023\u001b[0m, in \u001b[0;36mSession.logs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4020\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4023\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTransformJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   4025\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/session.py:3391\u001b[0m, in \u001b[0;36mSession._check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   3386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   3387\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   3388\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3389\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   3390\u001b[0m     )\n\u001b[0;32m-> 3391\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   3392\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   3393\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3394\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   3395\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job pytorch-inference-2022-08-21-09-02-13-653: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "max_concurrent_transforms = None\n",
    "max_payload = None\n",
    "\n",
    "inference_inputs = 's3://sagemaker-han/sagemaker/batch_transform'\n",
    "output_s3_path = 'https://sagemaker-han.s3.us-west-2.amazonaws.com/sagemaker/batch_transform_output_{}_{}'.format(max_concurrent_transforms,max_payload)\n",
    "\n",
    "\n",
    "model_data = 's3://sagemaker-us-west-2-608095525235/pytorch-training-2022-08-20-08-30-28-845/output/model.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data = model_data,\n",
    "                             entry_point='resnet_deploy.py',\n",
    "                             source_dir = 'src',\n",
    "                             framework_version='1.12.0',\n",
    "                             py_version='py38',\n",
    "                             role = role)\n",
    "\n",
    "transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")\n",
    "\n",
    "# transformer = o2v.transformer(instance_count=4,\n",
    "#                               instance_type=\"ml.p2.xlarge\",\n",
    "#                               max_concurrent_transforms=2,\n",
    "#                               max_payload=1,  # 1MB\n",
    "#                               strategy='MultiRecord',\n",
    "#                               env={'INFERENCE_PREFERRED_MODE': 'classification'},  # only useful with GPU\n",
    "#                               output_path=output_s3_path)\n",
    "\n",
    "# {\"in0\": [6, 17, 606, 19, 53, 67, 52, 12, 5, 10, 15, 10178, 7, 33, 652, 80, 15, 69, 821, 4], \"in1\": [16, 21, 13, 45, 14, 9, 80, 59, 164, 4]}\n",
    "# {\"in0\": [22, 1016, 32, 13, 25, 11, 5, 64, 573, 45, 5, 80, 15, 67, 21, 7, 9, 107, 4], \"in1\": [22, 32, 13, 25, 1016, 573, 3252, 4]}\n",
    "# {\"in0\": [774, 14, 21, 206], \"in1\": [21, 366, 125]}\n",
    "\n",
    "# {\"scores\":[0.195667684078216,0.395351558923721,0.408980727195739]}\n",
    "# {\"scores\":[0.251988261938095,0.258233487606048,0.489778339862823]}\n",
    "# {\"scores\":[0.280087798833847,0.368331134319305,0.351581096649169]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "41507e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest transform job: pytorch-inference-2022-08-21-08-18-59-697\n"
     ]
    }
   ],
   "source": [
    "print(\"Latest transform job:\", transformer.latest_transform_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "719ccee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[35mWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,025 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,173 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.6.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[34mMax heap size: 980 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.8\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,025 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,173 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.6.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[35mMax heap size: 980 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.8\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model=/opt/ml/model\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 2\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mModel config: N/A\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,189 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,227 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,235 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,235 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,239 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,267 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,562 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,563 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:10,572 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,312 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 2\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mLimit Maximum Image Pixels: true\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35mWorkflow Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mModel config: N/A\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,189 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,227 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,235 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,235 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,239 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,267 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,562 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,563 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:10,572 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,312 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,549 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.20628356933594|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.658847808837891|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,553 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,553 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6757.04296875|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,554 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:708.58984375|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:11,555 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,170 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,172 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]55\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,206 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,208 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]56\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,209 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,211 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,212 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,252 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,268 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063772268\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,274 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063772274\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,367 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:12,399 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,549 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.20628356933594|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,552 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.658847808837891|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,553 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,553 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:6757.04296875|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,554 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:708.58984375|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:11,555 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,170 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,172 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]55\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,206 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,208 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]56\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,209 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,211 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,212 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.8.13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,252 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,268 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063772268\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,274 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063772274\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,367 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:12,399 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 646\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,034 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,035 [INFO ] W-9000-model_1.0 TS_METRICS - W-9000-model_1.0.ms:2783|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,034 [INFO ] W-9001-model_1.0 TS_METRICS - W-9001-model_1.0.ms:2775|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,035 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:115|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:13,036 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:140|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 646\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,034 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 627\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,035 [INFO ] W-9000-model_1.0 TS_METRICS - W-9000-model_1.0.ms:2783|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,034 [INFO ] W-9001-model_1.0 TS_METRICS - W-9001-model_1.0.ms:2775|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,035 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:115|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:13,036 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:140|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,057 [INFO ] pool-2-thread-3 ACCESS_LOG - /169.254.255.130:40020 \"GET /ping HTTP/1.1\" 200 96\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,063 [INFO ] pool-2-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,112 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:40036 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,123 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779261\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,263 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779276\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,301 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,302 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,308 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,309 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 57\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,309 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,057 [INFO ] pool-2-thread-3 ACCESS_LOG - /169.254.255.130:40020 \"GET /ping HTTP/1.1\" 200 96\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,063 [INFO ] pool-2-thread-3 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,112 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:40036 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,123 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,261 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779261\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,263 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779276\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,301 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,302 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,307 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,308 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 46\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,309 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 57\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,309 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,310 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,310 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,312 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:44.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:305f85e4-09cf-4f97-a2d3-2ef046cbc26b,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,316 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d1e25bc3-6965-418d-bacd-343a85a120c8,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,421 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779421\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,422 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,441 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8a64ea9b-7fcc-4a69-bdb6-e1d5a19e1a5f,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,441 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,442 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,442 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,443 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,443 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,310 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,310 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,312 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:44.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:305f85e4-09cf-4f97-a2d3-2ef046cbc26b,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,316 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d1e25bc3-6965-418d-bacd-343a85a120c8,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,421 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779421\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,422 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,441 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8a64ea9b-7fcc-4a69-bdb6-e1d5a19e1a5f,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,441 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,442 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,442 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,443 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,443 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,557 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779557\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,573 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,574 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,574 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,557 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779557\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,559 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,573 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,574 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,574 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,575 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,575 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,576 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b9fbabf8-682c-475f-a236-37fee18fc26b,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,685 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779685\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,686 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,703 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:49b1bd6c-7ee6-4f70-949c-f75ec00ed16d,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,703 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,705 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,706 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,706 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,707 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,776 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,800 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 29\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,801 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,802 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,803 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,804 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bca203fd-ea2e-433a-a85e-27ed6eed1e51,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,808 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779808\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,575 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,575 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,576 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b9fbabf8-682c-475f-a236-37fee18fc26b,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,685 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779685\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,686 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,703 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:49b1bd6c-7ee6-4f70-949c-f75ec00ed16d,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,703 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,705 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,706 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,706 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,707 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,776 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,800 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 29\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,801 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,802 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,803 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,804 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bca203fd-ea2e-433a-a85e-27ed6eed1e51,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,808 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063779808\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,809 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,820 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,821 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,821 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,822 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,823 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:19,824 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5659e007-2d74-4b6c-8cae-c51c57a74d01,timestamp:1661063779\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780016\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,018 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,034 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,034 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,035 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:44030499-1604-4354-81e3-1a436cfa93cb,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,184 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780184\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,200 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,809 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,820 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,821 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,821 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,822 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,823 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:19,824 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5659e007-2d74-4b6c-8cae-c51c57a74d01,timestamp:1661063779\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780016\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,018 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,033 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,034 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,034 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,035 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:44030499-1604-4354-81e3-1a436cfa93cb,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,184 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780184\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,200 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,200 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,203 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,204 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,205 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,207 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.05|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f7821a7d-77a6-417d-92ef-bc9c652f649f,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,223 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780223\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,225 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780225\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,228 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,231 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,242 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,243 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,243 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,245 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,245 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,248 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.12|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:61144e25-567e-42f5-9304-ee2e12c8aa51,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,251 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,252 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.16|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a0c7268f-fcba-449c-9a44-137550e962bf,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,200 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,203 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,204 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,205 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,207 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.05|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f7821a7d-77a6-417d-92ef-bc9c652f649f,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,223 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780223\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,225 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780225\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,228 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,231 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,242 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,243 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,243 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,245 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,245 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,248 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.12|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:61144e25-567e-42f5-9304-ee2e12c8aa51,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,251 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,252 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.16|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a0c7268f-fcba-449c-9a44-137550e962bf,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,287 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780287\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,289 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,303 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,303 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a4590586-437b-4f26-8be0-fad18f9bd08a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,304 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,304 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,305 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,305 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,393 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780393\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,394 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,409 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,410 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,410 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,412 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d9050c09-cce3-4d5b-97c6-7581ec5da0a4,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,421 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780421\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,422 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,435 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780435\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,441 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,287 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780287\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,289 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,303 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,303 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a4590586-437b-4f26-8be0-fad18f9bd08a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,304 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,304 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,305 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,305 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,393 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780393\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,394 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,409 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,409 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,410 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,410 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,412 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d9050c09-cce3-4d5b-97c6-7581ec5da0a4,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,421 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780421\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,422 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,435 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780435\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,441 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,442 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,443 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,441 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:688f8e51-cef9-4865-a8d9-d9825f66687b,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,443 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,441 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:688f8e51-cef9-4865-a8d9-d9825f66687b,timestamp:1661063780\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:19.140:[sagemaker logs]: MaxConcurrentTransforms=16, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,457 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,458 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,458 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,459 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,459 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,457 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c4b99c0-930c-4c4e-8564-d31f1a71173d,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,498 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780498\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,500 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,521 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,521 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,522 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,528 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.22|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:df525ee5-d06b-4ec3-8342-2cd8ebea0802,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,457 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,458 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,458 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,459 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,459 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,457 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c4b99c0-930c-4c4e-8564-d31f1a71173d,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,498 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780498\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,500 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,521 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,521 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,522 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,528 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.22|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:df525ee5-d06b-4ec3-8342-2cd8ebea0802,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,641 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780641\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,643 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,659 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,659 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.98|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55b06955-16b3-4373-b37c-374c1b637bad,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,662 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,690 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780690\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,692 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,706 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,707 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,707 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,707 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780707\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,708 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,708 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,710 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,711 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6cb03280-c8fd-43ac-bca0-a5446bdb907b,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,712 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780712\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,714 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,725 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,727 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,727 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,728 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,728 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:80c1c1a3-cbe7-41ea-982d-e37c43a0adef,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,732 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 25\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,732 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,641 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780641\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,643 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,659 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,659 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.98|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55b06955-16b3-4373-b37c-374c1b637bad,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,660 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,662 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,690 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780690\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,692 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,706 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,707 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,707 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,707 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780707\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,708 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,708 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,710 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,711 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6cb03280-c8fd-43ac-bca0-a5446bdb907b,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,712 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780712\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,714 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,725 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,727 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,727 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,728 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,728 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:80c1c1a3-cbe7-41ea-982d-e37c43a0adef,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,732 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 25\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,732 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,733 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,733 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,739 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:401d5223-0c80-4ac6-b62a-190af83b5399,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,746 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780746\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,748 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,759 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.79|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:741900da-ba22-461b-a95d-4da4dddc1950,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,761 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,762 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,774 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780774\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,778 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6d52064a-5c30-48d9-80bb-2df3d3104f44,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,791 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,791 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,792 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,852 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780852\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,854 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,868 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.95|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3957888c-e4af-48b9-b9ae-f064fac6ffbb,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,869 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,869 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,870 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,733 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,733 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,739 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:401d5223-0c80-4ac6-b62a-190af83b5399,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,746 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780746\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,748 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,759 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,760 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.79|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:741900da-ba22-461b-a95d-4da4dddc1950,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,761 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,762 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,774 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780774\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,778 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,790 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6d52064a-5c30-48d9-80bb-2df3d3104f44,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,791 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,791 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,792 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,852 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780852\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,854 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,868 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.95|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3957888c-e4af-48b9-b9ae-f064fac6ffbb,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,869 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,869 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,870 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,871 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,899 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780898\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,900 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,916 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,916 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c38b81a-f8db-4d30-b05d-c84da17d6a08,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,969 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780969\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,970 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2edf731-7ad1-4806-a86d-81b01e5d2aec,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,984 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,984 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:20,985 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,128 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781128\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,130 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,145 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b7a52e78-0e1c-49e4-a2ba-e0059c2cfab3,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,145 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,147 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,156 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781156\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,871 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,899 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780898\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,900 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,916 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,916 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c38b81a-f8db-4d30-b05d-c84da17d6a08,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,917 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,969 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063780969\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,970 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2edf731-7ad1-4806-a86d-81b01e5d2aec,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,983 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,984 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,984 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:20,985 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063780\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,128 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781128\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,130 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,145 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b7a52e78-0e1c-49e4-a2ba-e0059c2cfab3,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,145 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,146 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,147 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,156 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781156\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,164 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,170 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,170 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,171 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,171 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,172 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,172 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.95|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f184ddaf-9983-4f17-ab51-8452e9993baa,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,200 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781200\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,205 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,218 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781218\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,219 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,232 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:27.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2770355a-94c9-426b-9730-ad1c80bfa547,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 34\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,234 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,235 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59961ecf-d961-450a-b6f5-543693a3c197,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,241 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,241 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781293\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,297 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781297\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,302 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,332 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,332 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:36.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:31df3229-ad80-4d90-ac6e-2ed83c20a37d,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,333 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 41\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,164 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,170 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,170 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,171 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,171 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,172 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,172 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.95|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f184ddaf-9983-4f17-ab51-8452e9993baa,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,200 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781200\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,205 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,218 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781218\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,219 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,232 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:27.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2770355a-94c9-426b-9730-ad1c80bfa547,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 34\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,233 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,234 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,235 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59961ecf-d961-450a-b6f5-543693a3c197,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,240 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,241 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,241 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781293\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,297 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781297\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,302 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,332 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,332 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:36.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:31df3229-ad80-4d90-ac6e-2ed83c20a37d,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,333 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 41\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,333 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,334 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,334 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,335 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 39\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,337 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.17|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:aae004ed-e0e5-417a-9959-1dc45403abc9,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,366 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781366\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,367 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,380 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,381 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,381 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,382 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,383 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,382 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:661d5eea-bd1f-4ba5-a5b0-f3550b5e8932,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,393 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781393\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,394 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,409 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d57e9ae1-ea47-4c3a-8a6b-c2248c85a7e2,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,333 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,334 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,334 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,335 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 39\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,336 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,337 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.17|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:aae004ed-e0e5-417a-9959-1dc45403abc9,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,366 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781366\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,367 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,380 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,381 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,381 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,382 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,383 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,382 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:661d5eea-bd1f-4ba5-a5b0-f3550b5e8932,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,393 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781393\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,394 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,407 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,409 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d57e9ae1-ea47-4c3a-8a6b-c2248c85a7e2,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,484 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781484\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,484 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781484\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,486 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,503 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.89|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f6d5263e-e151-40c8-91be-04780a32018c,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,503 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,486 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,503 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.89|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f6d5263e-e151-40c8-91be-04780a32018c,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,503 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,505 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,504 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,505 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781507\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,508 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,530 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:37eee410-8267-427e-a711-4082da703c29,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,530 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,531 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781546\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,547 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,563 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1cb05971-4981-48c9-bca7-18787d84b122,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,563 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,564 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,564 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,565 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,565 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,576 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781576\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,578 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,584 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781584\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,588 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,599 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781507\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,508 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,530 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,529 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:37eee410-8267-427e-a711-4082da703c29,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,530 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,531 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,546 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781546\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,547 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,563 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1cb05971-4981-48c9-bca7-18787d84b122,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,563 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,564 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,564 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,565 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,565 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,576 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781576\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,578 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,584 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781584\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,588 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,599 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,600 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,601 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,604 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:21.11|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b01f0c9c-daf9-4a7f-b48a-c6c37888f53f,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.97|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:83d33d33-2118-40dc-8c77-3973b5ff94d9,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 29\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,623 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781623\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,648 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,650 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,653 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4bc3a812-31be-4606-b924-792baeec6b50,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781661\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,680 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ea29e889-8f8f-46aa-9800-f75c575a0d95,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,682 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,681 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781681\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,682 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,601 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,604 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:21.11|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b01f0c9c-daf9-4a7f-b48a-c6c37888f53f,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.97|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:83d33d33-2118-40dc-8c77-3973b5ff94d9,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,613 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 29\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,614 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,623 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781623\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,648 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,649 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,650 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,653 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4bc3a812-31be-4606-b924-792baeec6b50,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781661\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,680 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ea29e889-8f8f-46aa-9800-f75c575a0d95,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,682 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,681 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781681\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,682 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,683 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,683 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59f3f024-cc89-4b03-886e-a649b3f94bce,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781718\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,727 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,742 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,742 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2352f82c-4004-45f6-a522-1a13ad1374d4,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,743 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,743 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,744 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,825 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781825\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,827 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,847 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:af4a4d1a-4417-487b-8baf-c5c67563d295,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,683 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,683 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,702 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,703 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59f3f024-cc89-4b03-886e-a649b3f94bce,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781718\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,727 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,742 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,742 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2352f82c-4004-45f6-a522-1a13ad1374d4,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,743 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,743 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,744 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,825 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781825\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,827 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,847 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:af4a4d1a-4417-487b-8baf-c5c67563d295,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781853\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,858 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,872 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,873 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.18|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:794e86af-db1b-40ff-9676-820a886c968c,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,874 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,875 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,875 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,876 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781977\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,983 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,996 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,996 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f6497c22-f7cd-4db9-93f0-d1d9e74805fa,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:21,998 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:12|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,022 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782022\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,853 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781853\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,858 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,872 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,873 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.18|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:794e86af-db1b-40ff-9676-820a886c968c,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,874 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,875 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,875 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,876 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,977 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063781977\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,983 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,996 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,996 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f6497c22-f7cd-4db9-93f0-d1d9e74805fa,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:21,998 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:12|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,022 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782022\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64f741e2-3c83-43b3-9ba0-12955881081a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,045 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,088 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782088\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64f741e2-3c83-43b3-9ba0-12955881081a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,043 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,044 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,045 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,088 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782088\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,095 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,107 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,108 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:29894ab6-df8b-4e0a-bb9f-6af2eff35ffa,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,110 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,138 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782138\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782140\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,144 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,155 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,174 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,175 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:30.2|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0464c5b5-17fe-403f-beaf-f479923667ae,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 43\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,180 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6dff0f34-eafe-40db-a3d6-3bc773a3dba1,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 43\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,183 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,183 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,095 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,107 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,108 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:29894ab6-df8b-4e0a-bb9f-6af2eff35ffa,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,109 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,110 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,138 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782138\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,140 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782140\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,144 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,155 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,174 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,175 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:30.2|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0464c5b5-17fe-403f-beaf-f479923667ae,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 43\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,180 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,180 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6dff0f34-eafe-40db-a3d6-3bc773a3dba1,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 43\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,182 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,183 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,183 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,219 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782219\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,222 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782226\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,228 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,253 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a868085e-262b-4a06-aeb1-84b52c9cffc0,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:31.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c9c01ae4-fa99-47c1-b08d-8ac9b2a1590e,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,254 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,255 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 36\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,256 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,256 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,256 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782364\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,382 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,383 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,383 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,384 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,219 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782219\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,222 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,226 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782226\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,228 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,253 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a868085e-262b-4a06-aeb1-84b52c9cffc0,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:31.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c9c01ae4-fa99-47c1-b08d-8ac9b2a1590e,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,254 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,255 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 36\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,255 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,256 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,256 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,256 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782364\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,382 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,382 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,383 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,383 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,384 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2c02bb79-4221-4e49-a253-226bc1570179,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,456 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782456\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,459 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2c02bb79-4221-4e49-a253-226bc1570179,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,456 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782456\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,459 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,479 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,481 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3979ac6a-2392-4ee4-aea2-d9dc55b6248e,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782549\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,553 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,571 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,479 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,480 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,481 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3979ac6a-2392-4ee4-aea2-d9dc55b6248e,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782549\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,553 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,571 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,573 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5c50af39-4679-4a85-bd5a-2a30f7a72239,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,611 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782610\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,631 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.25|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0690d303-d5be-402e-bae4-dc5c106c9e76,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,632 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,633 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,633 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,634 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,634 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,706 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782706\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,707 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,721 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,723 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,724 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f69dc3d-1dbe-4d00-9d9c-963e6043d79b,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,752 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782752\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,755 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,769 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,572 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,573 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:20.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5c50af39-4679-4a85-bd5a-2a30f7a72239,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,611 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782610\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,631 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.25|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0690d303-d5be-402e-bae4-dc5c106c9e76,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,632 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,633 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,633 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,634 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,634 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,706 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782706\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,707 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,721 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,722 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,723 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,724 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f69dc3d-1dbe-4d00-9d9c-963e6043d79b,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,752 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782752\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,755 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,768 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,769 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,770 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,770 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0bc59b9f-24cb-4774-9656-0b54398fe354,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,782 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,784 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,798 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,800 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,801 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,802 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d13db2c3-c3e1-48a6-a967-4625ebda9902,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,950 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782950\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,952 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f7094f3e-cd69-4ed4-b6b5-3e62203d3eb3,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,969 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,970 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782994\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:22,996 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,023 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,024 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,025 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,770 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,770 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0bc59b9f-24cb-4774-9656-0b54398fe354,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,782 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,784 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,798 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,800 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,801 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,802 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d13db2c3-c3e1-48a6-a967-4625ebda9902,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,950 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782950\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,952 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f7094f3e-cd69-4ed4-b6b5-3e62203d3eb3,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,968 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,969 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,970 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063782994\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:22,996 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063782\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,023 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,024 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,025 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,025 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,026 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,029 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:48c13016-44d1-4df0-b17f-c8e76b3338fd,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,031 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783031\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,048 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,048 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,051 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ddb0ef41-4a9c-4c24-8690-4ae4db5afa66,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,052 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783052\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,055 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e04017a1-503e-4df5-b332-9d6deaca9ae4,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,072 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,072 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,139 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783139\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,142 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,025 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,026 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,029 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:48c13016-44d1-4df0-b17f-c8e76b3338fd,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,031 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783031\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,047 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,048 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,048 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,051 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ddb0ef41-4a9c-4c24-8690-4ae4db5afa66,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,052 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783052\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,055 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,071 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e04017a1-503e-4df5-b332-9d6deaca9ae4,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,072 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,072 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,139 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783139\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,142 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.98|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8060eedd-08d0-4dc2-8469-126a72665880,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,158 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,158 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,170 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783170\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,176 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,193 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.82|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b127fd3-139c-4fd4-ba54-eae28dc2fd1e,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783264\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,267 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783276\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,283 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:29.21|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:155c31c6-3a0d-4edf-bdf5-989caadb4ca6,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,296 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,296 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,307 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 32\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.98|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8060eedd-08d0-4dc2-8469-126a72665880,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,157 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,158 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,158 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,170 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783170\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,176 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,193 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.82|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b127fd3-139c-4fd4-ba54-eae28dc2fd1e,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,198 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783264\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,267 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783276\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,283 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:29.21|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:155c31c6-3a0d-4edf-bdf5-989caadb4ca6,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,295 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,296 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,296 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,307 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,307 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 32\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eccfc49f-4cd2-4b71-9850-2bede170971a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783314\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,327 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,327 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3722516b-b8ed-4be4-a0e1-263974911577,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783363\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,365 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783365\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,373 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,388 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ea604a96-aac2-4c40-8df3-1b73728862b4,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,390 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,390 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,396 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eccfc49f-4cd2-4b71-9850-2bede170971a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,308 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783314\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,327 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,327 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3722516b-b8ed-4be4-a0e1-263974911577,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,328 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783363\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,365 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783365\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,373 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,388 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,389 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:24.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ea604a96-aac2-4c40-8df3-1b73728862b4,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,390 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,390 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,396 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,396 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:621eb0c6-1c02-4e4c-b8b1-89725ff9939f,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 33\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,425 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783425\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,426 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783436\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,454 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,454 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:27.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:da0c399c-342f-4f01-a4f3-bc2daecb371a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,396 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:621eb0c6-1c02-4e4c-b8b1-89725ff9939f,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 33\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,397 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,425 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783425\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,426 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783436\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,454 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,454 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:27.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:da0c399c-342f-4f01-a4f3-bc2daecb371a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,456 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,456 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783456\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,457 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,455 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,456 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,456 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783456\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,457 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,464 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,465 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,464 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:20e5b5b6-a0af-43df-b682-11b0c6ee61c6,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,466 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,467 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,467 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,475 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55420 \"POST /invocations HTTP/1.1\" 200 35\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:14|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,477 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,464 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,465 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 30\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,464 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:20e5b5b6-a0af-43df-b682-11b0c6ee61c6,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,466 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,467 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,467 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,475 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55420 \"POST /invocations HTTP/1.1\" 200 35\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,476 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:14|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,477 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,477 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:acd49299-7066-4329-beb6-8bd9498d099c,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783484\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,484 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,498 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:118ed100-3b21-4dd7-bb59-88739cec89d7,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,498 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,506 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783506\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,507 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,477 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:acd49299-7066-4329-beb6-8bd9498d099c,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783484\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,484 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,498 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:118ed100-3b21-4dd7-bb59-88739cec89d7,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,498 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,499 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,506 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783506\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,507 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,522 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f8c90815-56fe-43a1-8247-04766868fc08,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,592 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783592\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,593 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783600\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,604 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a834caf3-9f53-4668-a46c-933d1d1d335c,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,615 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,615 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,622 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:805ad295-bafc-4608-b683-3319395cb851,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,624 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,651 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783651\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,652 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eaccdf06-49f4-4d48-97ee-b6dc4c61b6e9,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,668 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,668 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,521 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,522 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f8c90815-56fe-43a1-8247-04766868fc08,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,592 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783592\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,593 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783600\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,604 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a834caf3-9f53-4668-a46c-933d1d1d335c,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,614 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,615 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,615 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,622 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:805ad295-bafc-4608-b683-3319395cb851,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,623 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,624 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,651 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783651\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,652 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eaccdf06-49f4-4d48-97ee-b6dc4c61b6e9,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,667 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,668 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,668 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,671 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783671\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,672 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,689 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.12|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ad3d7263-06e6-42db-a708-b181d0e248e2,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,753 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783753\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,754 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,766 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d7fd02d4-b335-4967-af1b-64d1391f85c4,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,766 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,767 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,768 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,769 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,769 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,781 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783781\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,784 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41dafd9a-f28d-413e-ab57-7eeee734e63e,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,802 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,802 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,840 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783840\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,841 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,854 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.99|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb77cc91-caf3-427c-aeed-4783454a6f3e,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,855 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,671 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783671\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,672 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,689 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.12|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ad3d7263-06e6-42db-a708-b181d0e248e2,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,697 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,753 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783753\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,754 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,766 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d7fd02d4-b335-4967-af1b-64d1391f85c4,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,766 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,767 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,768 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,769 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,769 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,781 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783781\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,784 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:17.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41dafd9a-f28d-413e-ab57-7eeee734e63e,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,801 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,802 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,802 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,840 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783840\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,841 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,854 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.99|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb77cc91-caf3-427c-aeed-4783454a6f3e,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,855 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,856 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,856 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,857 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,857 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,857 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783857\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,873 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:06900a9f-9580-4383-b83e-58732840e218,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,875 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,881 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783881\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,882 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,895 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.02|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:80bafa5c-27c7-42fe-9bab-0023dd916654,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,856 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,856 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,857 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,857 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,857 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783857\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,873 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:06900a9f-9580-4383-b83e-58732840e218,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,874 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,875 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,881 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783881\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,882 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,895 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,894 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:12.02|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:80bafa5c-27c7-42fe-9bab-0023dd916654,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783906\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:11026ff3-36b2-4519-9546-cc76e1ef23f3,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783906\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:15.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:11026ff3-36b2-4519-9546-cc76e1ef23f3,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,924 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,925 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,925 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,928 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783928\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,929 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,941 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:73eda7ba-ebed-4fb6-a3e7-4c5b824c23b8,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,941 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,925 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,925 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,928 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783928\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,929 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,941 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:73eda7ba-ebed-4fb6-a3e7-4c5b824c23b8,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,941 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,942 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,942 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,943 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,943 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,960 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783960\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,964 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,942 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 15\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,942 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,943 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,943 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,960 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783960\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,964 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:84424c1d-e1d1-4312-94c0-6502615a22e6,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,984 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783984\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,986 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,997 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55cce3d3-ee26-48a4-8ed7-9475f384a156,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:23,999 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,000 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,020 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784020\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,029 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784029\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,031 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:14.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:84424c1d-e1d1-4312-94c0-6502615a22e6,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,976 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 18\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,977 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,984 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063783984\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,986 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,997 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:11.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55cce3d3-ee26-48a4-8ed7-9475f384a156,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,998 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:23,999 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063783\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,000 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,020 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784020\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,029 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784029\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,031 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,044 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.32|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6706a40e-bd36-4b24-805e-bb6e13c0c3d7,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,046 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,050 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,044 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:22.32|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6706a40e-bd36-4b24-805e-bb6e13c0c3d7,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,045 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,046 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,050 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,052 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9dec379-9067-4d57-869b-ea69dccb4173,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,075 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784074\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,076 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:573ce314-3be7-4076-88bc-147bed74c825,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,097 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,097 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,124 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784124\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,125 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,145 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ca219d97-0b20-43f4-a2c3-efcfc5aafac9,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,145 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,147 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,150 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784150\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,151 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,168 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,168 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.36|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f33a3383-2b03-4fc1-acdd-adc4658ca60f,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,170 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,187 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784187\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,188 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,052 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,051 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9dec379-9067-4d57-869b-ea69dccb4173,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,075 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784074\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,076 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:18.93|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:573ce314-3be7-4076-88bc-147bed74c825,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,096 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,097 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,097 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,124 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784124\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,125 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,145 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ca219d97-0b20-43f4-a2c3-efcfc5aafac9,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,145 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,146 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,147 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,150 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784150\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,151 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,168 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 19\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,169 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,168 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.36|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f33a3383-2b03-4fc1-acdd-adc4658ca60f,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,170 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,187 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784187\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,188 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,202 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f11896f0-caca-4f07-9f02-74dc20bcde18,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,203 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,203 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,203 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784203\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,206 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,217 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784217\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,218 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,229 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,202 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:13.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f11896f0-caca-4f07-9f02-74dc20bcde18,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,203 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 16\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,203 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,204 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,203 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784203\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,206 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,217 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784217\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,218 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,229 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 26\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,231 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,231 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784231\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.2|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1c0f89f0-3299-466f-a439-95e1e26f997d,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,232 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,239 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,239 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53b5c30a-22c1-4c3c-9425-b5f9836cc3ab,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55434 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:abeff2cc-ef2e-43c0-ab6a-3754cb369d8f,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,267 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784267\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,268 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.96|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b8a7986d-662e-4c31-95c3-e40f4bac4c12,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,285 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784285\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,286 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784294\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,296 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,231 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,231 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784231\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,230 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:23.2|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1c0f89f0-3299-466f-a439-95e1e26f997d,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,232 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 20\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,239 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,239 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,238 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53b5c30a-22c1-4c3c-9425-b5f9836cc3ab,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55434 \"POST /invocations HTTP/1.1\" 200 23\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:16.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:abeff2cc-ef2e-43c0-ab6a-3754cb369d8f,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,267 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784267\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,268 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:10.96|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b8a7986d-662e-4c31-95c3-e40f4bac4c12,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,280 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,281 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,285 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784285\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,286 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784294\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,296 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,312 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,314 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:128aa196-5718-414b-8c31-d4b105e4ebc7,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bd8be4b5-9b16-4f85-9bae-e58d5b3723c8,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,334 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784334\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,335 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,362 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,362 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1826a997-e763-4ae6-9e2f-cc674bb5c770,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,312 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,313 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,314 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:128aa196-5718-414b-8c31-d4b105e4ebc7,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 21\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:19.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bd8be4b5-9b16-4f85-9bae-e58d5b3723c8,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 22\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,317 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,334 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784334\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,335 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,362 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 27\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,362 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 200 28\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,363 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:26.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1826a997-e763-4ae6-9e2f-cc674bb5c770,timestamp:1661063784\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.052:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/13.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.054:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/10.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.055:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.055:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.056:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/15.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.120:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8065fe50>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.121:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/12.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8065fe50>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.132:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/11.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.139:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.139:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.139:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.139:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.139:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.140:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.140:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.140:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.140:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.140:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.160:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/16.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.221:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.222:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/1.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.270:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.270:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/14.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.284:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.285:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/19.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.304:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.304:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.304:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/0.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe80554400>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.308:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.309:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/17.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.312:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.313:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/18.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784587\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784589\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,595 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,617 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 500 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,618 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,618 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,619 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.18|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9612a2ec-83f2-4532-8b11-9768eb8f2e17,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,620 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,620 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 500 31\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,620 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0aca590a-912e-4744-b083-6178b4f625d5,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,620 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,621 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,621 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,623 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784623\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,625 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55446 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,587 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784587\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,588 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784589\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,595 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,617 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 29\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:40050 \"POST /invocations HTTP/1.1\" 500 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,618 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,618 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,619 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.18|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9612a2ec-83f2-4532-8b11-9768eb8f2e17,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,620 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,620 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:40052 \"POST /invocations HTTP/1.1\" 500 31\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,620 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:28.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0aca590a-912e-4744-b083-6178b4f625d5,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,620 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,621 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,621 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,623 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784623\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,625 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55446 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,624 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:376303c1-90f7-4cfe-96a5-7cd0c2040a2d,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,628 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784663\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,665 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55438 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c2fb0dcc-43b8-441f-a1a9-99bb61a3ad25,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,667 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,673 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784673\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,674 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784674\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,675 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,675 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:14c1a4b0-fdb1-4a69-97ff-52591651f7cd,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55448 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,678 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784680\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,681 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,624 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:376303c1-90f7-4cfe-96a5-7cd0c2040a2d,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,628 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784663\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,665 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,665 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55438 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c2fb0dcc-43b8-441f-a1a9-99bb61a3ad25,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,666 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,667 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,673 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784673\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,674 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784674\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,675 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,675 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:14c1a4b0-fdb1-4a69-97ff-52591651f7cd,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55448 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,676 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,678 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,680 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784680\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,681 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55480 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,683 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,683 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3ae2f75-20de-462e-aef6-c4509e52426e,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55464 \"POST /invocations HTTP/1.1\" 500 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,687 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,691 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:4.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6834fb96-7336-494d-a839-efde2ef70548,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,696 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784696\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,698 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55488 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55480 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,683 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,683 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3ae2f75-20de-462e-aef6-c4509e52426e,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55464 \"POST /invocations HTTP/1.1\" 500 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,686 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,687 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,691 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:4.09|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6834fb96-7336-494d-a839-efde2ef70548,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,696 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784696\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,698 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55488 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,705 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,705 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:780cd7e6-110a-4ece-8721-29aa1fd40319,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,712 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784712\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,725 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55504 \"POST /invocations HTTP/1.1\" 500 14\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,727 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,727 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:13|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,728 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784728\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,729 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9d1e2be2-7bf6-4457-a8f2-6f4be283063e,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,729 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55508 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,731 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:19441542-a11a-4afb-ac6c-4159fb6186a2,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784736\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,737 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784737\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,738 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55554 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9a00eb24-18d7-465d-a1ae-44f0132f6a6a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,740 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784740\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,740 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,699 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,705 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,705 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:780cd7e6-110a-4ece-8721-29aa1fd40319,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,712 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784712\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,725 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55504 \"POST /invocations HTTP/1.1\" 500 14\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,726 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,727 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,727 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:13|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,728 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784728\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,729 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9d1e2be2-7bf6-4457-a8f2-6f4be283063e,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,729 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55508 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,730 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,731 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:19441542-a11a-4afb-ac6c-4159fb6186a2,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,736 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784736\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,737 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,737 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784737\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,738 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,738 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55554 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9a00eb24-18d7-465d-a1ae-44f0132f6a6a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,739 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,740 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784740\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,740 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,740 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,741 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55538 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:84b26193-635e-4a74-8604-5c8ae65555bb,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55522 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,744 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9a822f8-80ea-41a7-a5a8-0852709dfec5,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,745 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784745\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55564 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,748 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2391c755-9778-4c7f-b606-977fb2c287ae,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,762 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784762\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,763 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,765 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5f63f2f-1eaa-4c00-b423-d746c290f477,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,765 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55572 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,740 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,741 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55538 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:84b26193-635e-4a74-8604-5c8ae65555bb,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,742 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55522 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,743 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,744 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9a822f8-80ea-41a7-a5a8-0852709dfec5,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,745 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784745\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,746 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55564 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,747 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,748 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2391c755-9778-4c7f-b606-977fb2c287ae,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,762 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784762\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,763 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,765 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5f63f2f-1eaa-4c00-b423-d746c290f477,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,765 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55572 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,766 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,865 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784865\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:28034627-a265-4f7b-a349-fffffdd5a56a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55588 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784875\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,881 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55592 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,884 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a018d968-9984-43bd-87cc-c7ed2d36c249,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,884 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784884\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,885 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,885 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784885\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,886 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,886 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:71ae0a68-66a7-48fb-9824-43788978d81b,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,886 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55596 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,889 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,889 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55594 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:15312993-692a-4f49-a190-446a907612c7,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,865 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784865\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:28034627-a265-4f7b-a349-fffffdd5a56a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55588 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,867 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784875\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,881 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55592 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,882 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,884 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a018d968-9984-43bd-87cc-c7ed2d36c249,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,884 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784884\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,885 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,885 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784885\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,886 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,886 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:71ae0a68-66a7-48fb-9824-43788978d81b,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,886 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55596 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,887 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,889 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,889 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55594 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:15312993-692a-4f49-a190-446a907612c7,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,890 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,912 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784912\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,913 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784913\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,914 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4c601ab7-6c39-43fa-99c8-fad6922a1480,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55608 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,915 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,916 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,916 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55636 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,918 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,918 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6bc2f314-5f85-4e7e-b571-e547544a15a2,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784923\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,924 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5836cfb3-af9d-4b2e-a97a-313d49d14909,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,926 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,926 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,942 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784942\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,942 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784942\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,943 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,944 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55664 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,912 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784912\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,913 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784913\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,914 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4c601ab7-6c39-43fa-99c8-fad6922a1480,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55608 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,915 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,915 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,916 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,916 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55636 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,917 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,918 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,918 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6bc2f314-5f85-4e7e-b571-e547544a15a2,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784923\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,924 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5836cfb3-af9d-4b2e-a97a-313d49d14909,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,925 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,926 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,926 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,942 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784942\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,942 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784942\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,943 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,944 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55664 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,944 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,945 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8069a58c-6685-4838-9607-14fb8f64eaae,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,945 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55648 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,948 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784948\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,948 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,948 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,948 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,949 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cfe54d51-c88e-4c88-91be-980440b1e9b4,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,951 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:17413afa-a716-4b80-8ba9-b0a4dc4eaff8,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55670 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,953 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784959\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784960\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,961 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,961 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f98280a6-b7c9-4f67-b7ed-a4e41346c087,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55680 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,962 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,963 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,963 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55696 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,963 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,945 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8069a58c-6685-4838-9607-14fb8f64eaae,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,945 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55648 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,947 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,948 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784948\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,948 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,948 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,948 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,949 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cfe54d51-c88e-4c88-91be-980440b1e9b4,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,951 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:17413afa-a716-4b80-8ba9-b0a4dc4eaff8,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55670 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,952 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,953 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784959\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784960\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,961 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,961 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f98280a6-b7c9-4f67-b7ed-a4e41346c087,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55680 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,962 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,962 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,963 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,963 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55696 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,963 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,964 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,964 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784965\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,965 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d992cdda-88de-4d43-97c1-e7f0117590da,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,966 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55704 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,968 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,969 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:21f03177-9ef9-4ff1-91d3-2b24dd4627fa,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784986\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,987 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e12b9b28-da37-469a-b17f-f174bb26ad6d,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55710 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,989 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:24,989 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,023 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785023\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,024 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55714 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,026 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:229b8787-b74c-4775-bbaf-12eaf34d36cb,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785033\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:273d4683-3b1e-4a98-b59b-467b94817602,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55724 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,964 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,964 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784965\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,965 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d992cdda-88de-4d43-97c1-e7f0117590da,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,966 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55704 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,967 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,968 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,969 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:21f03177-9ef9-4ff1-91d3-2b24dd4627fa,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063784986\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,987 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e12b9b28-da37-469a-b17f-f174bb26ad6d,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55710 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,988 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,989 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:24,989 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,023 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785023\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,024 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55714 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,025 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,026 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:229b8787-b74c-4775-bbaf-12eaf34d36cb,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785033\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:273d4683-3b1e-4a98-b59b-467b94817602,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55724 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,068 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785068\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,069 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55730 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,072 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55e17e50-6119-43cd-b605-27ff2f4ad7de,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785076\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,077 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,078 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f35b6b99-0971-453b-97fb-63b03e4bbcb5,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55734 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,085 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785085\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,088 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,088 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55736 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,090 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.17|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a9fad007-a48f-4b02-bb28-0d2857ea08b6,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,099 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785099\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,101 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,102 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:27835dfd-8ade-4496-8bfc-bcaa6e0dcec3,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55742 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,110 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785110\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,111 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ecd558e6-b51d-4a37-91a9-de9e4f07aa73,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55744 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785118\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,119 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5be32068-2f31-4dc9-a0e5-ed3f57f2af71,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,068 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785068\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,069 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55730 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,071 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,072 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55e17e50-6119-43cd-b605-27ff2f4ad7de,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785076\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,077 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,078 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f35b6b99-0971-453b-97fb-63b03e4bbcb5,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,078 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55734 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,079 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,085 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785085\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,088 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,088 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55736 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,089 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,090 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.17|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a9fad007-a48f-4b02-bb28-0d2857ea08b6,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,099 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785099\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,101 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,102 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:27835dfd-8ade-4496-8bfc-bcaa6e0dcec3,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55742 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,103 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,110 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785110\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,111 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ecd558e6-b51d-4a37-91a9-de9e4f07aa73,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,112 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55744 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,113 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785118\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,119 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5be32068-2f31-4dc9-a0e5-ed3f57f2af71,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55746 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,121 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,125 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785125\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,125 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,126 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:238338b6-a4cd-4b42-ae28-8e15956d157d,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,126 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,136 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785136\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55768 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,139 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,139 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785140\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,140 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6e823734-0baa-4e90-a1aa-ac8e8097b563,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,141 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6876a86-198f-43a2-89d0-36d20ad9a426,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55798 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,143 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,143 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785143\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4485867e-dec9-49fc-a908-d2f22c58e8f3,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55782 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,149 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785149\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,150 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f964ef8d-480a-475f-bae2-97b1c1675fda,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55766 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55746 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,120 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,121 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,125 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785125\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,125 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,126 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:238338b6-a4cd-4b42-ae28-8e15956d157d,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,126 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55752 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,127 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,136 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785136\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55768 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,138 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,139 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,139 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785140\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,140 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6e823734-0baa-4e90-a1aa-ac8e8097b563,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,141 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6876a86-198f-43a2-89d0-36d20ad9a426,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55798 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,142 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,143 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,143 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,143 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785143\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4485867e-dec9-49fc-a908-d2f22c58e8f3,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,144 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55782 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,145 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,149 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785149\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,150 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f964ef8d-480a-475f-bae2-97b1c1675fda,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55766 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,151 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,152 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,166 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785166\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,166 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,167 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2e0b20bf-82ae-44f2-930c-52a2506f9a76,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,167 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,208 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55804 \"POST /invocations HTTP/1.1\" 500 43\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,214 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785214\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,215 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,216 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2d0ee8a1-edaa-4af9-8e7b-1404e536e12b,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55816 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785218\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,217 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785217\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,219 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,220 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55834 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,220 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,220 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,221 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,221 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f475ef4b-65f8-4461-8155-6e9702313bff,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,221 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3bd512dc-b752-47ac-b990-b0b4b69d5a92,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,221 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,222 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55826 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,222 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,222 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,228 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785228\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,229 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55838 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d34eab2e-7a84-43c6-9930-b5d56915bb3a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,231 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,231 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,234 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785234\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,235 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,235 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1d9b9431-3b74-43de-99b5-a356f722f59a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55840 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,239 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785239\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,152 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,166 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785166\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,166 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,167 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2e0b20bf-82ae-44f2-930c-52a2506f9a76,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,167 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,208 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55804 \"POST /invocations HTTP/1.1\" 500 43\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,209 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,214 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785214\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,215 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,216 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2d0ee8a1-edaa-4af9-8e7b-1404e536e12b,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55816 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,217 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,218 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785218\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,217 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785217\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,219 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,220 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55834 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,220 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,220 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,221 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,221 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f475ef4b-65f8-4461-8155-6e9702313bff,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,221 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3bd512dc-b752-47ac-b990-b0b4b69d5a92,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,221 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,222 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55826 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,222 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,222 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,223 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,228 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785228\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,229 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,229 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55838 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d34eab2e-7a84-43c6-9930-b5d56915bb3a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,230 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,231 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,231 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,234 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785234\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,235 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,235 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1d9b9431-3b74-43de-99b5-a356f722f59a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55840 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,236 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,239 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785239\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,240 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55854 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,242 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e7f16532-06c9-478a-8881-cbbf24082546,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,243 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785243\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,244 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c11f5bf0-d163-4853-9bf5-0c117d12bfb3,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,246 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785246\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59c57d80-2acb-4d75-89dd-db307812f6e2,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55868 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,251 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785251\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41f52c41-dfc1-4ef6-94a3-3f0374d6fc78,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55858 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,255 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,255 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,262 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785262\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,263 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,263 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:69edb54e-4afc-4d6d-98fa-886f581c1e86,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55878 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,240 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55854 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,242 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,241 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e7f16532-06c9-478a-8881-cbbf24082546,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,243 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785243\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,244 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c11f5bf0-d163-4853-9bf5-0c117d12bfb3,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,245 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55870 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,246 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785246\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59c57d80-2acb-4d75-89dd-db307812f6e2,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55868 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,249 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,251 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785251\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41f52c41-dfc1-4ef6-94a3-3f0374d6fc78,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55858 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,255 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,255 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,262 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785262\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,263 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,263 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:69edb54e-4afc-4d6d-98fa-886f581c1e86,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55878 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,264 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785264\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,265 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f0931baf-97a0-4b7d-b9c6-81dd9e62bd41,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55896 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,268 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,268 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,294 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785294\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,295 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d04d2146-1617-424c-ae82-f361354739f4,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55904 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,297 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,297 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,319 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785319\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,319 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785319\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,320 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,320 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,321 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,322 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55890 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,321 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a6b397ae-910b-467a-8dbd-dcd52a42bda8,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,322 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,323 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,323 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,322 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d9a72979-36dc-4bfc-80b2-d8288fa5e8ce,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55906 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,264 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785264\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,265 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,265 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f0931baf-97a0-4b7d-b9c6-81dd9e62bd41,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55896 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,267 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,268 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,268 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,294 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785294\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,295 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d04d2146-1617-424c-ae82-f361354739f4,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55904 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,296 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,297 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,297 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,319 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785319\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,319 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785319\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,320 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,320 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,321 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,322 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55890 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,321 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a6b397ae-910b-467a-8dbd-dcd52a42bda8,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,322 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,323 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,323 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,322 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d9a72979-36dc-4bfc-80b2-d8288fa5e8ce,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55906 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,325 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,325 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785325\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,326 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55920 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e72ac15d-e1b8-4386-b3b6-bf3e03a5b026,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,328 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,328 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,333 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785333\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,334 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,335 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55928 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,335 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d16af29e-271a-4751-bb0c-271b81f22666,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,344 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785344\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,345 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,346 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:39f4d5f2-eca8-42b9-b38d-4fa596f369c8,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,346 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,347 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55938 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,347 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785347\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,347 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,348 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,348 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,324 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,325 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,325 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785325\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,326 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55920 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e72ac15d-e1b8-4386-b3b6-bf3e03a5b026,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,327 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,328 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,328 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,333 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785333\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,334 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,335 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55928 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,335 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d16af29e-271a-4751-bb0c-271b81f22666,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,336 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,344 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785344\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,345 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,346 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:39f4d5f2-eca8-42b9-b38d-4fa596f369c8,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,346 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,347 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55938 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,347 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785347\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,347 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,348 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,348 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55952 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0571d46f-a087-4ce5-a175-828d6f39e9d1,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,351 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,357 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785357\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,357 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785357\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,358 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,358 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,359 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b932dab7-a61b-475f-8485-769a3d41ddb8,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,359 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55948 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55952 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,349 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0571d46f-a087-4ce5-a175-828d6f39e9d1,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,350 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,351 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,357 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785357\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,357 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785357\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,358 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,358 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,359 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b932dab7-a61b-475f-8485-769a3d41ddb8,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,359 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55948 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,360 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,360 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55956 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:750e5e80-ad08-4b26-b069-4b7932adeb50,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,375 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785375\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,376 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785376\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,377 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,360 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55956 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:750e5e80-ad08-4b26-b069-4b7932adeb50,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,361 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,375 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785375\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,376 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785376\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,377 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,377 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4f285fc5-bb76-4283-a6ce-03e9b85dbc3d,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55978 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,379 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,379 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b314a1c-dd61-4578-a225-671d2958f7cf,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55972 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,381 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,383 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785383\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,383 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:91830159-4cbe-40c9-8f29-aadcb6bef86c,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55994 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,392 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785392\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,393 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7d82c099-9c03-4114-92f9-2b3546c8127c,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56006 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,395 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,377 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4f285fc5-bb76-4283-a6ce-03e9b85dbc3d,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,378 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55978 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,379 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,379 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,379 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b314a1c-dd61-4578-a225-671d2958f7cf,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:55972 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,380 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,381 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,383 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785383\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,383 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:91830159-4cbe-40c9-8f29-aadcb6bef86c,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,384 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:55994 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,385 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,392 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785392\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,393 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7d82c099-9c03-4114-92f9-2b3546c8127c,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56006 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,394 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,395 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,395 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,400 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785400\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,401 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,402 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56026 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.07|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cca3399a-7558-4427-90a6-c2ca461204f0,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,404 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785406\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,407 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,407 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:029aaaca-6db9-4dff-970a-9f1c96426150,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56032 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,409 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,415 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785415\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,423 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,424 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,424 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56028 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a2fa03c8-b689-4b03-876b-6029db7a5ce1,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785436\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,438 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53486293-df5c-4693-86d3-3055af6341ae,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,395 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,400 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785400\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,401 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,402 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56026 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.07|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cca3399a-7558-4427-90a6-c2ca461204f0,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,403 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,404 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785406\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,407 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,407 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:029aaaca-6db9-4dff-970a-9f1c96426150,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56032 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,408 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,409 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,415 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785415\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,423 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,424 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,424 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56028 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a2fa03c8-b689-4b03-876b-6029db7a5ce1,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,425 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785436\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,438 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53486293-df5c-4693-86d3-3055af6341ae,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56050 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,439 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785439\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,440 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,441 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56038 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,441 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f8707211-f4aa-481f-864b-8a9bd6d49b60,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,453 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785453\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,454 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:154d36f9-007b-4bad-8992-b7437331052c,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56010 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,456 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785471\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56070 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:86bbeff2-fe01-4577-b9a8-b5007c1f6508,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785484\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56050 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,439 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785439\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,440 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,441 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56038 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,442 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,441 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f8707211-f4aa-481f-864b-8a9bd6d49b60,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,453 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785453\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,453 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,454 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:154d36f9-007b-4bad-8992-b7437331052c,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56010 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,455 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,456 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785471\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56070 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,473 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:86bbeff2-fe01-4577-b9a8-b5007c1f6508,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,474 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,484 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785484\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,484 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785484\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,485 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,485 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,486 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5aa6515-a78e-4405-8c45-cd2d67766e55,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56080 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,488 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56082 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb2c65ed-d43e-4e2c-be4a-6f239cc95789,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,489 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,489 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785490\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,490 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:935a6f47-9aad-4640-b4c8-4bafbe27414d,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56066 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,511 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785511\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,512 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785512\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,513 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,513 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3764c556-e42b-4ed7-8cc5-f4d4141fb90c,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56088 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,484 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785484\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,485 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,485 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,486 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5aa6515-a78e-4405-8c45-cd2d67766e55,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56080 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,487 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,488 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56082 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,488 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb2c65ed-d43e-4e2c-be4a-6f239cc95789,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,489 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,489 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785490\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,490 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:935a6f47-9aad-4640-b4c8-4bafbe27414d,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,491 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56066 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,492 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,511 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785511\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,512 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785512\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,513 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,513 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3764c556-e42b-4ed7-8cc5-f4d4141fb90c,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56088 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,514 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,514 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,515 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,515 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56092 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:79efd588-7066-446e-8a40-c5714a5ba9a8,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,514 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,515 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,515 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56092 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:79efd588-7066-446e-8a40-c5714a5ba9a8,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,521 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[32m    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:25.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.467:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.467:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.467:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.468:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.468:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.468:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.468:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.468:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.469:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.469:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.494:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/20.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.497:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/2.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.498:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/23.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.524:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.525:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/25.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.537:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.538:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/21.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.572:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.574:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/24.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.629:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: Bad HTTP status received from algorithm: 500\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.656:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.657:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/22.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.674:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.676:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.676:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.676:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/27.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.683:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/26.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:25.717:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.725:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.726:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/28.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/29.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/3.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.836:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/30.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.940:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/31.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.980:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.981:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/33.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.983:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.983:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.983:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.983:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.988:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:25.989:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/32.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.019:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/34.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.122:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/35.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.175:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/38.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.178:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/36.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.182:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/37.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.266:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.267:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/39.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.443:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/42.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.448:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/40.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.450:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/45.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785536\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,537 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56100 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785536\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,537 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56100 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,540 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cf9a5674-f386-44c0-829f-2ebe24b454eb,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,572 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785572\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,573 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,573 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56104 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,575 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d97b6b85-964f-43f9-b18e-4735499885ad,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,583 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785583\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,584 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ad4e167-4cbc-4b64-b5e9-97037913cd52,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56112 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,586 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,586 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785589\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,590 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b812d598-dc9a-4108-a708-2122d194b2f6,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56116 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,591 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785591\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,593 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,539 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,540 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cf9a5674-f386-44c0-829f-2ebe24b454eb,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,572 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785572\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,573 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,573 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56104 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,575 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,574 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d97b6b85-964f-43f9-b18e-4735499885ad,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,583 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785583\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,584 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ad4e167-4cbc-4b64-b5e9-97037913cd52,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56112 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,585 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,586 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,586 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,589 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785589\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,590 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b812d598-dc9a-4108-a708-2122d194b2f6,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,591 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56116 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,591 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785591\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,592 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,593 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,593 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1963e90-b38a-4ce0-97f3-776d8527a009,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56122 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,595 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,599 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785599\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,600 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:097cf5c4-ab84-4027-afe3-854c69ce3938,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,607 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785607\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,608 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,608 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56142 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,593 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1963e90-b38a-4ce0-97f3-776d8527a009,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56122 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,594 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,595 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,599 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785599\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,600 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:097cf5c4-ab84-4027-afe3-854c69ce3938,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,601 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,607 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785607\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,608 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,608 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56142 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,609 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785609\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,610 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,610 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2d93be6-680d-443f-82c2-f749ffdeceb6,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,610 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bae7d36b-9f88-40c7-ae4b-4556d800efbc,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56154 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,612 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,612 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,620 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785620\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,621 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,621 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785621\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0007c77d-bc80-4b1c-b340-c8d8191fa543,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56166 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,609 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785609\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,609 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,610 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,610 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2d93be6-680d-443f-82c2-f749ffdeceb6,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,610 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bae7d36b-9f88-40c7-ae4b-4556d800efbc,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56154 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,611 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,612 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,612 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,620 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785620\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,621 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,621 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785621\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.69|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0007c77d-bc80-4b1c-b340-c8d8191fa543,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56166 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,623 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,623 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b20b09c-434a-4cfc-a754-89e0c72f1ad5,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56172 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,625 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,634 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785634\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,635 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,635 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56188 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8648f091-3d11-4832-a544-4e5daac69f83,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,642 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785642\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,643 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dc99bb89-9daa-4b70-8652-b084aaaf846b,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56180 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,645 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785650\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,622 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,623 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,623 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b20b09c-434a-4cfc-a754-89e0c72f1ad5,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56172 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,624 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,625 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,634 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785634\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,635 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,635 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56188 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8648f091-3d11-4832-a544-4e5daac69f83,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,636 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,642 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785642\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,643 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dc99bb89-9daa-4b70-8652-b084aaaf846b,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56180 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,644 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,645 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,650 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785650\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5e8c51d-565e-4ec0-8889-926069d6ab0f,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56198 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,659 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785659\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,660 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:10f10daa-77c0-4d8f-bca8-6d47887224ed,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56204 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5e8c51d-565e-4ec0-8889-926069d6ab0f,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,652 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56198 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,653 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,659 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785659\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,660 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:10f10daa-77c0-4d8f-bca8-6d47887224ed,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56204 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,661 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,662 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,676 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785676\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,677 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785678\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,678 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,662 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,676 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785676\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,677 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785678\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,678 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.02|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:942033eb-c7e0-4aa7-b445-eb444eddc2ad,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56220 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.02|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:942033eb-c7e0-4aa7-b445-eb444eddc2ad,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56220 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,679 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,680 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,680 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56234 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,682 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7b2522c2-eda9-4eed-8edb-34758b60aa1d,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,696 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785696\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,697 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,697 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56242 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,680 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,680 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56234 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,681 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,682 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,682 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7b2522c2-eda9-4eed-8edb-34758b60aa1d,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,696 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785696\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,697 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,697 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56242 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,699 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:81541c13-97bd-4f96-8d25-c334f81e9d06,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,713 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785713\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,714 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0346db0a-0e0e-4ce3-a1ff-97e2c5b4a37a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56252 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,735 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785735\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,736 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56268 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5861617-724f-4eee-9fd4-4848c7a5e1ba,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,773 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,773 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785773\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,774 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:aa4afbfb-ccd6-4a61-ae5e-310ae68d982b,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56278 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,698 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,699 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:81541c13-97bd-4f96-8d25-c334f81e9d06,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,713 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785713\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,714 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0346db0a-0e0e-4ce3-a1ff-97e2c5b4a37a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,715 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56252 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,716 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,735 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785735\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,736 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56268 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,737 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f5861617-724f-4eee-9fd4-4848c7a5e1ba,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,773 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,773 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785773\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,774 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:aa4afbfb-ccd6-4a61-ae5e-310ae68d982b,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,775 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56278 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,776 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56272 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64b3321b-bff2-411f-bb2e-da27059f9b55,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,787 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f99b3e7a-b470-4fa3-92d8-8a7f65fbe73b,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56286 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785803\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,804 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56302 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8265f9bb-f0eb-4a20-9669-2f72c7e8e677,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,858 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785858\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dc49c535-7781-4bbb-ac7b-ac50b59976ac,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56318 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,861 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,861 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56272 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,781 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64b3321b-bff2-411f-bb2e-da27059f9b55,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,787 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f99b3e7a-b470-4fa3-92d8-8a7f65fbe73b,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56286 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,796 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785803\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,804 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56302 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,805 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8265f9bb-f0eb-4a20-9669-2f72c7e8e677,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,858 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785858\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dc49c535-7781-4bbb-ac7b-ac50b59976ac,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56318 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,861 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,861 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,867 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785867\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,868 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,869 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56334 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1eb53d32-1d52-4355-9f87-d49c9f00d643,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785888\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,888 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785888\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a66c47c8-5b17-41d3-a937-d6b7f2a334fa,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,891 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,891 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56348 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,893 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e0ad4c9b-7c80-4f3a-a148-3e1f39c13c5a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,904 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785904\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,905 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:37915996-bdc5-49b8-8755-0b8b36bfc592,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56360 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,867 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785867\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,868 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,869 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56334 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,870 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1eb53d32-1d52-4355-9f87-d49c9f00d643,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,888 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785888\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,888 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785888\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a66c47c8-5b17-41d3-a937-d6b7f2a334fa,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,890 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,891 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,891 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56348 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,892 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,893 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e0ad4c9b-7c80-4f3a-a148-3e1f39c13c5a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,904 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785904\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,905 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:37915996-bdc5-49b8-8755-0b8b36bfc592,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56360 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,910 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785910\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56374 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,913 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59b0bd89-7f29-44be-83be-cfd67fc18e18,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,922 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785922\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:919e0f31-c6a3-4b1b-bb3e-47a517f3c2fe,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56380 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,928 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785928\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,928 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,906 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,910 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785910\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56374 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,912 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,913 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:59b0bd89-7f29-44be-83be-cfd67fc18e18,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,922 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785922\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:919e0f31-c6a3-4b1b-bb3e-47a517f3c2fe,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,923 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56380 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,924 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,928 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785928\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,928 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,929 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,929 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56396 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6092e56f-d363-49d1-b1ef-61592c45e12b,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,931 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785931\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,933 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.89|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:191528c2-803c-4811-aff8-0da40fd465a6,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56410 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785934\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,935 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56406 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,937 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:562b75d0-f932-44bd-8535-16832f74d207,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,929 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,929 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56396 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,930 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6092e56f-d363-49d1-b1ef-61592c45e12b,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,931 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785931\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,933 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.89|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:191528c2-803c-4811-aff8-0da40fd465a6,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56410 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785934\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,934 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,935 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56406 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,936 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,937 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:562b75d0-f932-44bd-8535-16832f74d207,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,949 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785949\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,949 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,950 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41057690-7e14-41b3-b994-50a47b4df04e,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,950 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56420 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785959\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,959 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56426 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52f64dd1-dcae-4656-8754-94c59fe76c00,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,963 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785963\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,963 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,964 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785964\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56434 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,966 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.94|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4c8bdba3-5ce2-49d6-af9a-d54dd16b7f6c,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,966 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56448 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,949 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785949\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,949 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,950 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41057690-7e14-41b3-b994-50a47b4df04e,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,950 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56420 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,951 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,959 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785959\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,959 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56426 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,961 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52f64dd1-dcae-4656-8754-94c59fe76c00,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,963 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785963\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,963 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,964 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785964\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56434 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,965 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,966 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.94|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4c8bdba3-5ce2-49d6-af9a-d54dd16b7f6c,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,966 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56448 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,968 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b257d3b-bab7-4f31-8363-b6ea5bb2a70f,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,992 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785992\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,994 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785994\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:67ca57a7-ee45-4cb2-a436-87895f8e9e80,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:00246686-d888-4a3f-8b9b-9ea4257e50ce,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56458 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:25,998 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,022 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786022\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7d9ce25e-3a79-41dd-8a73-39d87b1fe254,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56474 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786033\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,967 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,968 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b257d3b-bab7-4f31-8363-b6ea5bb2a70f,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,992 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785992\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,994 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063785994\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,994 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56454 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,995 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:67ca57a7-ee45-4cb2-a436-87895f8e9e80,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:00246686-d888-4a3f-8b9b-9ea4257e50ce,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56458 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,997 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:25,998 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063785\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,022 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786022\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7d9ce25e-3a79-41dd-8a73-39d87b1fe254,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,025 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56474 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,026 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,033 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786033\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:48c4cbc6-c19d-4a76-b637-42ae9363f791,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786042\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b37cdbb-f306-4268-a3be-c1e9e12ecf6a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,051 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786051\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,052 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a61e77c0-31c1-4f9e-90ff-87f97a7150f3,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,063 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786063\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ebac1ae6-37fe-40ac-bc1f-bc38f789c421,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56504 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,074 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786074\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:48c4cbc6-c19d-4a76-b637-42ae9363f791,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,035 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,036 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,036 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,042 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786042\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b37cdbb-f306-4268-a3be-c1e9e12ecf6a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,044 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,045 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,051 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786051\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,052 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a61e77c0-31c1-4f9e-90ff-87f97a7150f3,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,053 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56496 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,054 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,063 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786063\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,065 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ebac1ae6-37fe-40ac-bc1f-bc38f789c421,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56504 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,066 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,074 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786074\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,074 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,075 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:40e4ef7f-1632-4ff1-8fa9-c0f6d45d81c7,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,075 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56522 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,077 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786077\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,078 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,078 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:866ceadc-93c9-4fb5-b61e-95dca1b977ef,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56510 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,080 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,087 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786087\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,089 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9adf83ce-f7cb-4a7c-890c-c64b08287853,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56532 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,104 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786104\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,106 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3efe1411-4ec2-47a9-b79a-c1a68c73987d,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56546 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,074 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,075 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:40e4ef7f-1632-4ff1-8fa9-c0f6d45d81c7,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,075 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56522 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,076 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,077 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786077\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,078 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,078 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:866ceadc-93c9-4fb5-b61e-95dca1b977ef,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56510 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,079 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,080 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,087 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786087\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,089 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9adf83ce-f7cb-4a7c-890c-c64b08287853,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56532 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,090 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,104 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786104\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,106 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3efe1411-4ec2-47a9-b79a-c1a68c73987d,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56546 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786122\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,123 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786123\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0e1c77cd-da9e-45ca-836c-b9dbbead9fbb,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55907139-cb1d-401f-89d4-7d0b3588f32c,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56568 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786125\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56564 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56550 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,129 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c1e12fd-5fbf-44fb-a6c4-ab6dad190485,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,150 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786150\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,107 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786122\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,123 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786123\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0e1c77cd-da9e-45ca-836c-b9dbbead9fbb,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55907139-cb1d-401f-89d4-7d0b3588f32c,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56568 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786125\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,125 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56564 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,126 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56550 \"POST /invocations HTTP/1.1\" 500 10\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,128 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,129 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c1e12fd-5fbf-44fb-a6c4-ab6dad190485,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,150 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786150\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,151 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,153 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1acdf55-86d7-4949-8f24-bdcd396e59f0,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,154 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56572 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,161 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786161\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,162 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56578 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,164 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:88012c0d-d6a0-4613-830d-786e0ea27df7,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,166 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786166\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,167 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56594 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6c50b1ef-eece-41f6-8f22-70ee1ea822fd,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,212 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786212\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,213 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,151 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,153 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1acdf55-86d7-4949-8f24-bdcd396e59f0,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,154 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56572 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,155 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,161 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786161\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,162 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56578 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,163 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,164 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:88012c0d-d6a0-4613-830d-786e0ea27df7,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,166 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786166\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,167 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56594 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6c50b1ef-eece-41f6-8f22-70ee1ea822fd,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,168 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,212 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786212\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,213 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56606 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c62054fc-d411-4112-8128-dae1bfc19e0f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,224 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786224\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,225 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,226 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.07|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eaad2c7-4774-458a-bc64-33c625d202cc,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,226 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56614 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,233 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786233\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,234 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56620 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,236 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0fa4d636-dc16-4dff-8766-3431d000fb86,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,237 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786237\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,237 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,238 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cdcb9581-fe3a-43df-9725-099609984e94,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,244 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786244\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56606 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c62054fc-d411-4112-8128-dae1bfc19e0f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,214 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,224 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786224\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,225 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,226 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.07|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eaad2c7-4774-458a-bc64-33c625d202cc,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,226 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56614 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,227 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,233 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786233\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,234 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56620 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,235 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,236 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0fa4d636-dc16-4dff-8766-3431d000fb86,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,237 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786237\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,237 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,238 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cdcb9581-fe3a-43df-9725-099609984e94,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,239 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,244 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786244\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,245 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,245 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56636 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,247 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:984cac73-2854-4f61-83ef-4a026a8a712a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,248 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786248\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,249 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0fad8902-d074-4a16-afa1-6390d2cc8e56,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56644 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,256 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786256\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,257 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56654 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56636 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,247 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:984cac73-2854-4f61-83ef-4a026a8a712a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,248 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786248\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,249 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0fad8902-d074-4a16-afa1-6390d2cc8e56,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56644 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,256 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786256\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,257 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56654 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,259 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:adc627cd-27d7-4604-8a6b-7e6e6fe4fcfc,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,267 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786267\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,268 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,269 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eb15a88-3041-4be9-bafa-7532292860c6,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,270 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56660 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,282 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786282\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,283 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56664 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,285 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cb3030e1-adb7-4aaa-984d-3796b1d701f6,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,258 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,259 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:adc627cd-27d7-4604-8a6b-7e6e6fe4fcfc,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,267 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786267\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,268 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,269 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eb15a88-3041-4be9-bafa-7532292860c6,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,270 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56660 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,271 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,282 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786282\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,283 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56664 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,284 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,285 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cb3030e1-adb7-4aaa-984d-3796b1d701f6,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786292\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,293 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786293\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,293 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56674 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,295 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,295 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56672 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a17f3b9f-10dc-46d4-9b08-a6ee857210b3,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,296 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4fe6c871-a1b4-4d2b-ba6c-90fb52b245ee,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,299 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786299\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9b6d3f12-d1d7-4bee-a137-53c0ad00bb75,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56688 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786292\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,293 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786293\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,293 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56674 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,294 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,295 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,295 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56672 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,295 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.75|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a17f3b9f-10dc-46d4-9b08-a6ee857210b3,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,296 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,296 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4fe6c871-a1b4-4d2b-ba6c-90fb52b245ee,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,299 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786299\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,299 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9b6d3f12-d1d7-4bee-a137-53c0ad00bb75,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,300 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56688 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786322\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,323 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:01a27d0e-bdfe-424b-82ce-a64f69ac8499,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56694 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,325 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,325 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,327 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786327\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,327 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,328 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,330 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:34b41e79-8733-41c8-98ed-df1ecb9b0596,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786334\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,335 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5f6af54a-49e5-4bda-8550-6a75595d2995,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56716 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,337 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,342 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786342\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,301 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786322\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,323 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:01a27d0e-bdfe-424b-82ce-a64f69ac8499,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56694 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,324 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,325 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,325 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,327 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786327\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,327 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,328 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,329 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,330 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:34b41e79-8733-41c8-98ed-df1ecb9b0596,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786334\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,335 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5f6af54a-49e5-4bda-8550-6a75595d2995,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56716 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,336 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,337 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,342 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786342\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,343 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56732 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,345 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,345 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,346 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:94f6cc87-e34b-4c36-8c41-ba5b18d1cd0e,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,352 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786352\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,353 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786353\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,353 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,354 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ffd02fdd-7e15-4d71-a9e7-268bc509cf2d,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56740 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786355\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,356 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56742 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,357 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,343 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56732 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,344 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,345 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,345 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,346 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:94f6cc87-e34b-4c36-8c41-ba5b18d1cd0e,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,352 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786352\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,353 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786353\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,353 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,354 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ffd02fdd-7e15-4d71-a9e7-268bc509cf2d,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56740 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,354 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,355 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786355\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,356 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56742 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,356 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,357 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,357 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,357 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c74a0ca4-9eaf-4127-ad8b-379a903fda04,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,357 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56758 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,359 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a02d4151-69f5-4566-b52f-83e9dd52d717,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,367 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786367\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41845379-2dc3-4f75-a3d2-9273fc7d5d36,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56770 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,371 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,371 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,380 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786380\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,381 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,382 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bcee69db-24c6-400d-b15d-d862b46f4f93,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56772 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,404 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786404\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,404 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786404\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,405 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,405 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,406 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0f0bb727-30f9-4653-b210-e0d786c1238c,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,357 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,357 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c74a0ca4-9eaf-4127-ad8b-379a903fda04,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,357 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56758 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,358 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,359 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a02d4151-69f5-4566-b52f-83e9dd52d717,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,367 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786367\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,369 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41845379-2dc3-4f75-a3d2-9273fc7d5d36,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56770 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,370 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,371 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,371 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,380 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786380\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,381 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,382 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.36|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bcee69db-24c6-400d-b15d-d862b46f4f93,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56772 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,383 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,404 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786404\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,404 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786404\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,405 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,405 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,406 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0f0bb727-30f9-4653-b210-e0d786c1238c,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56818 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,408 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,408 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,408 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56810 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,409 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,409 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,410 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,410 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.33|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3daeccf9-e3f1-4054-abbf-377cdca09d82,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,413 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786413\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,413 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786413\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,414 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,414 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,414 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c0deabe5-ec52-4213-9577-9932a9dd08c5,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56796 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,416 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,416 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56788 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,418 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c15e669-03d4-4f83-97d0-a36ae34db8e9,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56818 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,407 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,408 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,408 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,408 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56810 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,409 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,409 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,410 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,410 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.33|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3daeccf9-e3f1-4054-abbf-377cdca09d82,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,413 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786413\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,413 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786413\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,414 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,414 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,414 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c0deabe5-ec52-4213-9577-9932a9dd08c5,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56796 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,415 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,416 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,416 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56788 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,417 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,418 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.1|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c15e669-03d4-4f83-97d0-a36ae34db8e9,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,423 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786423\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,423 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786423\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,424 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,424 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e9507f3b-9b84-4b1a-ac83-0026de739cbd,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56830 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,426 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56828 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,428 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c81881c-a006-4b64-b8ae-699e5c70230f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,432 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786432\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52f29c6e-2db1-40fe-b69d-4ce750843080,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56844 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,437 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786437\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,438 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56850 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,423 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786423\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,423 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786423\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,424 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,424 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e9507f3b-9b84-4b1a-ac83-0026de739cbd,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56830 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,425 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,426 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56828 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,427 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,428 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.97|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9c81881c-a006-4b64-b8ae-699e5c70230f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,432 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786432\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52f29c6e-2db1-40fe-b69d-4ce750843080,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,434 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56844 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,435 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,437 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786437\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,438 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56850 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,439 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,440 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,440 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba38145f-33ef-4217-90df-33c39aba4f80,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,505 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786505\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,506 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b33c6e4d-1d7c-477c-8d07-01daad6a7944,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56852 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,518 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786518\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,519 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786520\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56854 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64c4b3a4-0bdd-45a1-a003-94ec9534858b,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56862 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f193e5a-5869-4245-9438-6f7c90880c9d,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,531 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786531\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,531 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,532 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56878 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,440 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,440 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba38145f-33ef-4217-90df-33c39aba4f80,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,505 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786505\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,506 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.87|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b33c6e4d-1d7c-477c-8d07-01daad6a7944,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,507 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56852 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,508 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,518 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786518\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,519 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786520\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56854 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,521 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64c4b3a4-0bdd-45a1-a003-94ec9534858b,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56862 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f193e5a-5869-4245-9438-6f7c90880c9d,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,522 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,531 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786531\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,531 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,532 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,532 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56878 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,534 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eabaede7-31a5-4506-8985-643f72ac5976,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,534 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786534\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,535 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bff6c72b-0a7b-4be7-bded-c40ea264d219,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56888 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,537 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,537 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,550 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786550\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,551 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,551 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56894 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5863a84f-8e66-4183-a4b6-148d42ee6fd3,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,554 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786554\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,555 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cc9e6120-cdbb-4fd4-be15-7e14ba0fe025,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,533 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,534 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eabaede7-31a5-4506-8985-643f72ac5976,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,534 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786534\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,535 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bff6c72b-0a7b-4be7-bded-c40ea264d219,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56888 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,536 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,537 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,537 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,550 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786550\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,551 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,551 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56894 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,552 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5863a84f-8e66-4183-a4b6-148d42ee6fd3,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,554 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786554\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,555 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cc9e6120-cdbb-4fd4-be15-7e14ba0fe025,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56898 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56898 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,556 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.509:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/41.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.510:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/4.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.573:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/44.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.599:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.600:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.600:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.600:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.647:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: Traceback (most recent call last):\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/47.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/49.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.707:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/46.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.750:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/48.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.790:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/5.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.793:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.794:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/50.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.812:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.813:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.813:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.813:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.813:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/43.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.841:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/51.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:26.975:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/53.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: Traceback (most recent call last):\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:27.110:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.111:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/57.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/52.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.170:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.170:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.170:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.170:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.170:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.179:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.179:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.180:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/55.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/56.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.181:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.187:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.187:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/58.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.189:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: \n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:27.192:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.192:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.195:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/54.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.220:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/61.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.234:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.235:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/60.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.248:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/6.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.274:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.275:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.276:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/62.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.295:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: Bad HTTP status received from algorithm: 500\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:27.298:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.300:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.303:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.304:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.305:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.305:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.305:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.306:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/59.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.329:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/63.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.359:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/65.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.362:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/64.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.386:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/66.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.402:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.403:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/67.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786581\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,582 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786582\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,582 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,583 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,583 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:910d2473-ec05-451e-9057-719c29409dff,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56908 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,585 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56916 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d5a2d120-5896-4ac5-968f-72f441dcba1f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,610 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786610\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,581 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786581\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,582 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786582\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,582 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,583 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,583 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:910d2473-ec05-451e-9057-719c29409dff,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56908 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,584 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,585 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56916 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,585 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,586 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d5a2d120-5896-4ac5-968f-72f441dcba1f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,610 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786610\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,610 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786610\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,611 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,612 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56942 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,613 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7b4234a0-f1e6-4ed4-8da2-8fed2d796601,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,613 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,614 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786615\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0619de2b-7183-4e1d-b0e7-f557fd52de7b,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56938 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,617 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56922 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:77e0c777-4fde-4064-b4e5-3be8d8eb1e74,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786626\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,630 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6815e8ea-a3f7-4fef-b66a-336b196045a9,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56954 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,610 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786610\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,611 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,612 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56942 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,613 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,612 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7b4234a0-f1e6-4ed4-8da2-8fed2d796601,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,613 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,614 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786615\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0619de2b-7183-4e1d-b0e7-f557fd52de7b,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56938 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,616 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,617 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,617 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56922 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,618 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:77e0c777-4fde-4064-b4e5-3be8d8eb1e74,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786626\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,630 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6815e8ea-a3f7-4fef-b66a-336b196045a9,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56954 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,631 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,632 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,632 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786636\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,636 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786636\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,637 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,637 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,638 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,638 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:50cd3c65-324b-42bd-afe5-c789f52e7c1b,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56962 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786639\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,640 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f1dfc101-7bbd-4a2a-9418-f38f4a7a5a0e,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56966 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,642 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,642 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,642 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56960 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5670bdf1-82e1-4223-87c9-d6e4751f111f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786658\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,659 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56974 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bb979bf6-03d2-4f03-aa7f-ca805c8787a7,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,632 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,632 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786636\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,636 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786636\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,637 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,637 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,638 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,638 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:50cd3c65-324b-42bd-afe5-c789f52e7c1b,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56962 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,639 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786639\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,640 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f1dfc101-7bbd-4a2a-9418-f38f4a7a5a0e,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56966 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,641 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,642 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,642 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,642 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56960 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,643 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5670bdf1-82e1-4223-87c9-d6e4751f111f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,658 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786658\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,659 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:56974 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,660 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bb979bf6-03d2-4f03-aa7f-ca805c8787a7,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,666 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786666\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,667 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56988 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,669 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,669 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:79350a95-64c4-4df8-85f2-9eaace00fe90,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,674 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786674\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,674 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,675 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d16233af-0087-4f67-a03e-c8e8f82b02e2,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57004 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,687 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786687\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,690 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,691 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57012 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,693 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d0d31a6-84fa-4e70-b6fd-132fcc4dec1b,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,698 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786698\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,699 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,700 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ee11eb6-26c7-4954-932d-6f3b53ed37d5,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,700 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57026 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,661 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,666 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786666\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,667 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:56988 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,668 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,669 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,669 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:79350a95-64c4-4df8-85f2-9eaace00fe90,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,674 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786674\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,674 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,675 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d16233af-0087-4f67-a03e-c8e8f82b02e2,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57004 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,676 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,687 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786687\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,690 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,691 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57012 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,692 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,693 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d0d31a6-84fa-4e70-b6fd-132fcc4dec1b,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,698 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786698\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,699 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,700 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ee11eb6-26c7-4954-932d-6f3b53ed37d5,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,700 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57026 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786718\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786719\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,721 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,721 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,721 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3a360008-cbdd-4bf0-9b04-bd8100ff0e3e,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57044 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,723 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786723\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,724 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,724 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,724 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:644d6728-4692-4c68-854d-48cda8a8cdd0,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,724 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57040 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,725 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57060 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,727 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fc95957b-fb19-478d-8f22-197cca629742,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,733 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786733\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,734 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57070 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,737 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,701 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786718\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,719 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786719\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,721 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,721 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,721 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3a360008-cbdd-4bf0-9b04-bd8100ff0e3e,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57044 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,722 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,723 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786723\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,724 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,724 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,724 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.34|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:644d6728-4692-4c68-854d-48cda8a8cdd0,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,724 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57040 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,725 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,725 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57060 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,726 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,727 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fc95957b-fb19-478d-8f22-197cca629742,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,733 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786733\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,734 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57070 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,736 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,737 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,737 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e755a027-dcb8-4451-a0ae-73a700483a87,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,741 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786741\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:12a0af77-7802-4834-bdec-f4b2f5342cc1,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57082 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,743 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786743\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,744 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,745 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57090 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,747 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:adc4205b-aef0-48f9-8b4e-ffeb5d4d1c6f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,756 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786756\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,757 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57102 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.28|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6072f7be-9c8e-4c2c-a77b-5042f790b0b2,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,764 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786764\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,765 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57100 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,737 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e755a027-dcb8-4451-a0ae-73a700483a87,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,741 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786741\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:12a0af77-7802-4834-bdec-f4b2f5342cc1,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,742 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57082 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,743 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786743\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,743 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,744 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,745 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57090 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,746 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,747 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:adc4205b-aef0-48f9-8b4e-ffeb5d4d1c6f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,756 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786756\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,757 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57102 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.28|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6072f7be-9c8e-4c2c-a77b-5042f790b0b2,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,758 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,764 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786764\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,765 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57100 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,767 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:18cc5633-245e-48f1-a030-0f2b5ca5b03c,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786776\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,776 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,777 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7bb58821-641a-4713-aa38-8716a3f5765c,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57108 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,784 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786784\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,785 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,791 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,791 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57118 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:6.23|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:acdd0131-4712-4839-a5bb-6f6695b93edd,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,802 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786802\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,802 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,804 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,804 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786804\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57126 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,806 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.79|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:99f445a6-d89a-4e07-90bd-e476889e92d7,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,806 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57128 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,766 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,767 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,767 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:18cc5633-245e-48f1-a030-0f2b5ca5b03c,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,776 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786776\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,776 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,777 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7bb58821-641a-4713-aa38-8716a3f5765c,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,777 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57108 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,778 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,784 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786784\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,785 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,791 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,791 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57118 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,792 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:6.23|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:acdd0131-4712-4839-a5bb-6f6695b93edd,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,802 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786802\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,802 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,804 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,804 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786804\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57126 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,805 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,806 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.79|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:99f445a6-d89a-4e07-90bd-e476889e92d7,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,806 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57128 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,808 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b4c8dd75-782b-4504-b391-00da5f233c57,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,820 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786820\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57140 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55a1f037-f518-4381-b0ae-bdee674c208d,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,830 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786830\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,831 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,832 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786832\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,832 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57160 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786834\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b07f3e2f-5dc6-45a1-9960-ad3b2a896466,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e40ca8e1-19c3-4f26-a2bf-0be9b0bc3831,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57152 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,807 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,808 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b4c8dd75-782b-4504-b391-00da5f233c57,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,820 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786820\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57140 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,822 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:55a1f037-f518-4381-b0ae-bdee674c208d,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,830 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786830\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,831 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,832 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786832\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,832 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57160 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,833 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786834\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,834 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.54|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b07f3e2f-5dc6-45a1-9960-ad3b2a896466,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,835 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e40ca8e1-19c3-4f26-a2bf-0be9b0bc3831,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57152 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57166 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,838 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:5.13|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:db1eeb1f-faf8-4657-b91a-385f5ced176a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,844 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786844\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,845 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,847 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e2c0dba0-9427-49ca-a7d2-08c6b84a5977,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786855\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,856 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786856\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,857 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,857 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57190 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,858 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57200 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,836 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57166 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,837 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,838 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:5.13|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:db1eeb1f-faf8-4657-b91a-385f5ced176a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,844 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786844\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,845 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,846 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,847 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e2c0dba0-9427-49ca-a7d2-08c6b84a5977,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,855 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786855\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,856 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786856\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,857 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,857 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57190 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,858 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,858 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57200 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a3c3546f-6980-48f1-96cd-6e706afdd6dd,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,865 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dff95090-9ce5-4ff7-aa82-14e3973f3b3f,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,961 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786961\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,962 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,963 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57224 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0f9b6ae7-b2fe-4988-81a6-3f4f98224d10,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786965\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,966 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,967 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,967 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57210 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:36d64728-19f9-4621-b6c7-38389cf4c5a2,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,972 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786972\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57230 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d03980b2-1340-4e5a-83d8-0c4c095c8e80,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,977 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786977\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,977 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57234 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a3c3546f-6980-48f1-96cd-6e706afdd6dd,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,865 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dff95090-9ce5-4ff7-aa82-14e3973f3b3f,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,961 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786961\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,962 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,963 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57224 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,965 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.67|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0f9b6ae7-b2fe-4988-81a6-3f4f98224d10,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,965 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786965\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,966 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,967 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,967 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57210 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,968 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:36d64728-19f9-4621-b6c7-38389cf4c5a2,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,972 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786972\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57230 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d03980b2-1340-4e5a-83d8-0c4c095c8e80,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,973 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,977 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786977\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,977 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57234 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,978 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,979 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a7d554c9-87b7-4e3e-bebe-a3ce868b05fc,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786985\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57248 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,987 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,987 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d71b15aa-e419-4940-b49e-3c155419e072,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,991 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786991\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,992 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57260 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,994 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:26,994 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a6f8d6a0-d488-4117-bed2-5b52dd44545d,timestamp:1661063786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,000 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787000\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,001 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57262 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,003 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,003 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,004 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fd0798c8-f7ae-407d-aad4-72ef7400ab09,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,010 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787010\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,012 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787011\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,012 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,013 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,013 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,979 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a7d554c9-87b7-4e3e-bebe-a3ce868b05fc,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,985 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786985\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57248 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,986 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,987 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,987 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d71b15aa-e419-4940-b49e-3c155419e072,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,991 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063786991\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,992 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57260 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,993 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,994 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:26,994 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a6f8d6a0-d488-4117-bed2-5b52dd44545d,timestamp:1661063786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,000 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787000\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,001 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57262 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,002 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,003 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,003 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,004 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fd0798c8-f7ae-407d-aad4-72ef7400ab09,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,010 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787010\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,012 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787011\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,012 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,013 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,013 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57290 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eba869a6-f4a1-434e-a695-75c81f651f0d,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787015\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,016 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ed5470fe-9fd2-4e05-a32b-78bf38bc108b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57270 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787017\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57282 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787018\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,018 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,019 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.99|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d4643977-0ca6-4291-82cd-b0509b214371,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,019 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bab3b804-fa04-4c4e-99dc-484409244f41,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57306 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,021 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,021 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57290 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eba869a6-f4a1-434e-a695-75c81f651f0d,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,014 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,015 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787015\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,016 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ed5470fe-9fd2-4e05-a32b-78bf38bc108b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57270 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,016 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,017 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787017\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57282 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787018\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,018 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,019 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.99|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d4643977-0ca6-4291-82cd-b0509b214371,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,019 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bab3b804-fa04-4c4e-99dc-484409244f41,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57306 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,020 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,021 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,021 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,021 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57302 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f27ffc79-c520-42c2-9aa1-2c0594e45d9f,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,036 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787036\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8b3292b6-2fc4-4e6a-afce-90d3b04c6e92,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,038 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57320 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,038 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,041 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,041 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,063 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787063\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,063 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787063\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4bdc94c2-182b-4b08-a76d-ac23a1d142f2,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:211ba7f6-2413-471b-aa65-0c79e0ee5d78,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57324 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57328 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,075 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787075\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,076 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,021 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57302 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,022 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f27ffc79-c520-42c2-9aa1-2c0594e45d9f,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,036 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787036\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,037 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8b3292b6-2fc4-4e6a-afce-90d3b04c6e92,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,038 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57320 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,038 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,041 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,041 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,063 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787063\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,063 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787063\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4bdc94c2-182b-4b08-a76d-ac23a1d142f2,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:211ba7f6-2413-471b-aa65-0c79e0ee5d78,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,065 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57324 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57328 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,066 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,075 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787075\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,076 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:400a331a-7805-4bf7-9734-6bd6858aebed,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57338 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,078 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,084 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787084\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,085 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f859bb54-e5cd-4cbb-bf03-75430f100fcf,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,087 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,087 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787102\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,104 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57368 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5313204e-d85f-49b7-aa74-22089245f679,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,106 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,107 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,111 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787111\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,113 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57382 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:76960b9b-8ef0-4e4d-a19f-3687bd00f71e,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,123 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787123\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,123 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,124 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f38bc94f-2c85-40bc-9f58-09116552c8cd,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:400a331a-7805-4bf7-9734-6bd6858aebed,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57338 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,077 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,078 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,084 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787084\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,085 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f859bb54-e5cd-4cbb-bf03-75430f100fcf,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57354 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,086 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,087 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,087 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,102 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787102\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,104 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57368 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5313204e-d85f-49b7-aa74-22089245f679,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,105 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,106 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,107 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,111 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787111\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,113 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57382 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,114 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,115 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:76960b9b-8ef0-4e4d-a19f-3687bd00f71e,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,123 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787123\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,123 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,124 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f38bc94f-2c85-40bc-9f58-09116552c8cd,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57396 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,126 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,131 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787131\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,131 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787131\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,132 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,132 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d5d11238-ad34-4173-beb9-de1b83dc9665,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57412 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57418 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,134 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787134\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,135 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9d216334-d2a3-4f62-a56b-1868abd4f231,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fff21c7c-42c5-415e-be57-dc767ff0631c,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57434 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,146 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787146\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,147 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,147 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1df1c7e6-abc1-4d42-96ed-1d2070683cef,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57396 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,125 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,126 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,131 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787131\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,131 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787131\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,132 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,132 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d5d11238-ad34-4173-beb9-de1b83dc9665,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57412 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,133 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57418 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,134 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787134\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,135 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.8|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9d216334-d2a3-4f62-a56b-1868abd4f231,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fff21c7c-42c5-415e-be57-dc767ff0631c,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57434 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,136 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,146 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787146\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,147 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,147 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1df1c7e6-abc1-4d42-96ed-1d2070683cef,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787148\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787148\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,149 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,150 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57460 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57444 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,153 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5518fd92-f735-402a-88b9-e121ccf08e5f,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,153 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:726d476a-0c4a-4887-892f-024a2a555bb7,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,160 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787160\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57462 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,163 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4d9c6efe-f38b-49d1-8f38-9476fbdeae2b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,165 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787165\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,165 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57448 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787148\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,148 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787148\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,149 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,150 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57460 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,151 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57444 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,152 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,153 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5518fd92-f735-402a-88b9-e121ccf08e5f,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,153 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:726d476a-0c4a-4887-892f-024a2a555bb7,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,160 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787160\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57462 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,162 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,163 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4d9c6efe-f38b-49d1-8f38-9476fbdeae2b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,165 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787165\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,165 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,166 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787166\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57466 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:45a49243-d3b2-42ef-8a4f-60758b3c652b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,168 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57464 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3dafde5-fe4d-4ca3-9cad-e120035851b5,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787171\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,172 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57480 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,174 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2836e053-9fa0-4b66-a5d6-3c1fbec359e8,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787177\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,177 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,178 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,180 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1590a143-bb22-4f90-8e71-22b34e6d8876,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,190 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787190\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,166 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787166\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57466 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,167 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:45a49243-d3b2-42ef-8a4f-60758b3c652b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,168 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57464 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,169 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3dafde5-fe4d-4ca3-9cad-e120035851b5,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787171\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,172 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57480 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,173 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,174 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2836e053-9fa0-4b66-a5d6-3c1fbec359e8,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,177 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787177\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,177 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,178 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,179 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,180 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1590a143-bb22-4f90-8e71-22b34e6d8876,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,190 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787190\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57486 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,193 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c71d801-df46-4631-8964-0fe9addd6dd9,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787194\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,194 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,195 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,195 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57498 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7aa2b2cc-9d28-4566-98af-7d0f107bf811,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,210 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787209\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787211\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,211 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57504 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,213 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,213 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53eca2b4-a556-4d4e-865e-66bd52bcf039,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,213 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,215 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57506 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,217 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b10459c8-829a-4bc6-a60f-3db3535a5058,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,230 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787230\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57486 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,192 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,193 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c71d801-df46-4631-8964-0fe9addd6dd9,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,194 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787194\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,194 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,195 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,195 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57498 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,196 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7aa2b2cc-9d28-4566-98af-7d0f107bf811,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,210 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787209\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,211 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787211\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,211 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57504 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,212 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,213 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,213 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53eca2b4-a556-4d4e-865e-66bd52bcf039,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,213 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,215 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57506 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,216 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,217 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b10459c8-829a-4bc6-a60f-3db3535a5058,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,230 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787230\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,230 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,231 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57510 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,233 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fe2d9ffc-a655-449e-b0c8-5787d3dd5b50,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787234\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,236 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787236\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,236 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57524 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,230 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,231 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57510 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,232 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,233 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fe2d9ffc-a655-449e-b0c8-5787d3dd5b50,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787234\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,236 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787236\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,236 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57524 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,237 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,238 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,238 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57522 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e777f792-b15c-4017-b124-03644a1f3be3,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,240 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:13a9a040-dae4-4c75-be3f-754508fdfbfa,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,247 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787247\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,248 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e53c6368-72f1-4528-b22f-e63df8e0e440,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57532 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787252\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:113b0b79-6df2-4d7a-9a61-44fab145cff9,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57546 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,255 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,271 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787271\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,272 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,272 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787272\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,273 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9ac562de-3712-4cee-bbd4-148d555ccab2,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,237 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,238 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,238 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57522 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,239 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e777f792-b15c-4017-b124-03644a1f3be3,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,240 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:13a9a040-dae4-4c75-be3f-754508fdfbfa,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,247 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787247\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,248 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e53c6368-72f1-4528-b22f-e63df8e0e440,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,249 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57532 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,250 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787252\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,253 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,253 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:113b0b79-6df2-4d7a-9a61-44fab145cff9,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57546 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,254 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,255 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,271 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787271\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,272 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,272 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787272\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,273 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9ac562de-3712-4cee-bbd4-148d555ccab2,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57556 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,275 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,275 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787276\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,278 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,278 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a251d711-0197-48b7-9e94-f8cf6cebe6d4,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57566 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787279\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.32|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0dd9b498-f31d-42c4-838e-56c3f790a0aa,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57576 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,280 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,281 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,281 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57554 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8505760d-ff5a-4356-ae72-233781cd0159,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,283 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,290 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787290\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57556 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,274 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,275 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,275 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,276 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787276\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,277 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,278 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,278 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,278 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.11|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a251d711-0197-48b7-9e94-f8cf6cebe6d4,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57566 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,279 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787279\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.32|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0dd9b498-f31d-42c4-838e-56c3f790a0aa,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57576 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,280 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,280 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,281 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,281 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57554 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8505760d-ff5a-4356-ae72-233781cd0159,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,282 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,283 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,290 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787290\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f59c5a2c-ad3f-4240-8770-e7286497318d,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57582 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,300 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787300\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d68b1065-acf0-420d-b103-3ce2b03f00cb,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57598 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,303 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,313 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787313\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:786d0a06-d206-491e-b6fd-74d6081bd661,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57602 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,316 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,316 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,316 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787316\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,317 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e945a28b-52ed-4c51-b3f1-3ab4ec7b963b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57610 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f59c5a2c-ad3f-4240-8770-e7286497318d,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57582 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,293 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,300 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787300\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d68b1065-acf0-420d-b103-3ce2b03f00cb,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57598 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,302 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,303 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,313 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787313\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:786d0a06-d206-491e-b6fd-74d6081bd661,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57602 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,315 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,316 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,316 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,316 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787316\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,317 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e945a28b-52ed-4c51-b3f1-3ab4ec7b963b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57610 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,322 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787322\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,323 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,323 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:94d9bd57-cb75-41e0-a4f8-146144f782f7,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57626 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787334\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,335 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,318 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,322 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787322\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,323 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,323 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:94d9bd57-cb75-41e0-a4f8-146144f782f7,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57626 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,324 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,334 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787334\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,335 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,336 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787336\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,336 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:14c504e0-26bf-4fe5-9add-1b5535042ec4,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,338 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,338 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57642 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,340 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d47a3d9e-3c71-4fe8-8365-ea6d2f5ad6bc,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,340 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57636 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,347 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787347\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,348 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:589c9304-14db-41e5-9806-d8d1d7bd4117,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57658 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,350 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,354 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787354\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:39acb68c-4932-41d3-9bd6-803f21c2b65a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57654 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,357 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,357 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,362 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787362\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,336 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787336\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,336 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:14c504e0-26bf-4fe5-9add-1b5535042ec4,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,338 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,338 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57642 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,339 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,340 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.39|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d47a3d9e-3c71-4fe8-8365-ea6d2f5ad6bc,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,340 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57636 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,341 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,347 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787347\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,348 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:589c9304-14db-41e5-9806-d8d1d7bd4117,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57658 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,349 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,350 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,354 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787354\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:39acb68c-4932-41d3-9bd6-803f21c2b65a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57654 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,356 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,357 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,357 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,362 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787362\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c07ce09-bcd9-4918-b19c-f4ffb037bf84,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,369 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787369\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,371 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,372 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57670 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,374 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8bdd80b7-198f-4eca-92c8-6f1eb90b022a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,376 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787376\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5655545d-0d64-44a0-94f2-84e40f588537,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57686 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,379 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,379 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,384 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787384\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,385 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,386 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:60bb13d3-9cdf-4add-bbef-053d03978db4,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57688 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,388 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,397 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787397\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c07ce09-bcd9-4918-b19c-f4ffb037bf84,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,363 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,364 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,369 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787369\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,371 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,372 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57670 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,373 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,374 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.78|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8bdd80b7-198f-4eca-92c8-6f1eb90b022a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,376 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787376\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5655545d-0d64-44a0-94f2-84e40f588537,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57686 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,378 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,379 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,379 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,384 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787384\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,385 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,386 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:60bb13d3-9cdf-4add-bbef-053d03978db4,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57688 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,387 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,388 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,397 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787397\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,397 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,398 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,398 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f0b624eb-39d7-4782-9ca7-aa90c6234d66,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57698 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,412 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787412\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3b355e31-adef-465c-963b-5a1617947412,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57714 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,417 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787417\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57722 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7bf65802-5bb3-44c1-9607-142949cd1eae,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,420 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,420 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,434 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787434\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,436 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7db86294-4774-4a58-bd3f-178e2f11812a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787436\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57726 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,397 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,398 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,398 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f0b624eb-39d7-4782-9ca7-aa90c6234d66,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57698 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,399 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,412 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787412\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3b355e31-adef-465c-963b-5a1617947412,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,414 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57714 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,415 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,417 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787417\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57722 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,419 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7bf65802-5bb3-44c1-9607-142949cd1eae,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,420 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,420 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,434 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787434\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,436 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7db86294-4774-4a58-bd3f-178e2f11812a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787436\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57726 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57738 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d710ba8-5878-46ef-8886-daa2dfd15ea2,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,468 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787467\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,469 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,469 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787469\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dae21825-0cd0-4515-b447-377f085b828d,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,470 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:97322f7c-bdeb-4510-b71b-636031df172b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57756 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,514 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787514\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,516 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5a9e059d-35e6-4b61-a72c-be25167f036f,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57768 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57738 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d710ba8-5878-46ef-8886-daa2dfd15ea2,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,468 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787467\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,469 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,469 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787469\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dae21825-0cd0-4515-b447-377f085b828d,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,470 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,470 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57740 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,471 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:97322f7c-bdeb-4510-b71b-636031df172b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,472 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57756 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,473 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,514 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787514\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,516 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,516 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5a9e059d-35e6-4b61-a72c-be25167f036f,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57768 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,517 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787520\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,521 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:68f52800-fa09-4ccb-9ac2-b2202c78f8d1,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57776 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,528 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787528\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,529 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:30a41155-93cf-4a27-a4a3-d23b2742125a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57786 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,551 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787551\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,553 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57802 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:4.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cd1f7a45-595b-4c84-8452-2bb15e0c6680,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,559 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,559 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,520 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787520\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,521 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:68f52800-fa09-4ccb-9ac2-b2202c78f8d1,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57776 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,522 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,523 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,523 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,528 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787528\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,529 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:30a41155-93cf-4a27-a4a3-d23b2742125a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,530 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57786 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,531 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,551 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787551\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,553 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57802 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,558 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:4.3|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cd1f7a45-595b-4c84-8452-2bb15e0c6680,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,559 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,559 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.639:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.640:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/68.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.645:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/70.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.684:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/69.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.704:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/7.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.861:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.861:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.861:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.861:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.862:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.862:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.862:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.862:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.869:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.869:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.870:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.870:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.870:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.870:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.871:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:27.871:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/71.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.020:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.021:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.021:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.021:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.021:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.022:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.022:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.022:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.023:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/73.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.046:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/75.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.049:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: Bad HTTP status received from algorithm: 500\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.051:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/72.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.071:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/76.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.086:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.108:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/74.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.112:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/77.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.149:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.149:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.150:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.152:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.153:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.153:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.153:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.154:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.154:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.157:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.157:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.158:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.158:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.223:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.224:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/78.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.225:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.226:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/79.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.232:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/8.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.297:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/81.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.310:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/80.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.324:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.325:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/83.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.344:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/82.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\n",
      "    #011at java.lang.Thread.run(Thread.java:750)2022-08-21T06:36:28.378:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.378:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.379:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.379:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.379:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.380:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.380:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.380:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.380:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.380:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.381:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.382:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.383:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.383:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.383:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.383:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/84.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.511:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/86.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.512:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/85.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.513:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/87.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787618\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,620 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,620 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57822 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,622 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,622 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b4a76146-111d-4576-895d-23cb1f6a1ac2,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787624\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d1387a68-fe58-437a-a03c-e4f4e9a1ebba,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57812 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,619 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787618\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,620 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,620 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57822 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,621 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,622 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,622 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.85|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b4a76146-111d-4576-895d-23cb1f6a1ac2,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787624\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d1387a68-fe58-437a-a03c-e4f4e9a1ebba,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,626 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57812 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787636\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,636 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,637 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57848 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,639 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c6c0c9d-b5b0-42bf-b400-685203710208,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,668 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787668\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,627 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,636 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787636\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,636 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,637 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57848 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,638 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,639 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c6c0c9d-b5b0-42bf-b400-685203710208,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,668 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787668\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,669 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,669 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a4ab07de-68cb-4a54-b0bc-816d7b3b15bb,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57832 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,671 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,671 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,676 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787676\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,677 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57860 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,669 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,669 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a4ab07de-68cb-4a54-b0bc-816d7b3b15bb,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57832 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,670 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,671 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,671 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,676 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787676\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,677 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57860 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,678 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cec15fb9-cf63-4ddd-bd9b-588c8234a64b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,693 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787693\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,694 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,694 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5187d2d5-292c-4e8d-8b7b-1da419e312b5,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57876 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,696 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,696 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,716 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787716\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,717 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57882 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,719 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,719 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,720 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4e1355db-cb07-4f4d-9472-1fd312407fda,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,679 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cec15fb9-cf63-4ddd-bd9b-588c8234a64b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,693 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787693\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,694 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,694 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5187d2d5-292c-4e8d-8b7b-1da419e312b5,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57876 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,695 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,696 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,696 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,716 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787716\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,717 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57882 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,718 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,719 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,719 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,720 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4e1355db-cb07-4f4d-9472-1fd312407fda,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,745 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787745\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,747 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57902 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,749 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,749 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,752 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:62c6e0d0-8d35-4cc6-b625-a92a4937def9,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,753 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787753\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,754 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,745 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787745\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,747 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57902 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,748 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,749 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,749 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,752 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:62c6e0d0-8d35-4cc6-b625-a92a4937def9,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,753 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787753\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,754 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57894 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,757 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,757 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ad3889e2-d377-48bc-8eb5-154ab9010a22,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787769\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,772 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,772 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,773 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57914 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,773 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,774 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,774 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,775 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9aa01152-3695-4b5a-809e-cb4f17effcd0,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787796\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,797 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57916 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,800 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,800 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c623998a-762f-49ea-928e-06e1bfe32430,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,819 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787819\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57932 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,822 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,823 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1b3305c2-4f1b-435d-a5fd-408d1f074ede,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57894 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,756 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,757 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,757 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ad3889e2-d377-48bc-8eb5-154ab9010a22,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787769\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,772 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,772 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,773 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57914 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,773 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,774 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,774 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,775 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.84|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9aa01152-3695-4b5a-809e-cb4f17effcd0,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787796\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,797 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57916 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,799 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,800 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,800 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c623998a-762f-49ea-928e-06e1bfe32430,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,819 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787819\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57932 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,822 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,823 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1b3305c2-4f1b-435d-a5fd-408d1f074ede,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,823 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,824 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,835 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787835\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,836 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8088aefe-080a-41ed-94e3-9f62e6be7f15,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57940 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,838 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,838 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,839 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787839\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,840 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57946 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,851 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,851 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:66bfa86e-aa91-4283-b004-1858b2092ff8,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787864\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57948 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,867 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,867 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,871 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b2dcc509-ac37-416f-a227-ee393ffcdd62,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,885 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787885\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,887 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787887\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,888 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,823 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,824 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,835 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787835\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,836 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8088aefe-080a-41ed-94e3-9f62e6be7f15,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57940 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,837 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,838 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,838 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,839 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787839\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,840 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57946 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,841 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,851 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,851 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:66bfa86e-aa91-4283-b004-1858b2092ff8,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,864 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787864\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57948 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,866 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,867 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,867 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,871 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,871 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b2dcc509-ac37-416f-a227-ee393ffcdd62,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,885 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787885\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,887 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787887\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,888 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:614f77af-b6b6-45e5-b53d-a1b1c3596175,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57964 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,890 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57974 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787891\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787892\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,892 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.94|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6b3c252-4190-44e1-82fd-6b411dc985d7,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,893 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,893 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:614f77af-b6b6-45e5-b53d-a1b1c3596175,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,889 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57964 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,890 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57974 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,891 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787891\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,892 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787892\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,892 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.94|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6b3c252-4190-44e1-82fd-6b411dc985d7,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,893 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,893 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57984 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b0ec1b9d-4064-4376-8839-1eddb7cc3982,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,895 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,895 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f87b52b8-f6c8-45b5-8d2d-373f4c9fd6e1,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57956 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,897 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,900 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787900\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,894 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57984 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,895 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b0ec1b9d-4064-4376-8839-1eddb7cc3982,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,895 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,895 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f87b52b8-f6c8-45b5-8d2d-373f4c9fd6e1,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,896 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,896 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57956 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,896 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,897 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,900 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787900\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,901 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,901 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:377b59af-704e-4137-b734-f722eee346d7,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57954 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,909 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787909\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,909 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787909\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,910 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,910 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c99cf2ae-4752-48d5-94f4-e8359a1e73d1,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57990 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,912 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,911 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,912 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57994 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,901 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,901 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:377b59af-704e-4137-b734-f722eee346d7,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57954 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,902 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,909 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787909\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,909 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787909\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,910 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,910 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c99cf2ae-4752-48d5-94f4-e8359a1e73d1,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:57990 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,912 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,911 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,912 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:57994 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,912 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9fc7d559-3be9-43f3-b7da-a8b6aac8a06b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,913 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787913\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787914\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,914 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c5ea3b04-f2ee-4c64-8616-7cec0efaf22f,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58016 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,916 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,916 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,916 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,912 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9fc7d559-3be9-43f3-b7da-a8b6aac8a06b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,913 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787913\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,914 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787914\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,914 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.91|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c5ea3b04-f2ee-4c64-8616-7cec0efaf22f,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58016 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,915 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,916 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,916 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,916 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58004 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53fdf55d-05cd-42a2-aa2d-5365f3e650e6,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,929 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787929\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,929 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5d70fd86-dcdb-4d26-9ed7-b8cd16e43e17,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58004 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,917 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:53fdf55d-05cd-42a2-aa2d-5365f3e650e6,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,918 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,929 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787929\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,929 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.04|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5d70fd86-dcdb-4d26-9ed7-b8cd16e43e17,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58028 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787932\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58028 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,931 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,932 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787932\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,933 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e8cd77b1-d495-4905-893e-9c3849958b7b,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58020 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,938 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787938\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,938 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,939 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,939 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58042 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b9d8ad67-918a-4464-b9df-29b3a7e10f6c,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,955 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787955\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3a097b8d-d8cd-447f-833b-4b1a865bbae8,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,933 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.76|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e8cd77b1-d495-4905-893e-9c3849958b7b,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58020 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,934 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,938 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787938\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,938 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,939 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,939 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58042 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:b9d8ad67-918a-4464-b9df-29b3a7e10f6c,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,940 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,955 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787955\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3a097b8d-d8cd-447f-833b-4b1a865bbae8,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,957 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787957\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58060 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,958 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,959 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787959\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,960 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:82bb9c15-61d6-451c-a7ff-7e3d9676a398,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,960 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58048 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,961 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58046 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b19c424-1bf2-46e5-b9cb-a4ce644c0490,timestamp:1661063787\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:27,995 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787995\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,957 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787957\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,957 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58060 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,958 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,958 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,959 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,959 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787959\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,960 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.31|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:82bb9c15-61d6-451c-a7ff-7e3d9676a398,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,960 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,960 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58048 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,961 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,961 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58046 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,962 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b19c424-1bf2-46e5-b9cb-a4ce644c0490,timestamp:1661063787\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:27,995 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063787995\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9a8e65d3-4542-4b14-a20a-ae0f89249818,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58070 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,053 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788053\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,055 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9534d65a-7519-4cf7-989d-ab3eea67198c,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58074 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,057 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,057 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,059 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788059\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,061 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9a8e65d3-4542-4b14-a20a-ae0f89249818,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,003 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58070 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,004 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,053 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788053\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,055 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9534d65a-7519-4cf7-989d-ab3eea67198c,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58074 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,056 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,057 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,057 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,059 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788059\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,061 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58080 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:73b062e0-c081-4ee6-b086-7ac526f38ba1,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,066 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,066 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788070\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,071 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8b5891ea-de9b-4826-9600-372e48a892c6,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58090 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,073 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788076\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,076 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58100 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58080 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.52|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:73b062e0-c081-4ee6-b086-7ac526f38ba1,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,065 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,066 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,066 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,070 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788070\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,071 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8b5891ea-de9b-4826-9600-372e48a892c6,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58090 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,072 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,073 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,073 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788076\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,076 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58100 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:99b67fed-017b-416d-9b82-be2f69203f68,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,082 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788082\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,083 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58110 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a1f161fe-cae0-4bf7-8b36-18daf1e82bec,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,087 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788087\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,087 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58120 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,080 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:3.01|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:99b67fed-017b-416d-9b82-be2f69203f68,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,081 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,082 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788082\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,083 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58110 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a1f161fe-cae0-4bf7-8b36-18daf1e82bec,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,084 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,087 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788087\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,087 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58120 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,089 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba604762-0a86-42ef-a803-f018c95323d3,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,091 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788091\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,092 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,094 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52494ab6-69fb-458c-910d-c6d4b3373fea,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,095 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788095\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,095 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,100 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,100 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58140 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,101 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788101\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,102 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6d9c8f9-2516-4477-afb5-484416485a90,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,102 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58156 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fb9c358b-0454-4159-a7a8-daa80b6bf83e,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,088 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,089 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba604762-0a86-42ef-a803-f018c95323d3,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,091 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788091\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,092 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58132 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,093 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,094 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:52494ab6-69fb-458c-910d-c6d4b3373fea,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,095 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788095\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,095 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,100 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,100 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58140 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,101 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,101 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788101\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,102 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.82|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e6d9c8f9-2516-4477-afb5-484416485a90,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,102 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58156 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:fb9c358b-0454-4159-a7a8-daa80b6bf83e,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788118\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,118 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58166 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,120 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,120 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,122 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ec5a8df2-ff94-4e6d-95bb-5d66b04a348b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,122 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788122\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,123 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,125 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64887219-6bf4-453f-a6f0-01ec6500aa3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,137 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788137\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,138 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58196 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,103 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,118 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788118\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,118 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58166 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,119 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,120 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,120 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,122 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ec5a8df2-ff94-4e6d-95bb-5d66b04a348b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,122 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788122\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,123 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58182 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,124 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,125 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:64887219-6bf4-453f-a6f0-01ec6500aa3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,137 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788137\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,138 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58196 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,139 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,140 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c88a5c05-233d-4f84-96af-205d17adc873,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,152 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788152\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,153 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58212 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c526d49-a634-405e-aca3-5add8d3e6837,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,156 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788163\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,163 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,164 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58226 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,166 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,166 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2a960447-11ee-42ca-bbe0-580ad5bda0e7,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,170 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788170\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,171 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,172 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:28a9b2b3-89c7-4daa-aeb5-bc23684739f4,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,172 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58228 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788177\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,140 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c88a5c05-233d-4f84-96af-205d17adc873,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,152 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788152\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,153 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58212 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,155 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8c526d49-a634-405e-aca3-5add8d3e6837,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,156 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,163 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788163\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,163 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,164 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58226 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,165 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,166 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,166 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2a960447-11ee-42ca-bbe0-580ad5bda0e7,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,170 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788170\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,171 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,172 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:28a9b2b3-89c7-4daa-aeb5-bc23684739f4,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,172 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58228 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,173 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,177 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788177\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,178 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58244 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,180 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,180 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,181 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dbac08b8-0643-48a6-95f1-5a482f730201,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,187 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788186\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,187 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,188 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:72a9b81e-b598-4c6a-8c8b-9a9cb44c5c64,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,188 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58252 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,190 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,199 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788199\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,199 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,200 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58274 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,202 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eb0aefc-5ff2-4773-bfaf-73857604f821,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,203 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788203\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,178 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58244 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,179 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,180 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,180 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,181 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dbac08b8-0643-48a6-95f1-5a482f730201,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,187 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788186\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,187 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,188 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:72a9b81e-b598-4c6a-8c8b-9a9cb44c5c64,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,188 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58252 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,189 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,190 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,199 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788199\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,199 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,200 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58274 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,201 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,202 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2eb0aefc-5ff2-4773-bfaf-73857604f821,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,203 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788203\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,203 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788203\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,204 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58262 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,206 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,206 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58254 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,207 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,206 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cdb51fff-d6c2-4c82-8237-9af7bb93a726,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,208 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,208 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,209 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:30eca519-e240-4863-b381-d9945d03cb8f,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788234\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:652d8002-9557-4dd8-98c2-302ffa306508,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58288 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788241\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,242 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788242\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,203 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788203\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,204 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58262 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,205 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,206 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,206 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58254 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,207 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,206 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.83|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cdb51fff-d6c2-4c82-8237-9af7bb93a726,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,208 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,208 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,209 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:30eca519-e240-4863-b381-d9945d03cb8f,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,234 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788234\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,236 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:652d8002-9557-4dd8-98c2-302ffa306508,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,236 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58288 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,237 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788241\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,242 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788242\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,242 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,242 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,243 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7f2c305e-6b43-4a4f-b229-70f5cd7fffc9,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,243 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,243 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,244 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58314 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,244 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,245 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,244 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58304 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,245 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,245 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,246 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788246\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,246 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,247 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f8071de-b045-4881-9d3d-3a329a2c1262,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,247 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,248 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,248 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58328 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,250 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:744dd2ab-2bcf-42f5-967b-7cd3a882df5d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,256 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788256\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,263 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,242 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,242 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,243 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7f2c305e-6b43-4a4f-b229-70f5cd7fffc9,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,243 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,243 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,244 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58314 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,244 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,245 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,244 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58304 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,245 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,245 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,246 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,246 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788246\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,246 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,247 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.58|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3f8071de-b045-4881-9d3d-3a329a2c1262,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,247 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,248 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,248 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58328 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,249 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,250 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:744dd2ab-2bcf-42f5-967b-7cd3a882df5d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,256 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788256\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,263 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:07655aa8-4069-4c6e-bdee-a8d25bc67cf0,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58334 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,270 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788270\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,271 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788271\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,272 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,272 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,273 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58364 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,273 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58362 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:07655aa8-4069-4c6e-bdee-a8d25bc67cf0,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58334 \"POST /invocations HTTP/1.1\" 500 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,264 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,270 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788270\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,271 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788271\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,272 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,272 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,273 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58364 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,273 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58362 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1169d51d-4bac-429f-a984-84527c7b3469,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,274 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788275\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:355e3465-d838-45cb-86b5-eac781ac8041,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58370 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dff39285-f865-453b-8c13-5a52c9edc965,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,282 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788282\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,283 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,273 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1169d51d-4bac-429f-a984-84527c7b3469,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,274 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,274 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788275\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,275 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:355e3465-d838-45cb-86b5-eac781ac8041,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,276 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58370 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,277 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:dff39285-f865-453b-8c13-5a52c9edc965,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,282 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788282\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,283 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58346 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,285 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7e6d5ea9-8e83-4e75-bf33-45eb456b8756,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,285 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,303 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788303\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,304 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58372 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,306 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,306 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788306\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,306 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,307 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c98a9646-5c7c-4f98-ae4d-889db41ffa9d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,307 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,285 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,284 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7e6d5ea9-8e83-4e75-bf33-45eb456b8756,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,285 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,303 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788303\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,304 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58372 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,305 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,306 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,306 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788306\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,306 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,307 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c98a9646-5c7c-4f98-ae4d-889db41ffa9d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,307 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d16c18f-f42e-4603-9bca-6b8ed49b20de,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,308 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58382 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788314\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,315 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58386 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,308 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.57|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8d16c18f-f42e-4603-9bca-6b8ed49b20de,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,308 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58382 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,309 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,314 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788314\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,315 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58386 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,317 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ec721a6-e576-492d-9487-8686a41dd51a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,316 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,317 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0ec721a6-e576-492d-9487-8686a41dd51a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,317 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788317\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,318 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,319 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:475f5c93-51ba-4acc-ab1e-832cdcc8a1ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,319 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58398 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,320 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788320\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,322 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,317 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788317\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,318 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,319 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.5|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:475f5c93-51ba-4acc-ab1e-832cdcc8a1ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,319 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58398 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,320 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,320 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788320\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,322 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58410 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,324 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c283b540-d59c-4722-8208-abeaa8ff05fe,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,328 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788328\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,329 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0d0de35d-cab6-4d6f-a646-88fee9cfeef5,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58414 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,331 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,331 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788363\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,363 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788362\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3d53d31d-e420-425f-81f1-0f0000176f13,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,322 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58410 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,323 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,324 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.61|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c283b540-d59c-4722-8208-abeaa8ff05fe,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,328 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788328\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,329 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0d0de35d-cab6-4d6f-a646-88fee9cfeef5,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58414 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,330 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,331 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,331 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,363 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788363\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,363 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788362\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.59|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3d53d31d-e420-425f-81f1-0f0000176f13,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58424 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,366 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,366 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58424 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,365 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,366 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,366 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,366 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:372d248e-1180-474d-8f70-eaa8e4c571e7,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58430 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,375 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788375\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,376 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,377 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,378 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7e04e689-8ceb-4689-a8f9-a5a33f33b00f,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,379 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58434 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,379 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,380 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,380 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,383 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788383\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,384 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,385 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58436 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,387 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b8e29ad-0c41-44ee-a2b6-2b7bb7597c3d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,395 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788395\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,395 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788395\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,396 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,366 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:372d248e-1180-474d-8f70-eaa8e4c571e7,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58430 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,367 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,375 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788375\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,376 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,377 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,378 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7e04e689-8ceb-4689-a8f9-a5a33f33b00f,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,379 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58434 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,379 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,380 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,380 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,383 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788383\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,384 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,385 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58436 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,386 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,387 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:5b8e29ad-0c41-44ee-a2b6-2b7bb7597c3d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,395 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788395\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,395 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788395\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,396 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,396 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0807935f-655c-4879-8e86-3cac20af379f,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58442 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,397 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,398 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,398 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,399 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58444 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,407 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:02ef6e86-6f75-424e-aeca-509eb8f5998d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,408 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788408\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,409 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,410 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f30f4308-383d-4bf3-9434-f7b7ee5f7c3c,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,410 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58454 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,414 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788414\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,414 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,415 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58462 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,417 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,417 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1b48868-4c20-4f65-963c-02eb744694ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,422 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788422\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,396 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0807935f-655c-4879-8e86-3cac20af379f,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58442 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,397 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,397 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,398 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,398 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,399 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,399 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58444 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,400 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,407 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.66|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:02ef6e86-6f75-424e-aeca-509eb8f5998d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,408 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788408\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,409 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,410 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f30f4308-383d-4bf3-9434-f7b7ee5f7c3c,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,410 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58454 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,411 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,414 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788414\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,414 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,415 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58462 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,416 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,417 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,417 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.49|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c1b48868-4c20-4f65-963c-02eb744694ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,422 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788422\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,423 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b691a13-f37a-49d7-a830-2207179b445d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58466 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,430 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788430\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,431 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788431\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,432 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:344f2fe4-9f48-47c8-922f-0476158d9852,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58480 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,423 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.62|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b691a13-f37a-49d7-a830-2207179b445d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,424 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58466 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,425 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,430 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788430\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,431 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788431\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,432 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.64|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:344f2fe4-9f48-47c8-922f-0476158d9852,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58476 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,433 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,437 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,438 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58480 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,439 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,440 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:180aaee3-fe48-42d2-9ac4-9d30d96ce0c2,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,450 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788450\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,450 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788450\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,451 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,451 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,452 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1cbcf46a-a407-4643-ba12-32416fc79c3d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,452 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,453 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58496 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0a3b59a5-1449-482e-a15c-20c20cabfa03,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788473\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,474 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:abf4f126-b5f5-47be-a3a1-06899fa70acd,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,476 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788475\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,477 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58498 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,479 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,440 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:180aaee3-fe48-42d2-9ac4-9d30d96ce0c2,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,450 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788450\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,450 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788450\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,451 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,451 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,452 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.65|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1cbcf46a-a407-4643-ba12-32416fc79c3d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,452 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58482 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,453 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,453 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58496 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,454 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,455 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.77|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0a3b59a5-1449-482e-a15c-20c20cabfa03,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,473 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788473\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,474 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:abf4f126-b5f5-47be-a3a1-06899fa70acd,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,475 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58504 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,476 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788475\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,476 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,477 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58498 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,478 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,479 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,479 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bb76b36a-6ec7-4123-83af-5deb003ff21a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,481 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788481\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,482 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2ca5a729-d759-404e-97ea-468dafbf53e6,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58520 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,494 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788493\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,494 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,495 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58532 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,501 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:13976369-0369-4b6e-a5b9-c0bd95fbb5e8,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,507 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788507\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,508 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,509 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41b02287-65f5-4805-885a-3d5f2d6c65e8,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,509 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58542 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,532 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788532\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,532 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,533 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,479 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bb76b36a-6ec7-4123-83af-5deb003ff21a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,481 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788481\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,482 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.48|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2ca5a729-d759-404e-97ea-468dafbf53e6,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58520 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,483 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,494 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788493\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,494 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,495 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58532 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,500 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,501 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.56|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:13976369-0369-4b6e-a5b9-c0bd95fbb5e8,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,507 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788507\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,508 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,509 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.72|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:41b02287-65f5-4805-885a-3d5f2d6c65e8,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,509 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58542 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,510 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,532 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788532\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,532 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,533 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,533 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58548 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,535 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bd65c2b0-6911-4eb5-aae6-a010cae35f25,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,536 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788536\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,537 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,537 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0edfd18b-fad2-4ff6-870a-a221bebed4ff,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58558 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788539\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,539 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,540 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58572 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:56661416-a685-49a5-9b1f-4138e8265a59,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,548 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788548\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58584 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,533 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58548 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,534 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,535 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bd65c2b0-6911-4eb5-aae6-a010cae35f25,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,536 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788536\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,537 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,537 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0edfd18b-fad2-4ff6-870a-a221bebed4ff,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58558 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,538 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788539\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,539 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,540 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58572 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,541 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:56661416-a685-49a5-9b1f-4138e8265a59,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,548 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788548\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,549 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58584 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,551 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1455b268-5445-45eb-a3a6-bb6517402cb2,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788553\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,554 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58600 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a0b6d987-dad6-49f7-b782-955eeabfb5db,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,565 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788565\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58616 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2d9fe11f-867e-4c97-9fb0-ebfadced0e44,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,577 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788577\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,577 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,578 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:625ef65a-4cb1-4d0e-b7a0-a154507255b5,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,582 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788582\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,550 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,551 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1455b268-5445-45eb-a3a6-bb6517402cb2,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788553\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,554 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58600 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,556 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,557 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.92|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a0b6d987-dad6-49f7-b782-955eeabfb5db,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,565 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788565\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58616 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,566 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.44|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2d9fe11f-867e-4c97-9fb0-ebfadced0e44,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,577 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788577\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,577 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,578 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58624 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,579 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.46|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:625ef65a-4cb1-4d0e-b7a0-a154507255b5,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,582 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788582\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,583 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,584 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b215c65-a6cb-49d0-9388-324ccbc46665,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,584 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58626 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,589 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788589\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,589 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58628 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,591 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4fb1d56f-773e-4328-966b-fee2858a866d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788600\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788602\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,602 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58634 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:119daabb-bec5-4fc0-8ebc-eb5176620f3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,604 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58636 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,606 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2db4e92-bfaa-4b21-b484-75e00b945c7a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,584 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.81|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4b215c65-a6cb-49d0-9388-324ccbc46665,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,584 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58626 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,585 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,589 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788589\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,589 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58628 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,590 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,591 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:4fb1d56f-773e-4328-966b-fee2858a866d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,600 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788600\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,602 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788602\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,602 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58634 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.71|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:119daabb-bec5-4fc0-8ebc-eb5176620f3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,603 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,604 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58636 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,605 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,606 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:2.26|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:d2db4e92-bfaa-4b21-b484-75e00b945c7a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,611 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788611\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788615\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,615 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,616 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,616 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,616 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58638 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58640 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:978b1ed0-8eb3-45b3-8bdf-f6849aab531a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,618 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,618 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,618 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9f18c840-aa08-4f9f-94a9-4c0dfcffcf3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788624\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,624 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,625 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,625 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58650 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0b78ad09-385e-493d-9900-2aa523b855bd,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,639 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788639\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,639 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,640 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1b9555b9-e498-4754-a387-4f16664a4c96,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,611 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788611\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,615 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788615\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,615 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,616 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,616 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,616 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58638 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58640 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:978b1ed0-8eb3-45b3-8bdf-f6849aab531a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,617 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,618 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,618 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,618 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:9f18c840-aa08-4f9f-94a9-4c0dfcffcf3b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788624\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,624 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,625 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,625 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58650 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,626 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,627 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.35|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:0b78ad09-385e-493d-9900-2aa523b855bd,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,639 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788639\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,639 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,640 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58662 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1b9555b9-e498-4754-a387-4f16664a4c96,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,641 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.548:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.549:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.549:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.549:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.549:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/89.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.553:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.558:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.559:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/88.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.607:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/9.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.685:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.686:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/90.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.770:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/92.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.771:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/93.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.796:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.797:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/91.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.839:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.840:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.840:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.840:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.840:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/96.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.864:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.865:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/95.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.866:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.867:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.867:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.867:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/94.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.900:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/98.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.909:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.910:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.910:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/99.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fbe8379bea0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.924:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.924:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: \u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.924:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: Message:\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.924:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 128, in transform\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:     result = self._transform_fn(self._model, input_data, content_type, accept)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/sagemaker_inference/transformer.py\", line 233, in _default_transform_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:     data = self._input_fn(input_data, content_type)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 83, in input_fn\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:     image_tensor = load_from_bytearray(request_body)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:   File \"/opt/ml/model/code/resnet_deploy.py\", line 75, in load_from_bytearray\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:     image = Image.open(image_as_bytes)\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:   File \"/opt/conda/lib/python3.8/site-packages/PIL/Image.py\", line 3147, in open\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out:     raise UnidentifiedImageError(\u001b[0m\n",
      "\u001b[32m2022-08-21T06:36:28.925:[sagemaker logs]: sagemaker-han/sagemaker/batch_transform_outputs/97.png.out: PIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x7fe3068b0ef0>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2022-08-21T06:36:28,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788660\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,661 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788661\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,662 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,662 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,662 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58684 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bbbe6788-e1e3-4110-8838-cc7894927bb2,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,665 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,665 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,665 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788665\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,666 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba8b7f5a-fabf-407e-b5cf-5125824dfc7e,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,666 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,667 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58692 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,669 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,670 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788670\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,671 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:86570589-bdca-4ada-aab3-663dc6a949b9,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,660 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788660\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,661 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,661 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788661\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,662 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,662 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,662 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58684 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,663 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,663 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.6|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bbbe6788-e1e3-4110-8838-cc7894927bb2,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58678 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,664 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,665 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,665 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,665 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788665\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,666 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:ba8b7f5a-fabf-407e-b5cf-5125824dfc7e,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,666 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,667 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58692 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,668 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,669 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,670 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788670\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,671 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.47|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:86570589-bdca-4ada-aab3-663dc6a949b9,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,672 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58704 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,677 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f71b3ce5-7894-4860-a10f-8b655c75998b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788686\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,688 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,689 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58712 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,689 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:49f71c1e-b4cf-4acb-b25a-114127cceeaf,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,697 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788697\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,697 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788697\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,698 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58718 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,700 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,700 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:08098109-ddd2-48d1-8d5b-9c330c721e47,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,703 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58714 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8cfe08ef-c2b2-4b10-bc4d-06beefcffff9,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,716 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788716\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,717 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58726 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bf4f9415-7802-45dc-b07e-bd1a98af1e1b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,719 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,729 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788729\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788730\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,731 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,733 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,733 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58750 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,734 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:902da044-b63b-4bc4-a025-fd1f835e4da5,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,673 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,677 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f71b3ce5-7894-4860-a10f-8b655c75998b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,686 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788686\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,688 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,689 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58712 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,690 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,689 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:49f71c1e-b4cf-4acb-b25a-114127cceeaf,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,697 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788697\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,697 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788697\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,698 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58718 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,700 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,700 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,699 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.73|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:08098109-ddd2-48d1-8d5b-9c330c721e47,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,703 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58714 \"POST /invocations HTTP/1.1\" 500 7\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,704 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8cfe08ef-c2b2-4b10-bc4d-06beefcffff9,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,705 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,716 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788716\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,717 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58726 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:bf4f9415-7802-45dc-b07e-bd1a98af1e1b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,718 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,719 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,729 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788729\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,730 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788730\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,731 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58742 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,732 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,733 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,733 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58750 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,734 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.41|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:902da044-b63b-4bc4-a025-fd1f835e4da5,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,735 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb964baa-96f8-4e63-a07e-76dd592683e6,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788741\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,742 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,749 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788749\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:7.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a7755608-894d-413a-8517-109d6e5347fe,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58772 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788750\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,753 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,753 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:87615708-a60d-49ea-96bc-b7151364b652,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:421827d5-b124-480a-9675-f2bdf15d4264,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58758 \"POST /invocations HTTP/1.1\" 500 13\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58788 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,768 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788768\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,768 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58790 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cf12afe9-164a-40c0-b373-fbe48b74da5b,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,770 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,770 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,771 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788771\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:112790b9-6e34-4f7b-9469-0f777f73010d,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58794 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,774 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,774 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,786 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,786 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788786\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,787 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,787 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,788 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.21|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8bf1d053-a93d-4a98-8a0e-91cb6c76a408,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58806 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,734 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,735 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.55|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:eb964baa-96f8-4e63-a07e-76dd592683e6,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,741 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788741\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,742 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,749 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788749\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:7.63|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a7755608-894d-413a-8517-109d6e5347fe,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58772 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,750 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788750\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,753 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,753 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.88|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:87615708-a60d-49ea-96bc-b7151364b652,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.28|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:421827d5-b124-480a-9675-f2bdf15d4264,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58758 \"POST /invocations HTTP/1.1\" 500 13\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,755 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58788 \"POST /invocations HTTP/1.1\" 500 9\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,758 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,768 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788768\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,768 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58790 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,769 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.4|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:cf12afe9-164a-40c0-b373-fbe48b74da5b,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,770 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,770 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,771 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788771\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:112790b9-6e34-4f7b-9469-0f777f73010d,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58794 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,773 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,774 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,774 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,786 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,786 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788786\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,787 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,787 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,788 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.21|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:8bf1d053-a93d-4a98-8a0e-91cb6c76a408,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58806 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3df4a1d-cd56-490d-a855-fc42fd433feb,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,789 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,790 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58808 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,790 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,791 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,791 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,790 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788792\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,792 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3d2854dd-e9a6-45e0-8c4f-72c06795e5a0,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58796 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788796\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,798 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,798 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:00744e6c-776b-4b0c-92b1-e75a04e9ab2e,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58814 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,800 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,800 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,813 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788813\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,814 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58816 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1dbd73ac-141a-4980-813f-869f191ca6be,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,816 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,816 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,822 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788822\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58832 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:136c42fa-b571-4a99-abca-7b1c0b77f1d4,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,827 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788827\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,828 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58836 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1ded7270-bb65-4a66-badc-40457b675b9e,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,830 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,831 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.7|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f3df4a1d-cd56-490d-a855-fc42fd433feb,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,789 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,790 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58808 \"POST /invocations HTTP/1.1\" 500 5\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,790 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,791 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,791 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,790 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788792\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,792 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:3d2854dd-e9a6-45e0-8c4f-72c06795e5a0,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,793 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58796 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,794 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,796 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788796\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,798 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,798 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.37|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:00744e6c-776b-4b0c-92b1-e75a04e9ab2e,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58814 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,799 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,800 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,800 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,813 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788813\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,814 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58816 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1dbd73ac-141a-4980-813f-869f191ca6be,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,815 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,816 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,816 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,822 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788822\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58832 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,823 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,824 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:136c42fa-b571-4a99-abca-7b1c0b77f1d4,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,827 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788827\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,828 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58836 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.53|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:1ded7270-bb65-4a66-badc-40457b675b9e,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,829 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,830 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,831 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,831 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58844 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,833 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e0e74dda-42f2-45d4-bcd9-3083503b51cf,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788847\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,848 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788848\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,848 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,849 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,849 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58846 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58856 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,851 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:12de9d31-06a0-4d5e-b538-2e9dde8a01c7,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,852 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,852 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7015802b-48d9-47e9-a8ce-2ad3fbc7436a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,856 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788856\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,857 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788857\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,857 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,858 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58872 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,860 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,860 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58878 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,870 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:964f150f-bda3-41f8-9327-33fd2615586e,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,871 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788871\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788871\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a8ed7bae-56b3-466a-90a3-87b57c3b2236,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,873 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,875 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b727453-0cb4-4c81-85cd-93e99fef7897,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,875 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,875 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58894 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58886 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,831 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58844 \"POST /invocations HTTP/1.1\" 500 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,832 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,833 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.38|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:e0e74dda-42f2-45d4-bcd9-3083503b51cf,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,847 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788847\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,848 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788848\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,848 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,849 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,849 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58846 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,850 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58856 \"POST /invocations HTTP/1.1\" 500 4\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,851 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.43|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:12de9d31-06a0-4d5e-b538-2e9dde8a01c7,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,851 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,852 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,852 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.9|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:7015802b-48d9-47e9-a8ce-2ad3fbc7436a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,856 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788856\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,857 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788857\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,857 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,858 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58872 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,859 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,860 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,860 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58878 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,870 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,870 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:1.86|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:964f150f-bda3-41f8-9327-33fd2615586e,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,871 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788871\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,871 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788871\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,860 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.42|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:a8ed7bae-56b3-466a-90a3-87b57c3b2236,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,873 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,875 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:2b727453-0cb4-4c81-85cd-93e99fef7897,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,875 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,875 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,875 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58894 \"POST /invocations HTTP/1.1\" 500 6\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58886 \"POST /invocations HTTP/1.1\" 500 12\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,877 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,877 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9c8a629-afcd-43b8-96a3-9b33ccbfa575,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,897 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788897\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,897 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,898 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58908 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c6e90760-5efe-42a9-8321-f80970fc4133,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,905 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788905\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,907 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58916 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6b4c9c6e-4fd7-4715-9fca-a6cfebaca4ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,876 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,877 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,877 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.45|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:f9c8a629-afcd-43b8-96a3-9b33ccbfa575,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,897 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788897\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,897 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,898 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 ACCESS_LOG - /169.254.255.130:58908 \"POST /invocations HTTP/1.1\" 500 2\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.68|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:c6e90760-5efe-42a9-8321-f80970fc4133,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,899 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,905 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1661063788905\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,907 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,907 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 ACCESS_LOG - /169.254.255.130:58916 \"POST /invocations HTTP/1.1\" 500 3\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063778\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:0.51|#ModelName:model,Level:Model|#hostname:3717f2878b4a,requestID:6b4c9c6e-4fd7-4715-9fca-a6cfebaca4ee,timestamp:1661063788\u001b[0m\n",
      "\u001b[35m2022-08-21T06:36:28,908 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063788\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.19969177246094|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.665439605712891|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:4951.5234375|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2514.015625|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.19969177246094|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.665439605712891|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:13.7|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:4951.5234375|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[35m2022-08-21T06:37:11,333 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2514.015625|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n",
      "\u001b[34m2022-08-21T06:37:11,334 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2022-08-21T06:37:11,334 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.2|#Level:Host|#hostname:3717f2878b4a,timestamp:1661063831\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job pytorch-inference-2022-08-21-06-31-31-788: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_transform_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/transformer.py:292\u001b[0m, in \u001b[0;36mTransformer.stop_transform_job\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_transform_job\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_transform_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/transformer.py:440\u001b[0m, in \u001b[0;36m_TransformJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m--> 440\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_transform_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_transform_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/session.py:4023\u001b[0m, in \u001b[0;36mSession.logs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4020\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   4022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4023\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTransformJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   4025\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/batch_transform-aeIkgUX-/lib/python3.9/site-packages/sagemaker/session.py:3391\u001b[0m, in \u001b[0;36mSession._check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   3386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   3387\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   3388\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3389\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   3390\u001b[0m     )\n\u001b[0;32m-> 3391\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   3392\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   3393\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   3394\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   3395\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job pytorch-inference-2022-08-21-06-31-31-788: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "transformer.stop_transform_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf813c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 21, 12, 13, 37, 860000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'FailureReason': 'AlgorithmError: See job logs for more information',\n",
      " 'ModelName': 'pytorch-inference-2022-08-21-03-13-10-667',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '949',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 21 Aug 2022 05:10:13 GMT',\n",
      "                                      'x-amzn-requestid': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 21, 12, 18, 21, 796000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-han/sagemaker/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:608095525235:transform-job/pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobStatus': 'Failed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-608095525235/pytorch-inference-2022-08-21-03-13-37-242'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 8, 21, 12, 16, 42, 175000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "job_name = 'pytorch-inference-2022-08-21-03-13-37-242'\n",
    "sm_cli = sagemaker_session.sagemaker_client\n",
    "job_info = sm_cli.describe_transform_job(TransformJobName=job_name)\n",
    "pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53b2cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = 'outputs'\n",
    "\n",
    "sagemaker_session.download_data(path=local_path, bucket=bucket, key_prefix='sagemaker/batch_transform/outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d8b1c9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n",
      "{'predictions': 8}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61056ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('aws_batch_transform-pg7SNxiG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "445eadaa75e92a02935b67c0f43eae30d5f0df35a0b86dd757723720e6c70438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
