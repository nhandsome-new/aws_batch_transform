{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0c300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os, boto3, json, sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from io import BytesIO\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# AWS設定\n",
    "region = boto3.Session().region_name\n",
    "role = 'han_s3_full_access'\n",
    "bucket='sagemaker-han-batch'\n",
    "# role = 'FullAccessHan'\n",
    "# bucket='sagemaker-han'\n",
    "prefix = 'batch-images'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "model_prefix = os.path.join(prefix, 'model')\n",
    "input_prefix = os.path.join(prefix, 'inputs')\n",
    "output_prefix = os.path.join(prefix, 'outputs')\n",
    "inference_prefix = os.path.join(prefix, 'f_inference')\n",
    "\n",
    "# Local設定\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "model_dir = os.path.join(base_dir, 'model')\n",
    "input_dir = os.path.join(base_dir, 'inputs')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "inference_dir = os.path.join(base_dir, 'inference')\n",
    "source_dir = os.path.join(base_dir, 'src')\n",
    "for dir_name in [model_dir, input_dir, output_dir, source_dir, inference_dir]:\n",
    "    make_dir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f28de312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Inference用のデータを作る(jsonlines)\n",
    "    - Sampling\n",
    "    - Convert Image into bytes\n",
    "    - Save as jsonlines\n",
    "'''\n",
    "from src.utils import image_to_bytes\n",
    "\n",
    "r_inference_path = os.path.join(base_dir, 'real_inference')\n",
    "n = 5000\n",
    "json_name = r_inference_path+f'/inf_data{n}.jsonl'\n",
    "\n",
    "image_to_bytes(json_name, data_dir, inference_dir, n)\n",
    "\n",
    "f_inference = sagemaker_session.upload_data(path=r_inference_path, bucket=bucket, key_prefix='batch-images/r_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6c0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for the model training\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "training_data_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(input_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(output_dir, 'test.pt'))\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=input_dir, bucket=bucket, key_prefix=input_prefix)\n",
    "outputs = sagemaker_session.upload_data(path=output_dir, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9a0ac",
   "metadata": {},
   "source": [
    "## Traning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5274c069",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msagemaker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mimport\u001b[39;00m PyTorch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=3'>4</a>\u001b[0m estimator \u001b[39m=\u001b[39m PyTorch(entry_point\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresnet.py\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=4'>5</a>\u001b[0m                     role\u001b[39m=\u001b[39mrole,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=5'>6</a>\u001b[0m                     source_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msrc\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=13'>14</a>\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=14'>15</a>\u001b[0m                     })\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/han/Desktop/Fusic/2022/aws_batch_transform/batch_image/batch_transform_image_input.ipynb#ch0000005?line=16'>17</a>\u001b[0m estimator\u001b[39m.\u001b[39mfit({\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m: inputs})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Training Container\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"resnet.py\",\n",
    "                    role=role,\n",
    "                    source_dir = \"src\",\n",
    "                    framework_version='1.12.0',\n",
    "                    py_version='py38',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'batch-size':128,\n",
    "                        'lr': 0.01,\n",
    "                        'epochs': 1,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.rand(1,3,32,32)\n",
    "test_output = cifar10_predictor.predict(test_input)\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)\n",
    "\n",
    "cifar10_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4fb4",
   "metadata": {},
   "source": [
    "# Batch Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb925323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# home\n",
    "# model_path = 's3://sagemaker-us-west-2-608095525235/pytorch-training-2022-08-22-14-02-01-637/model.tar.gz'\n",
    "# fusic\n",
    "model_path = 's3://sagemaker-us-west-2-582981179587/pytorch-training-2022-08-22-11-21-23-382/model.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data = model_path,\n",
    "                             entry_point='resnet_batch_transform.py',\n",
    "                             source_dir = 'src',\n",
    "                             framework_version='1.12.0',\n",
    "                             py_version='py38',\n",
    "                             role = role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea2048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concurrent_transforms = 10\n",
    "max_payload = 1\n",
    "strategy = 'SingleRecord'\n",
    "# split_type = None\n",
    "# strategy = 'MultiRecord'\n",
    "split_type = 'Line'\n",
    "\n",
    "output_s3_path = 's3://{}/{}/bt_test_{}_{}_{}_{}'.format(bucket, output_prefix, max_concurrent_transforms, max_payload, strategy, split_type)\n",
    "\n",
    "transformer = pytorch_model.transformer(instance_count=1,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              max_concurrent_transforms=max_concurrent_transforms,\n",
    "                              max_payload=max_payload,  \n",
    "                              strategy=strategy,\n",
    "                              output_path=output_s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a14655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_path = f's3://{bucket}/batch-images/r_inference'\n",
    "transformer.transform(\n",
    "    data=inference_path,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/jsonlines\",\n",
    "    wait=False,\n",
    "    split_type=split_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ccee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer.stop_transform_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf813c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 21, 12, 13, 37, 860000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'FailureReason': 'AlgorithmError: See job logs for more information',\n",
      " 'ModelName': 'pytorch-inference-2022-08-21-03-13-10-667',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '949',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Sun, 21 Aug 2022 05:10:13 GMT',\n",
      "                                      'x-amzn-requestid': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'cd218913-c7fe-4e1f-9b31-2b2fa07372d4',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 21, 12, 18, 21, 796000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-han/sagemaker/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-west-2:608095525235:transform-job/pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-21-03-13-37-242',\n",
      " 'TransformJobStatus': 'Failed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-west-2-608095525235/pytorch-inference-2022-08-21-03-13-37-242'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.large'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 8, 21, 12, 16, 42, 175000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "# import pprint as pp\n",
    "\n",
    "# job_name = 'pytorch-inference-2022-08-21-03-13-37-242'\n",
    "# sm_cli = sagemaker_session.sagemaker_client\n",
    "# job_info = sm_cli.describe_transform_job(TransformJobName=job_name)\n",
    "# pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "054838cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n",
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n",
      "PRED SHAPE: torch.Size([2])\n",
      "tensor([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"predictions\": [1, 1, 1, 1, 1, 1]}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.resnet_batch_transform import resnet20\n",
    "\n",
    "tmp_model = resnet20()\n",
    "tmp_model.eval()\n",
    "tmp_input = torch.rand(2, 3, 32, 32)\n",
    "\n",
    "preds = []\n",
    "for _ in range(3):\n",
    "    tmp_output = tmp_model(tmp_input)\n",
    "    pred = torch.argmax(tmp_output, dim=1)\n",
    "    print(f'PRED SHAPE: {pred.shape}')\n",
    "    print(pred)\n",
    "    preds += pred\n",
    "\n",
    "preds = np.array(preds).tolist()\n",
    "\n",
    "p_return = {\"predictions\": preds}\n",
    "json.dumps(p_return)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "170915b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.SageMaker at 0x290eb4a60>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "969cb06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['create_transform_job',\n",
       " 'describe_transform_job',\n",
       " 'list_transform_jobs',\n",
       " 'stop_transform_job']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: \"transform\" in x, dir(sm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "08288b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x['TransformJobStatus'] == \"InProgress\", sm.list_transform_jobs()['TransformJobSummaries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c4369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('aws_batch_transform-pg7SNxiG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "445eadaa75e92a02935b67c0f43eae30d5f0df35a0b86dd757723720e6c70438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
