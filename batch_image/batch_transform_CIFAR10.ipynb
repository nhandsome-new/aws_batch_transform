{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0c300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os, boto3, json, sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from io import BytesIO\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# AWS設定\n",
    "region = boto3.Session().region_name\n",
    "role = 'YOUR_AWS_ROLE_NAME' # with s3, sagemaker accese policy\n",
    "bucket='YOUR_BUCKET_NAME'\n",
    "prefix = 'batch-images'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "input_prefix = os.path.join(prefix, 'inputs')\n",
    "output_prefix = os.path.join(prefix, 'outputs')\n",
    "inference_prefix = os.path.join(prefix, 'f_inference')\n",
    "\n",
    "# Local設定\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "input_dir = os.path.join(base_dir, 'inputs')\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "inference_dir = os.path.join(base_dir, 'inference')\n",
    "source_dir = os.path.join(base_dir, 'src')\n",
    "for dir_name in [input_dir, output_dir, source_dir, inference_dir]:\n",
    "    make_dir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f28de312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inference用のデータを作る(jsonlines)\n",
    "    - Sampling\n",
    "    - Convert Image into bytes\n",
    "    - Save as jsonlines\n",
    "'''\n",
    "from src.utils import image_to_bytes\n",
    "\n",
    "r_inference_path = os.path.join(base_dir, 'real_inference')\n",
    "n = 1000\n",
    "json_name = r_inference_path+f'/inf_data{n}.jsonl'\n",
    "\n",
    "image_to_bytes(json_name, data_dir, inference_dir, n)\n",
    "\n",
    "f_inference = sagemaker_session.upload_data(path=r_inference_path, bucket=bucket, key_prefix='batch-images/r_inference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9a0ac",
   "metadata": {},
   "source": [
    "## Traning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6c0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for the model training\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "training_data_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "training_data_loaded = next(iter(training_data_loader))\n",
    "torch.save(training_data_loaded, os.path.join(input_dir, 'training.pt'))\n",
    "\n",
    "test_data_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "test_data_loaded = next(iter(test_data_loader))\n",
    "torch.save(test_data_loaded, os.path.join(output_dir, 'test.pt'))\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path=input_dir, bucket=bucket, key_prefix=input_prefix)\n",
    "outputs = sagemaker_session.upload_data(path=output_dir, bucket=bucket, key_prefix=output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Container\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"resnet.py\",\n",
    "                    role=role,\n",
    "                    source_dir = \"src\",\n",
    "                    framework_version='1.12.0',\n",
    "                    py_version='py38',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'batch-size':128,\n",
    "                        'lr': 0.01,\n",
    "                        'epochs': 1,\n",
    "                    })\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_predictor = estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e52ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.rand(1,3,32,32)\n",
    "test_output = cifar10_predictor.predict(test_input)\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)\n",
    "\n",
    "cifar10_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4fb4",
   "metadata": {},
   "source": [
    "# Batch Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb925323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# model_path = cifar10_predictor\n",
    "model_path = 's3://your/saved/model/path/model.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data = model_path,\n",
    "                             entry_point='resnet_batch_transform.py',\n",
    "                             source_dir = 'src',\n",
    "                             framework_version='1.12.0',\n",
    "                             py_version='py38',\n",
    "                             role = role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea2048d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_concurrent_transforms = 10\n",
    "max_payload = 1\n",
    "# strategy = 'SingleRecord'\n",
    "# split_type = None\n",
    "strategy = 'MultiRecord'\n",
    "split_type = 'Line'\n",
    "\n",
    "output_s3_path = 's3://your/output/path'\n",
    "\n",
    "transformer = pytorch_model.transformer(instance_count=1,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              max_concurrent_transforms=max_concurrent_transforms,\n",
    "                              max_payload=max_payload,  \n",
    "                              strategy=strategy,\n",
    "                              output_path=output_s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# データをセーブしておいたPath (f_inference)\n",
    "inference_path = f's3://your/input/path'\n",
    "\n",
    "transformer.transform(\n",
    "    data=inference_path,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/jsonlines\",\n",
    "    wait=True,\n",
    "    split_type=split_type,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('aws_batch_transform-pg7SNxiG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "445eadaa75e92a02935b67c0f43eae30d5f0df35a0b86dd757723720e6c70438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
